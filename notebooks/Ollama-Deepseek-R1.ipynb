{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31a3a75b",
   "metadata": {},
   "source": [
    "## **Convert all of these Anthropic examples to work with DeepSeek-R1 via Ollama.** \n",
    " \n",
    " ##**Anthropic Examples**## \n",
    " \n",
    " Sure, I can help you convert the Anthropic examples to work with DeepSeek-R1 via Ollama. Please provide the specific Anthropic examples you would like to convert. Here are some general guidelines and a template to get started:\n",
    "\n",
    " 1. Stream Thinking Example\n",
    " 2. Tools Example \n",
    " 3. Budget Comparison \n",
    " 4. Prompting Best Practices \n",
    " 5. Cost Analysis \n",
    "   \n",
    "###\n",
    "| **Anthropic Feature** | **DeepSeek-R1 Equivalent** |\n",
    "|----------------------|----------------------------|\n",
    "| `thinking={\"type\": \"enabled\"}` | Automatic `<think>` tags |\n",
    "| `budget_tokens=5000` | No budget needed - automatic |\n",
    "| `client.messages.stream()` | `client.chat(stream=True)` |\n",
    "| `block.type == \"thinking\"` | Parse `<think>...</think>` |\n",
    "| Token cost management | FREE local inference |\n",
    "| Tool calling | Manual calculation requests |\n",
    "| Response streaming events | Chunk-based content streaming |\n",
    "\n",
    "### Key Advantages of DeepSeek-R1:\n",
    "\n",
    "1. **üí∞ Cost**: Completely FREE vs Claude's $0.05-0.50 per analysis\n",
    "2. **üß† Thinking**: Always visible, no budget management needed  \n",
    "3. **üîí Privacy**: Runs locally, no cloud dependencies\n",
    "4. **‚ö° Performance**: No network latency, unlimited usage\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5844ea5",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "## 2. Setting Up Your Environment using Astral uv\n",
    "\n",
    "Let's start by installing the necessary packages and setting up our API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685ee4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ollama\n",
    "from IPython.display import Markdown, display\n",
    "import json\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Use the working URL directly\n",
    "ollama_url = 'http://localhost:11434'  # Your confirmed working URL\n",
    "model_name = 'deepseek-r1:14b'\n",
    "\n",
    "# Create Ollama client\n",
    "client = ollama.Client(host=ollama_url)\n",
    "\n",
    "print(f\"‚úÖ Connected to Ollama at: {ollama_url}\")\n",
    "print(f\"ü§ñ Using model: {model_name}\")\n",
    "\n",
    "# Verify the model is available\n",
    "try:\n",
    "    models = client.list()\n",
    "    available_models = [m['name'] for m in models.get('models', [])]\n",
    "    print(f\"‚úÖ Found {len(available_models)} models\")\n",
    "    \n",
    "    if model_name in available_models:\n",
    "        print(f\"‚úÖ {model_name} is available and ready!\")\n",
    "    else:\n",
    "        print(f\"‚ùå {model_name} not found. Available models:\")\n",
    "        for model in available_models[:5]:  # Show first 5\n",
    "            print(f\"  - {model}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error verifying models: {e}\")\n",
    "\n",
    "# Test a simple chat\n",
    "def test_basic_chat():\n",
    "    print(f\"\\nüß™ Testing basic chat...\")\n",
    "    try:\n",
    "        response = client.chat(\n",
    "            model=model_name,\n",
    "            messages=[{\"role\": \"user\", \"content\": \"Hello! Just say 'Hi' back.\"}],\n",
    "            stream=False\n",
    "        )\n",
    "        \n",
    "        answer = response.get('message', {}).get('content', '')\n",
    "        print(f\"‚úÖ DeepSeek says: {answer}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Chat test failed: {e}\")\n",
    "        return False\n",
    "\n",
    "# Run the test\n",
    "if test_basic_chat():\n",
    "    print(f\"\\nüéâ Everything is working perfectly!\")\n",
    "    print(f\"You can now use the converted examples.\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå Something went wrong with the chat test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16068e0d",
   "metadata": {},
   "source": [
    "### All of my Ollama.ai models are supported.\n",
    "\n",
    "| Model Name               | ID              | Size    | Last Modified |\n",
    "|--------------------------|-----------------|---------|---------------|\n",
    "| phi4-mini:3.8b           | 78fad5d182a7    | 2.5 GB  | 6 days ago    |\n",
    "| deepseek-r1:32b          | edba8017331d    | 19 GB   | 6 days ago    |\n",
    "| deepseek-r1:14b          | c333b7232bdb    | 9.0 GB  | 6 days ago    |\n",
    "| deepseek-r1:8b           | 6995872bfe4c    | 5.2 GB  | 6 days ago    |\n",
    "| deepseek-r1:1.5b         | e0979632db5a    | 1.1 GB  | 6 days ago    |\n",
    "| gemma3n:e4b              | 15cb39fd9394    | 7.5 GB  | 6 days ago    |\n",
    "| qwen2.5vl:7b             | 5ced39dfa4ba    | 6.0 GB  | 3 weeks ago   |\n",
    "| qwen2.5vl:32b            | 3edc3a52fe98    | 21 GB   | 3 weeks ago   |\n",
    "| mistral-small3.1:24b     | b9aaf0c2586a    | 15 GB   | 3 weeks ago   |\n",
    "| gemma3:27b               | a418f5838eaf    | 17 GB   | 4 weeks ago   |\n",
    "| gemma3:12b               | f4031aab637d    | 8.1 GB  | 4 weeks ago   |\n",
    "| gemma3:4b                | a2af6cc3eb7f    | 3.3 GB  | 4 weeks ago   |\n",
    "| phi4-reasoning:latest    | 47e2630ccbcd    | 11 GB   | 4 weeks ago   |\n",
    "| qwen2.5-coder:14b        | 9ec8897f747e    | 9.0 GB  | 4 weeks ago   |\n",
    "| qwen2.5-coder:7b         | dae161e27b0e    | 4.7 GB  | 4 weeks ago   |\n",
    "| qwen3:14b                | bdbd181c33f2    | 9.3 GB  | 4 weeks ago   |\n",
    "| qwen3:8b                 | 500a1f067a9f    | 5.2 GB  | 4 weeks ago   |\n",
    "| phi4:latest              | ac896e5b8b34    | 9.1 GB  | 6 months ago  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1d9995",
   "metadata": {},
   "source": [
    "<a id='basic-usage'></a>\n",
    "## 3. Basic Usage\n",
    "\n",
    "Let's start with a simple example to see extended thinking in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f873cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your basic thinking example (converted)\n",
    "def basic_thinking_example():\n",
    "    response = client.chat(\n",
    "        model='deepseek-r1:14b',\n",
    "        messages=[{\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"What is 27 * 453? Show me how you calculate this step by step.\"\n",
    "        }],\n",
    "        stream=False\n",
    "    )\n",
    "    \n",
    "    full_response = response.get('message', {}).get('content', '')\n",
    "    \n",
    "    # Parse thinking and answer\n",
    "    if '<think>' in full_response:\n",
    "        thinking_start = full_response.find('<think>') + 7\n",
    "        thinking_end = full_response.find('</think>')\n",
    "        thinking = full_response[thinking_start:thinking_end].strip()\n",
    "        answer = full_response[thinking_end + 8:].strip()\n",
    "        \n",
    "        print(\"ü§î DeepSeek's Thinking:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(thinking)\n",
    "        print(\"-\" * 50)\n",
    "        print(\"\\n‚úÖ Final Answer:\")\n",
    "        print(answer)\n",
    "    else:\n",
    "        print(\"‚úÖ Response:\")\n",
    "        print(full_response)\n",
    "\n",
    "# Run it\n",
    "basic_thinking_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e4d362",
   "metadata": {},
   "source": [
    "# **No, this is NOT valid for DeepSeek-R1.** Here's the key difference:\n",
    "\n",
    "## Anthropic Claude vs DeepSeek-R1 Thinking\n",
    "\n",
    "### ‚ùå **Anthropic Claude (Manual Configuration)**\n",
    "```python\n",
    "thinking={\n",
    "    \"type\": \"enabled\",        # Must explicitly enable\n",
    "    \"budget_tokens\": 5000     # Must set token budget\n",
    "}\n",
    "```\n",
    "\n",
    "### ‚úÖ **DeepSeek-R1 (Automatic)**\n",
    "```python\n",
    "# No thinking parameters needed!\n",
    "client.chat(\n",
    "    model='deepseek-r1:14b',\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Your question\"}]\n",
    ")\n",
    "# Thinking happens automatically in <think>...</think> tags\n",
    "```\n",
    "\n",
    "## Key Differences:\n",
    "\n",
    "| **Feature** | **Anthropic Claude** | **DeepSeek-R1** |\n",
    "|-------------|---------------------|-----------------|\n",
    "| **Thinking Control** | Manual (`thinking={\"type\": \"enabled\"}`) | ‚úÖ **Automatic** |\n",
    "| **Token Budget** | Required (`budget_tokens: 1024-32000`) | ‚úÖ **No budget needed** |\n",
    "| **Thinking Output** | Separate block/summary | ‚úÖ **Full process in `<think>` tags** |\n",
    "| **Cost** | Thinking tokens billed as output | ‚úÖ **FREE (local)** |\n",
    "| **Configuration** | Complex parameter management | ‚úÖ **Zero configuration** |\n",
    "\n",
    "## DeepSeek-R1 Thinking Behavior:\n",
    "\n",
    "```python\n",
    "# Simple question = shorter thinking\n",
    "response = client.chat(messages=[{\"role\": \"user\", \"content\": \"What is 2+2?\"}])\n",
    "# Result: <think>Simple addition: 2+2=4</think>The answer is 4.\n",
    "\n",
    "# Complex question = extensive thinking  \n",
    "response = client.chat(messages=[{\"role\": \"user\", \"content\": \"Design a REST API...\"}])\n",
    "# Result: <think>[5000+ characters of detailed reasoning]</think>[Final answer]\n",
    "```\n",
    "\n",
    "## Why DeepSeek-R1 is Simpler:\n",
    "\n",
    "1. **üéØ No Parameter Management**: Just ask your question\n",
    "2. **üß† Intelligent Scaling**: Thinking depth automatically matches complexity\n",
    "3. **üí∞ No Token Costs**: Think as much as needed without cost concerns\n",
    "4. **üîç Full Transparency**: See the complete thought process, not just summaries\n",
    "\n",
    "**Bottom Line**: DeepSeek-R1's thinking is **automatic, free, and transparent** - no configuration needed like Claude's manual thinking parameters!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c805e89",
   "metadata": {},
   "source": [
    "<a id='thinking-blocks'></a>\n",
    "## 4. Understanding Thinking Blocks\n",
    "\n",
    "Let's explore how thinking blocks work and what information they contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9b7d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_thinking_blocks():\n",
    "    \"\"\"Demonstrate the structure of DeepSeek-R1 thinking blocks\"\"\"\n",
    "    \n",
    "    response = client.chat(\n",
    "        model='deepseek-r1:14b',\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"I have a list of numbers: [15, 23, 8, 42, 16, 4, 30, 12].\n",
    "            \n",
    "            Please:\n",
    "            1. Find the median\n",
    "            2. Calculate the mean\n",
    "            3. Identify any outliers using the IQR method\n",
    "            4. Suggest what this data might represent\"\"\"\n",
    "        }],\n",
    "        stream=False\n",
    "    )\n",
    "    \n",
    "    # Get the full response\n",
    "    full_response = response.get('message', {}).get('content', '')\n",
    "    \n",
    "    # Analyze the response structure\n",
    "    print(\"üìä DeepSeek-R1 Response Structure Analysis\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Parse thinking vs final answer\n",
    "    if '<think>' in full_response and '</think>' in full_response:\n",
    "        thinking_start = full_response.find('<think>') + 7\n",
    "        thinking_end = full_response.find('</think>')\n",
    "        thinking_content = full_response[thinking_start:thinking_end].strip()\n",
    "        final_answer = full_response[thinking_end + 8:].strip()\n",
    "        \n",
    "        print(f\"\\nResponse Structure:\")\n",
    "        print(f\"  Total Length: {len(full_response)} characters\")\n",
    "        print(f\"  Has Thinking Block: Yes\")\n",
    "        print(f\"  Thinking Length: {len(thinking_content)} characters\")\n",
    "        print(f\"  Final Answer Length: {len(final_answer)} characters\")\n",
    "        print(f\"  Thinking Ratio: {len(thinking_content)/(len(full_response))*100:.1f}%\")\n",
    "        \n",
    "        print(f\"\\nü§î THINKING PROCESS:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(thinking_content)\n",
    "        \n",
    "        print(f\"\\n‚úÖ FINAL ANSWER:\")\n",
    "        print(\"-\" * 40)\n",
    "        display(Markdown(final_answer))\n",
    "        \n",
    "        # Additional analysis\n",
    "        print(f\"\\nüìà THINKING ANALYSIS:\")\n",
    "        print(\"-\" * 40)\n",
    "        thinking_lines = thinking_content.split('\\n')\n",
    "        print(f\"  Lines in thinking: {len(thinking_lines)}\")\n",
    "        print(f\"  Words in thinking: {len(thinking_content.split())}\")\n",
    "        \n",
    "        # Look for mathematical reasoning patterns\n",
    "        math_keywords = ['calculate', 'median', 'mean', 'average', 'sort', 'IQR', 'outlier']\n",
    "        found_keywords = [kw for kw in math_keywords if kw.lower() in thinking_content.lower()]\n",
    "        print(f\"  Mathematical concepts mentioned: {found_keywords}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\nResponse Structure:\")\n",
    "        print(f\"  Total Length: {len(full_response)} characters\")\n",
    "        print(f\"  Has Thinking Block: No\")\n",
    "        print(f\"  Response Type: Direct answer\")\n",
    "        \n",
    "        print(f\"\\n‚úÖ RESPONSE:\")\n",
    "        print(\"-\" * 40)\n",
    "        display(Markdown(full_response))\n",
    "    \n",
    "    return full_response\n",
    "\n",
    "# Run the analysis\n",
    "result = analyze_thinking_blocks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c95eb1",
   "metadata": {},
   "source": [
    "**No, this is NOT valid for DeepSeek-R1.** Those specific features are unique to Anthropic's Claude 4 implementation. Here's the comparison:\n",
    "\n",
    "## Anthropic Claude 4 vs DeepSeek-R1 Thinking\n",
    "\n",
    "| **Feature** | **Anthropic Claude 4** | **DeepSeek-R1** |\n",
    "|-------------|------------------------|------------------|\n",
    "| **Summarization** | ‚úÖ Provides summarized thinking | ‚ùå Shows FULL thinking process |\n",
    "| **Billing Model** | üí∞ Charged for full thinking tokens | üí∞ FREE (local inference) |\n",
    "| **Signature Verification** | ‚úÖ Cryptographic signatures | ‚ùå No signatures needed |\n",
    "| **Privacy Controls** | ‚úÖ Controlled thinking exposure | ‚úÖ Full local privacy |\n",
    "\n",
    "## DeepSeek-R1 Thinking Characteristics:\n",
    "\n",
    "### 1. **Full Thinking Display** (Not Summarized)\n",
    "```python\n",
    "# DeepSeek-R1 shows EVERYTHING in <think> tags\n",
    "response = \"\"\"<think>\n",
    "Let me work through this step by step...\n",
    "First I need to calculate 27 * 453...\n",
    "27 * 453 = 27 * (450 + 3) = 27 * 450 + 27 * 3\n",
    "27 * 450 = 27 * 45 * 10 = 1215 * 10 = 12,150\n",
    "27 * 3 = 81\n",
    "So 27 * 453 = 12,150 + 81 = 12,231\n",
    "</think>\n",
    "\n",
    "The answer is 27 √ó 453 = 12,231\"\"\"\n",
    "```\n",
    "\n",
    "### 2. **No Token Billing** (Free Local)\n",
    "- No \"thinking budget\" needed\n",
    "- No charge per token\n",
    "- Unlimited thinking depth\n",
    "\n",
    "### 3. **No Cryptographic Signatures**\n",
    "- No verification system\n",
    "- Direct model output\n",
    "- Trust based on model reliability\n",
    "\n",
    "### 4. **Complete Transparency**\n",
    "- You see the actual thinking process\n",
    "- No hidden reasoning steps\n",
    "- Full visibility into model reasoning\n",
    "\n",
    "## What This Means for You:## The Key Difference:\n",
    "\n",
    "**Anthropic Claude 4** gives you a \"polished summary\" of thinking with enterprise features.\n",
    "\n",
    "**DeepSeek-R1** gives you the \"raw, unfiltered thinking process\" with complete transparency.\n",
    "\n",
    "Think of it like:\n",
    "- **Claude 4**: A professional report with executive summary\n",
    "- **DeepSeek-R1**: The researcher's complete notebook with all work shown\n",
    "\n",
    "Both are valuable, but for **learning and understanding AI reasoning**, DeepSeek-R1 actually gives you MORE insight into how the model thinks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2b6885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepseek_thinking_reality():\n",
    "    \"\"\"Demonstrate actual DeepSeek-R1 thinking characteristics\"\"\"\n",
    "    \n",
    "    print(\"üîç DeepSeek-R1 Thinking Reality Check\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Test to show actual thinking behavior\n",
    "    response = client.chat(\n",
    "        model='deepseek-r1:14b',\n",
    "        messages=[{\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"Calculate 27 * 453 and show your work clearly.\"\n",
    "        }],\n",
    "        stream=False\n",
    "    )\n",
    "    \n",
    "    full_response = response.get('message', {}).get('content', '')\n",
    "    \n",
    "    print(\"üß† WHAT YOU ACTUALLY GET:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    if '<think>' in full_response and '</think>' in full_response:\n",
    "        thinking_start = full_response.find('<think>') + 7\n",
    "        thinking_end = full_response.find('</think>')\n",
    "        thinking_content = full_response[thinking_start:thinking_end].strip()\n",
    "        final_answer = full_response[thinking_end + 8:].strip()\n",
    "        \n",
    "        print(\"‚úÖ Full thinking process visible:\")\n",
    "        print(f\"   Length: {len(thinking_content)} characters\")\n",
    "        print(f\"   Words: {len(thinking_content.split())} words\")\n",
    "        print(f\"   Complete reasoning: YES\")\n",
    "        print(f\"   Summarized: NO\")\n",
    "        print(f\"   Cryptographic signature: NO\")\n",
    "        print(f\"   Cost: $0.00 (FREE)\")\n",
    "        \n",
    "        print(f\"\\nüéØ THINKING SAMPLE (first 500 chars):\")\n",
    "        print(f\"   {thinking_content[:500]}...\")\n",
    "        \n",
    "        print(f\"\\nüí° FINAL ANSWER:\")\n",
    "        print(f\"   {final_answer}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå No thinking block found in this response\")\n",
    "    \n",
    "    return full_response\n",
    "\n",
    "def anthropic_vs_deepseek_summary():\n",
    "    \"\"\"Summary of key differences\"\"\"\n",
    "    \n",
    "    print(f\"\\nüìä ANTHROPIC vs DEEPSEEK-R1 SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    differences = [\n",
    "        {\n",
    "            \"aspect\": \"Thinking Visibility\",\n",
    "            \"anthropic\": \"Summarized snippets\",\n",
    "            \"deepseek\": \"Complete full process\",\n",
    "            \"winner\": \"DeepSeek-R1\"\n",
    "        },\n",
    "        {\n",
    "            \"aspect\": \"Cost Model\", \n",
    "            \"anthropic\": \"Pay per thinking token\",\n",
    "            \"deepseek\": \"Free local inference\",\n",
    "            \"winner\": \"DeepSeek-R1\"\n",
    "        },\n",
    "        {\n",
    "            \"aspect\": \"Token Management\",\n",
    "            \"anthropic\": \"Budget required\",\n",
    "            \"deepseek\": \"No limits needed\",\n",
    "            \"winner\": \"DeepSeek-R1\"\n",
    "        },\n",
    "        {\n",
    "            \"aspect\": \"Privacy\",\n",
    "            \"anthropic\": \"Cloud-based processing\",\n",
    "            \"deepseek\": \"Local-only processing\", \n",
    "            \"winner\": \"DeepSeek-R1\"\n",
    "        },\n",
    "        {\n",
    "            \"aspect\": \"Setup Complexity\",\n",
    "            \"anthropic\": \"API key only\",\n",
    "            \"deepseek\": \"Local installation\",\n",
    "            \"winner\": \"Anthropic\"\n",
    "        },\n",
    "        {\n",
    "            \"aspect\": \"Verification\",\n",
    "            \"anthropic\": \"Cryptographic signatures\",\n",
    "            \"deepseek\": \"Direct model output\",\n",
    "            \"winner\": \"Anthropic\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(f\"{'Aspect':<20} | {'Anthropic':<20} | {'DeepSeek-R1':<20} | {'Better'}\")\n",
    "    print(\"-\" * 85)\n",
    "    \n",
    "    for diff in differences:\n",
    "        winner_symbol = \"üèÜ\" if diff['winner'] == \"DeepSeek-R1\" else \"‚≠ê\"\n",
    "        print(f\"{diff['aspect']:<20} | {diff['anthropic']:<20} | {diff['deepseek']:<20} | {winner_symbol} {diff['winner']}\")\n",
    "    \n",
    "    print(f\"\\nüéØ BOTTOM LINE:\")\n",
    "    print(f\"   ‚Ä¢ DeepSeek-R1: Better for transparency, cost, privacy\")\n",
    "    print(f\"   ‚Ä¢ Anthropic: Better for enterprise verification, ease of setup\")\n",
    "    print(f\"   ‚Ä¢ Both: Excellent reasoning capabilities\")\n",
    "\n",
    "def practical_implications():\n",
    "    \"\"\"What this means for your usage\"\"\"\n",
    "    \n",
    "    print(f\"\\nüí° PRACTICAL IMPLICATIONS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    implications = [\n",
    "        \"‚úÖ You see MORE thinking detail with DeepSeek-R1\",\n",
    "        \"‚úÖ No token budgets to manage or optimize\", \n",
    "        \"‚úÖ No surprise costs from long thinking processes\",\n",
    "        \"‚ùå No verification signatures (trust the model)\",\n",
    "        \"‚ùå More complex initial setup required\",\n",
    "        \"‚úÖ Complete privacy and data control\"\n",
    "    ]\n",
    "    \n",
    "    for implication in implications:\n",
    "        print(f\"   {implication}\")\n",
    "    \n",
    "    print(f\"\\nüöÄ RECOMMENDATION:\")\n",
    "    print(f\"   Use DeepSeek-R1 for: Learning, experimentation, cost-sensitive projects\")\n",
    "    print(f\"   Use Claude 4 for: Enterprise verification, quick API setup\")\n",
    "\n",
    "# Run the reality check\n",
    "result = deepseek_thinking_reality()\n",
    "anthropic_vs_deepseek_summary()\n",
    "practical_implications()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c0a6c4",
   "metadata": {},
   "source": [
    "No, the specific **streaming API structure** from Anthropic is not directly valid for DeepSeek-R1 via Ollama. Here's the comparison:\n",
    "\n",
    "## ‚ùå Anthropic Streaming (Not Valid for DeepSeek)\n",
    "\n",
    "```python\n",
    "# This is Anthropic-specific and won't work with DeepSeek-R1\n",
    "with client.messages.stream(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    thinking={\"type\": \"enabled\", \"budget_tokens\": 5000},\n",
    "    messages=[{\"role\": \"user\", \"content\": \"...\"}]\n",
    ") as stream:\n",
    "    for event in stream:\n",
    "        if event.type == \"content_block_start\":\n",
    "            # Anthropic-specific event structure\n",
    "        elif event.type == \"content_block_delta\":\n",
    "            # Anthropic-specific delta events\n",
    "```\n",
    "\n",
    "## ‚úÖ DeepSeek-R1 Streaming (What Actually Works)## Summary: What's Valid vs Invalid\n",
    "\n",
    "### ‚ùå **NOT Valid for DeepSeek-R1:**\n",
    "- `client.messages.stream()` - Different API\n",
    "- `thinking={\"type\": \"enabled\", \"budget_tokens\": 5000}` - No budget system\n",
    "- `event.type == \"content_block_start\"` - Different event structure\n",
    "- `event.delta.type == \"thinking_delta\"` - No delta events\n",
    "- Context managers (`with stream as s:`) - Different pattern\n",
    "\n",
    "### ‚úÖ **Valid Concepts (but different implementation):**\n",
    "- **Streaming responses** - Yes, but with `client.chat(stream=True)`\n",
    "- **Thinking visibility** - Yes, but via `<think>` tag parsing\n",
    "- **Progressive display** - Yes, but with chunk iteration\n",
    "- **Real-time feedback** - Yes, but simpler implementation\n",
    "\n",
    "### üéØ **Key Difference:**\n",
    "**Anthropic**: Complex event-driven streaming with budget management  \n",
    "**DeepSeek-R1**: Simple chunk-based streaming with automatic thinking\n",
    "\n",
    "**The concepts are similar, but the implementation is completely different.** DeepSeek-R1 is actually simpler - no complex event handling needed, just parse the `<think>` tags from the streaming content!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eff125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ANTHROPIC STREAMING (DOESN'T WORK WITH DEEPSEEK)\n",
    "# ============================================================================\n",
    "\n",
    "def anthropic_style_streaming():\n",
    "    \"\"\"This is how Anthropic streaming works - NOT valid for DeepSeek\"\"\"\n",
    "    \n",
    "    # ‚ùå This structure doesn't exist in Ollama\n",
    "    \"\"\"\n",
    "    with client.messages.stream(\n",
    "        model=\"claude-sonnet-4-20250514\",\n",
    "        thinking={\"type\": \"enabled\", \"budget_tokens\": 5000},\n",
    "        messages=[{\"role\": \"user\", \"content\": \"...\"}]\n",
    "    ) as stream:\n",
    "        for event in stream:\n",
    "            if event.type == \"content_block_start\":\n",
    "                # Anthropic-specific events\n",
    "            elif event.type == \"content_block_delta\":\n",
    "                # Anthropic-specific deltas\n",
    "    \"\"\"\n",
    "    print(\"‚ùå This Anthropic pattern doesn't work with DeepSeek-R1/Ollama\")\n",
    "\n",
    "# ============================================================================\n",
    "# DEEPSEEK-R1 STREAMING (WHAT ACTUALLY WORKS)\n",
    "# ============================================================================\n",
    "\n",
    "def deepseek_streaming_correct():\n",
    "    \"\"\"This is how DeepSeek-R1 streaming actually works\"\"\"\n",
    "    \n",
    "    print(\"‚úÖ DeepSeek-R1 Streaming (Correct Method)\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # ‚úÖ This is the correct way for DeepSeek-R1\n",
    "    stream = client.chat(\n",
    "        model='deepseek-r1:14b',\n",
    "        messages=[{\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"Explain quantum computing in simple terms.\"\n",
    "        }],\n",
    "        stream=True  # Simple boolean flag\n",
    "    )\n",
    "    \n",
    "    # Track streaming state\n",
    "    full_response = \"\"\n",
    "    in_thinking = False\n",
    "    \n",
    "    print(\"ü§ñ DeepSeek-R1: \", end=\"\", flush=True)\n",
    "    \n",
    "    # ‚úÖ Simple iteration over chunks\n",
    "    for chunk in stream:\n",
    "        if 'message' in chunk:\n",
    "            content = chunk['message'].get('content', '')\n",
    "            full_response += content\n",
    "            \n",
    "            # Handle thinking transitions\n",
    "            if '<think>' in content and not in_thinking:\n",
    "                in_thinking = True\n",
    "                print(\"\\nüß† [Thinking...] \", end=\"\", flush=True)\n",
    "                content = content.replace('<think>', '')\n",
    "            \n",
    "            if '</think>' in content and in_thinking:\n",
    "                in_thinking = False\n",
    "                print(\" [Done]\\nüí° Answer: \", end=\"\", flush=True)\n",
    "                content = content.replace('</think>', '')\n",
    "            \n",
    "            # Show appropriate content\n",
    "            if in_thinking:\n",
    "                print(\".\", end=\"\", flush=True)  # Progress dots\n",
    "            else:\n",
    "                print(content, end=\"\", flush=True)  # Actual content\n",
    "    \n",
    "    print(f\"\\n\\n‚úÖ Complete! ({len(full_response)} chars)\")\n",
    "    return full_response\n",
    "\n",
    "# ============================================================================\n",
    "# COMPARISON TABLE\n",
    "# ============================================================================\n",
    "\n",
    "def show_streaming_comparison():\n",
    "    \"\"\"Show the differences between Anthropic and DeepSeek streaming\"\"\"\n",
    "    \n",
    "    print(\"\\nüìä STREAMING API COMPARISON\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    comparison = [\n",
    "        {\n",
    "            \"Feature\": \"Stream initiation\",\n",
    "            \"Anthropic\": \"client.messages.stream()\",\n",
    "            \"DeepSeek\": \"client.chat(stream=True)\"\n",
    "        },\n",
    "        {\n",
    "            \"Feature\": \"Context manager\", \n",
    "            \"Anthropic\": \"with stream as s:\",\n",
    "            \"DeepSeek\": \"for chunk in stream:\"\n",
    "        },\n",
    "        {\n",
    "            \"Feature\": \"Event types\",\n",
    "            \"Anthropic\": \"event.type, event.delta\",\n",
    "            \"DeepSeek\": \"chunk['message']['content']\"\n",
    "        },\n",
    "        {\n",
    "            \"Feature\": \"Thinking detection\",\n",
    "            \"Anthropic\": \"event.type == 'thinking'\",\n",
    "            \"DeepSeek\": \"Parse <think> tags\"\n",
    "        },\n",
    "        {\n",
    "            \"Feature\": \"Content access\",\n",
    "            \"Anthropic\": \"event.delta.text\",\n",
    "            \"DeepSeek\": \"chunk['message']['content']\"\n",
    "        },\n",
    "        {\n",
    "            \"Feature\": \"Thinking budget\",\n",
    "            \"Anthropic\": \"budget_tokens=5000\",\n",
    "            \"DeepSeek\": \"Automatic (no config needed)\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(f\"{'Feature':<20} | {'Anthropic':<25} | {'DeepSeek-R1':<25}\")\n",
    "    print(\"-\" * 75)\n",
    "    \n",
    "    for comp in comparison:\n",
    "        print(f\"{comp['Feature']:<20} | {comp['Anthropic']:<25} | {comp['DeepSeek']:<25}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PRACTICAL DEEPSEEK STREAMING EXAMPLES\n",
    "# ============================================================================\n",
    "\n",
    "def practical_streaming_examples():\n",
    "    \"\"\"Show practical streaming patterns for DeepSeek-R1\"\"\"\n",
    "    \n",
    "    print(f\"\\nüöÄ PRACTICAL DEEPSEEK STREAMING PATTERNS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Pattern 1: Simple streaming\n",
    "    print(f\"\\n1Ô∏è‚É£ Simple Streaming:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\"\"\"\n",
    "stream = client.chat(model='deepseek-r1:14b', messages=messages, stream=True)\n",
    "for chunk in stream:\n",
    "    if 'message' in chunk:\n",
    "        content = chunk['message'].get('content', '')\n",
    "        print(content, end='', flush=True)\n",
    "\"\"\")\n",
    "    \n",
    "    # Pattern 2: Thinking-aware streaming\n",
    "    print(f\"\\n2Ô∏è‚É£ Thinking-Aware Streaming:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\"\"\"\n",
    "in_thinking = False\n",
    "for chunk in stream:\n",
    "    content = chunk['message'].get('content', '')\n",
    "    if '<think>' in content: in_thinking = True\n",
    "    if '</think>' in content: in_thinking = False\n",
    "    \n",
    "    if in_thinking:\n",
    "        print('.', end='', flush=True)  # Progress\n",
    "    else:\n",
    "        print(content, end='', flush=True)  # Response\n",
    "\"\"\")\n",
    "    \n",
    "    # Pattern 3: Advanced streaming with analysis\n",
    "    print(f\"\\n3Ô∏è‚É£ Advanced Streaming with Analysis:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\"\"\"\n",
    "thinking_buffer = \"\"\n",
    "response_buffer = \"\"\n",
    "\n",
    "for chunk in stream:\n",
    "    content = chunk['message'].get('content', '')\n",
    "    \n",
    "    if in_thinking_mode:\n",
    "        thinking_buffer += content\n",
    "        show_thinking_progress()\n",
    "    else:\n",
    "        response_buffer += content\n",
    "        display_response(content)\n",
    "\n",
    "analyze_thinking_patterns(thinking_buffer)\n",
    "\"\"\")\n",
    "\n",
    "# ============================================================================\n",
    "# RUN EXAMPLES\n",
    "# ============================================================================\n",
    "\n",
    "def run_all_examples():\n",
    "    \"\"\"Run all streaming examples\"\"\"\n",
    "    \n",
    "    print(\"üéØ DEEPSEEK-R1 STREAMING GUIDE\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Show what doesn't work\n",
    "    anthropic_style_streaming()\n",
    "    \n",
    "    # Show what does work\n",
    "    result = deepseek_streaming_correct()\n",
    "    \n",
    "    # Show comparisons\n",
    "    show_streaming_comparison()\n",
    "    \n",
    "    # Show practical patterns\n",
    "    practical_streaming_examples()\n",
    "    \n",
    "    print(f\"\\n‚úÖ Key Takeaway: DeepSeek-R1 streaming is simpler!\")\n",
    "    print(f\"   No complex event handling - just parse <think> tags\")\n",
    "    print(f\"   No budget management - thinking is automatic\")\n",
    "    print(f\"   No special context managers - simple iteration\")\n",
    "\n",
    "# Run the complete guide\n",
    "run_all_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4e60c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_thinking_example():\n",
    "    \"\"\"Demonstrate streaming with DeepSeek-R1 thinking\"\"\"\n",
    "    \n",
    "    print(\"üåä Streaming DeepSeek-R1 Thinking Example\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    question = \"\"\"Design a simple REST API for a todo list application. \n",
    "    Include endpoints for CRUD operations and consider:\n",
    "    - Authentication\n",
    "    - Error handling\n",
    "    - Data validation\n",
    "    - Response formats\"\"\"\n",
    "    \n",
    "    print(f\"‚ùì Question: {question}\\n\")\n",
    "    \n",
    "    # Stream the response\n",
    "    stream = client.chat(\n",
    "        model='deepseek-r1:14b',\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": question\n",
    "        }],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    # Track the response as it comes in\n",
    "    full_response = \"\"\n",
    "    in_thinking = False\n",
    "    thinking_content = \"\"\n",
    "    final_answer = \"\"\n",
    "    \n",
    "    print(\"ü§ñ DeepSeek-R1 Response:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    for chunk in stream:\n",
    "        if 'message' in chunk:\n",
    "            content = chunk['message'].get('content', '')\n",
    "            full_response += content\n",
    "            \n",
    "            # Check if we're entering thinking mode\n",
    "            if '<think>' in content and not in_thinking:\n",
    "                in_thinking = True\n",
    "                print(\"\\nüß† [THINKING...] \", end=\"\", flush=True)\n",
    "                continue\n",
    "            \n",
    "            # Check if we're exiting thinking mode\n",
    "            if '</think>' in content and in_thinking:\n",
    "                in_thinking = False\n",
    "                print(\" [THINKING COMPLETE]\\n\")\n",
    "                print(\"üí° Final Answer:\")\n",
    "                print(\"-\" * 20)\n",
    "                continue\n",
    "            \n",
    "            # Show progress dots during thinking\n",
    "            if in_thinking:\n",
    "                print(\".\", end=\"\", flush=True)\n",
    "            else:\n",
    "                # Show the actual final answer\n",
    "                print(content, end=\"\", flush=True)\n",
    "    \n",
    "    print(f\"\\n\\nüìä Stream Summary:\")\n",
    "    print(f\"  Total response length: {len(full_response)} characters\")\n",
    "    \n",
    "    # Parse the complete response for detailed analysis\n",
    "    if '<think>' in full_response and '</think>' in full_response:\n",
    "        thinking_start = full_response.find('<think>') + 7\n",
    "        thinking_end = full_response.find('</think>')\n",
    "        thinking_content = full_response[thinking_start:thinking_end].strip()\n",
    "        final_answer = full_response[thinking_end + 8:].strip()\n",
    "        \n",
    "        print(f\"  Thinking length: {len(thinking_content)} characters\")\n",
    "        print(f\"  Final answer length: {len(final_answer)} characters\")\n",
    "        print(f\"  Thinking took: {len(thinking_content.split())} words to process\")\n",
    "    \n",
    "    return full_response\n",
    "\n",
    "# Run the streaming example\n",
    "result = stream_thinking_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7c5c5f",
   "metadata": {},
   "source": [
    "### 5.2 Extended Thinking with Tool Use\n",
    "\n",
    "Extended thinking can be combined with tool use for even more powerful applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc5d913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "\n",
    "def advanced_streaming_with_thinking():\n",
    "    \"\"\"Advanced streaming that shows thinking process in real-time\"\"\"\n",
    "    \n",
    "    print(\"üöÄ Advanced Streaming with Real-time Thinking Display\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    question = \"\"\"Analyze this scenario: A tech startup wants to implement AI in their \n",
    "    customer service. They have 10,000 daily support tickets, 60% are simple FAQ-type \n",
    "    questions, 30% require human judgment, and 10% are complex technical issues. \n",
    "    Design a solution considering costs, customer satisfaction, and implementation timeline.\"\"\"\n",
    "    \n",
    "    print(f\"‚ùì Complex Question: {question}\\n\")\n",
    "    \n",
    "    # Stream the response\n",
    "    stream = client.chat(\n",
    "        model='deepseek-r1:14b',\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": question\n",
    "        }],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    # Advanced tracking\n",
    "    full_response = \"\"\n",
    "    thinking_buffer = \"\"\n",
    "    final_buffer = \"\"\n",
    "    in_thinking = False\n",
    "    thinking_started = False\n",
    "    \n",
    "    print(\"ü§ñ DeepSeek-R1 Processing:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    for chunk in stream:\n",
    "        if 'message' in chunk:\n",
    "            content = chunk['message'].get('content', '')\n",
    "            full_response += content\n",
    "            \n",
    "            # Handle thinking block start\n",
    "            if '<think>' in content:\n",
    "                in_thinking = True\n",
    "                thinking_started = True\n",
    "                content = content.replace('<think>', '')\n",
    "                print(\"\\nüß† THINKING PROCESS:\")\n",
    "                print(\"-\" * 30)\n",
    "                time.sleep(0.1)  # Small delay for readability\n",
    "            \n",
    "            # Handle thinking block end\n",
    "            if '</think>' in content:\n",
    "                in_thinking = False\n",
    "                content = content.replace('</think>', '')\n",
    "                thinking_buffer += content\n",
    "                print(f\"\\n{'.'*30}\")\n",
    "                print(\"üí° FINAL SOLUTION:\")\n",
    "                print(\"-\" * 30)\n",
    "                time.sleep(0.2)\n",
    "                continue\n",
    "            \n",
    "            # Process content based on current state\n",
    "            if in_thinking:\n",
    "                thinking_buffer += content\n",
    "                # Show thinking in real-time with slight delay\n",
    "                for char in content:\n",
    "                    print(char, end='', flush=True)\n",
    "                    time.sleep(0.005)  # Very small delay for dramatic effect\n",
    "            else:\n",
    "                final_buffer += content\n",
    "                # Show final answer immediately\n",
    "                print(content, end='', flush=True)\n",
    "    \n",
    "    # Final analysis\n",
    "    print(f\"\\n\\nüìä ADVANCED ANALYSIS:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    if thinking_buffer:\n",
    "        print(f\"‚úÖ Thinking captured: {len(thinking_buffer)} characters\")\n",
    "        print(f\"‚úÖ Final answer: {len(final_buffer)} characters\")\n",
    "        print(f\"‚úÖ Thinking-to-answer ratio: {len(thinking_buffer)/len(final_buffer):.1f}:1\")\n",
    "        \n",
    "        # Analyze thinking patterns\n",
    "        thinking_sentences = thinking_buffer.split('.')\n",
    "        print(f\"‚úÖ Thinking sentences: {len(thinking_sentences)}\")\n",
    "        \n",
    "        # Look for solution patterns\n",
    "        solution_keywords = ['consider', 'implement', 'solution', 'approach', 'strategy', 'recommend']\n",
    "        found_patterns = [kw for kw in solution_keywords if kw.lower() in thinking_buffer.lower()]\n",
    "        print(f\"‚úÖ Solution patterns found: {found_patterns}\")\n",
    "        \n",
    "        # Show thinking summary\n",
    "        print(f\"\\nüéØ THINKING SUMMARY (first 300 chars):\")\n",
    "        print(f\"   {thinking_buffer[:300]}...\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  No thinking block detected\")\n",
    "    \n",
    "    return {\n",
    "        'full_response': full_response,\n",
    "        'thinking': thinking_buffer,\n",
    "        'final_answer': final_buffer,\n",
    "        'has_thinking': bool(thinking_buffer)\n",
    "    }\n",
    "\n",
    "# Run the advanced streaming example\n",
    "result = advanced_streaming_with_thinking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e941b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_thinking_example():\n",
    "    \"\"\"Demonstrate streaming with DeepSeek-R1 extended thinking\"\"\"\n",
    "    \n",
    "    print(\"üåä Streaming Extended Thinking Example\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # DeepSeek-R1 automatically provides thinking - no budget needed!\n",
    "    stream = client.chat(\n",
    "        model='deepseek-r1:14b',\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"Design a simple REST API for a todo list application. \n",
    "            Include endpoints for CRUD operations and consider:\n",
    "            - Authentication\n",
    "            - Error handling\n",
    "            - Data validation\n",
    "            - Response formats\"\"\"\n",
    "        }],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    # Track streaming state\n",
    "    in_thinking = False\n",
    "    full_response = \"\"\n",
    "    \n",
    "    for chunk in stream:\n",
    "        if 'message' in chunk:\n",
    "            content = chunk['message'].get('content', '')\n",
    "            full_response += content\n",
    "            \n",
    "            # Detect thinking block start\n",
    "            if '<think>' in content and not in_thinking:\n",
    "                in_thinking = True\n",
    "                print(\"\\nü§î DeepSeek is thinking...\", end=\"\", flush=True)\n",
    "                content = content.replace('<think>', '')\n",
    "            \n",
    "            # Detect thinking block end\n",
    "            if '</think>' in content and in_thinking:\n",
    "                in_thinking = False\n",
    "                content = content.replace('</think>', '')\n",
    "                print(\" Done thinking!\")\n",
    "                print(\"\\n\\n‚úÖ Final Response:\\n\", end=\"\", flush=True)\n",
    "            \n",
    "            # Show appropriate output\n",
    "            if in_thinking:\n",
    "                # Show progress dots during thinking\n",
    "                print(\".\", end=\"\", flush=True)\n",
    "            else:\n",
    "                # Show the actual response content\n",
    "                print(content, end=\"\", flush=True)\n",
    "    \n",
    "    print(f\"\\n\\nResponse complete! Total length: {len(full_response)} characters\")\n",
    "    return full_response\n",
    "\n",
    "# Run the example\n",
    "result = stream_thinking_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8706d5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thinking_with_tools_example():\n",
    "    \"\"\"Demonstrate extended thinking with simulated tool use\"\"\"\n",
    "    \n",
    "    # Note: DeepSeek-R1 doesn't have native tool calling like Claude,\n",
    "    # but we can simulate it by asking it to \"think through\" calculations\n",
    "    \n",
    "    response = client.chat(\n",
    "        model='deepseek-r1:14b',\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"I'm planning a party for 25 people. Each person will eat:\n",
    "            - 3 slices of pizza (8 slices per pizza)\n",
    "            - 2 sodas ($1.50 each)\n",
    "            - 1 dessert ($3.00 each)\n",
    "            \n",
    "            Pizzas cost $12 each. Calculate the total cost and quantities needed.\n",
    "            Please show your mathematical calculations step by step.\"\"\"\n",
    "        }],\n",
    "        stream=False\n",
    "    )\n",
    "    \n",
    "    print(\"üéâ Party Planning with Extended Thinking\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    full_response = response.get('message', {}).get('content', '')\n",
    "    \n",
    "    # Parse thinking and final answer\n",
    "    if '<think>' in full_response and '</think>' in full_response:\n",
    "        thinking_start = full_response.find('<think>') + 7\n",
    "        thinking_end = full_response.find('</think>')\n",
    "        thinking_content = full_response[thinking_start:thinking_end].strip()\n",
    "        final_answer = full_response[thinking_end + 8:].strip()\n",
    "        \n",
    "        print(\"\\nü§î Planning Process:\")\n",
    "        print(\"-\" * 40)\n",
    "        # Show first 1000 characters of thinking\n",
    "        print(thinking_content[:1000])\n",
    "        if len(thinking_content) > 1000:\n",
    "            print(\"...\\n\")\n",
    "        \n",
    "        print(\"\\nüìã Final Plan:\")\n",
    "        print(\"-\" * 40)\n",
    "        display(Markdown(final_answer))\n",
    "        \n",
    "        # Analyze the thinking for mathematical patterns\n",
    "        calc_keywords = ['calculate', 'multiply', 'add', 'total', 'cost', 'pizza', 'soda']\n",
    "        found_calcs = [kw for kw in calc_keywords if kw.lower() in thinking_content.lower()]\n",
    "        print(f\"\\nüîß Mathematical concepts used: {found_calcs}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"\\nüìã Response:\")\n",
    "        display(Markdown(full_response))\n",
    "    \n",
    "    return full_response\n",
    "\n",
    "# DeepSeek-R1 Token Guidelines (No explicit budget needed)\n",
    "print(\"üéØ DeepSeek-R1 Guidelines\")\n",
    "print(\"=\" * 50)\n",
    "print(\"‚úÖ No token budgets needed - thinking is automatic\")\n",
    "print(\"‚úÖ Thinking depth scales with problem complexity\")\n",
    "print(\"‚úÖ Average thinking: 2K-10K characters\")\n",
    "print(\"‚úÖ Complex problems: 10K-50K+ characters\")\n",
    "print(\"‚úÖ No additional cost for thinking tokens\")\n",
    "\n",
    "thinking_with_tools_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4333e4f",
   "metadata": {},
   "source": [
    "<a id='best-practices'></a>\n",
    "## 6. Best Practices\n",
    "\n",
    "### 6.1 Choosing the Right Budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e0fe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompting_best_practices():\n",
    "    \"\"\"Demonstrate effective prompting strategies for DeepSeek-R1\"\"\"\n",
    "    \n",
    "    # Good prompt - clear, specific, structured\n",
    "    good_prompt = \"\"\"Analyze the following investment options and recommend the best choice:\n",
    "\n",
    "Option A: Stock Portfolio\n",
    "- Expected annual return: 8%\n",
    "- Risk level: High\n",
    "- Minimum investment: $10,000\n",
    "- Liquidity: High (can sell anytime)\n",
    "\n",
    "Option B: Real Estate\n",
    "- Expected annual return: 6%\n",
    "- Risk level: Medium\n",
    "- Minimum investment: $50,000\n",
    "- Liquidity: Low (takes months to sell)\n",
    "\n",
    "Option C: Bonds\n",
    "- Expected annual return: 4%\n",
    "- Risk level: Low\n",
    "- Minimum investment: $5,000\n",
    "- Liquidity: Medium\n",
    "\n",
    "Investor Profile:\n",
    "- Age: 35\n",
    "- Investment horizon: 15 years\n",
    "- Risk tolerance: Medium\n",
    "- Available capital: $75,000\n",
    "- Goal: Retirement savings\n",
    "\n",
    "Please provide:\n",
    "1. Analysis of each option\n",
    "2. Recommended allocation\n",
    "3. Justification for your recommendation\n",
    "\n",
    "Think through this systematically, considering risk-return tradeoffs, \n",
    "diversification principles, and the investor's specific situation.\"\"\"\n",
    "    \n",
    "    response = client.chat(\n",
    "        model='deepseek-r1:14b',\n",
    "        messages=[{\"role\": \"user\", \"content\": good_prompt}],\n",
    "        stream=False\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Best Practices Example: Structured Investment Analysis\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    full_response = response.get('message', {}).get('content', '')\n",
    "    \n",
    "    # Parse and display thinking + answer\n",
    "    if '<think>' in full_response and '</think>' in full_response:\n",
    "        thinking_start = full_response.find('<think>') + 7\n",
    "        thinking_end = full_response.find('</think>')\n",
    "        thinking_content = full_response[thinking_start:thinking_end].strip()\n",
    "        final_answer = full_response[thinking_end + 8:].strip()\n",
    "        \n",
    "        print(\"\\nüß† THINKING PROCESS:\")\n",
    "        print(\"=\" * 40)\n",
    "        # Show key parts of thinking\n",
    "        print(thinking_content[:800] + \"...\" if len(thinking_content) > 800 else thinking_content)\n",
    "        \n",
    "        print(f\"\\nüí° FINAL RECOMMENDATION:\")\n",
    "        print(\"=\" * 40)\n",
    "        display(Markdown(final_answer))\n",
    "        \n",
    "        # Analyze thinking quality\n",
    "        analysis_keywords = ['risk', 'return', 'diversification', 'allocation', 'horizon', 'liquidity']\n",
    "        found_concepts = [kw for kw in analysis_keywords if kw.lower() in thinking_content.lower()]\n",
    "        print(f\"\\nüìä Investment concepts analyzed: {found_concepts}\")\n",
    "        \n",
    "    else:\n",
    "        display(Markdown(full_response))\n",
    "    \n",
    "    return full_response\n",
    "\n",
    "def show_prompting_tips():\n",
    "    \"\"\"Show DeepSeek-R1 specific prompting tips\"\"\"\n",
    "    \n",
    "    print(\"\\nüéØ DeepSeek-R1 Prompting Tips\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    tips = [\n",
    "        {\n",
    "            \"tip\": \"Be Explicit About Thinking\",\n",
    "            \"description\": \"Ask to 'think through systematically' or 'analyze step by step'\",\n",
    "            \"example\": \"'Think through this problem step by step before giving your answer'\"\n",
    "        },\n",
    "        {\n",
    "            \"tip\": \"Structure Your Requests\", \n",
    "            \"description\": \"Use numbered lists and clear sections\",\n",
    "            \"example\": \"'Please provide: 1. Analysis 2. Recommendation 3. Justification'\"\n",
    "        },\n",
    "        {\n",
    "            \"tip\": \"Provide Context\",\n",
    "            \"description\": \"Give background information and constraints\",\n",
    "            \"example\": \"'Consider the investor profile and 15-year time horizon'\"\n",
    "        },\n",
    "        {\n",
    "            \"tip\": \"Ask for Reasoning\",\n",
    "            \"description\": \"Request explanations of the thought process\",\n",
    "            \"example\": \"'Explain your reasoning and show your calculations'\"\n",
    "        },\n",
    "        {\n",
    "            \"tip\": \"Specify Output Format\",\n",
    "            \"description\": \"Request specific formats or structures\",\n",
    "            \"example\": \"'Provide a summary table and detailed analysis'\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for i, tip in enumerate(tips, 1):\n",
    "        print(f\"\\n{i}. {tip['tip']}\")\n",
    "        print(f\"   üìù {tip['description']}\")\n",
    "        print(f\"   üí° Example: {tip['example']}\")\n",
    "    \n",
    "    print(f\"\\n‚ú® Pro Tip: DeepSeek-R1 excels at mathematical reasoning,\")\n",
    "    print(f\"   financial analysis, and systematic problem-solving!\")\n",
    "\n",
    "# Run the examples\n",
    "result = prompting_best_practices()\n",
    "show_prompting_tips()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e39a764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepseek_cost_benefits():\n",
    "    \"\"\"Analyze DeepSeek-R1 cost benefits vs Claude thinking\"\"\"\n",
    "    \n",
    "    print(\"üí∞ DeepSeek-R1 vs Claude Thinking Cost Analysis\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Simulated costs (DeepSeek-R1 via Ollama is FREE!)\n",
    "    scenarios = [\n",
    "        {\"name\": \"Simple Analysis\", \"input\": 500, \"thinking\": 5000, \"output\": 1000},\n",
    "        {\"name\": \"Complex Problem\", \"input\": 2000, \"thinking\": 20000, \"output\": 3000},\n",
    "        {\"name\": \"Deep Research\", \"input\": 5000, \"thinking\": 50000, \"output\": 8000}\n",
    "    ]\n",
    "    \n",
    "    # Claude pricing (example - per million tokens)\n",
    "    claude_pricing = {\"input\": 3, \"output\": 15}\n",
    "    \n",
    "    print(f\"\\nüìä Cost Comparison:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    total_claude_cost = 0\n",
    "    \n",
    "    for scenario in scenarios:\n",
    "        # Claude costs (thinking billed as output)\n",
    "        claude_input_cost = (scenario[\"input\"] / 1_000_000) * claude_pricing[\"input\"]\n",
    "        claude_thinking_cost = (scenario[\"thinking\"] / 1_000_000) * claude_pricing[\"output\"]\n",
    "        claude_output_cost = (scenario[\"output\"] / 1_000_000) * claude_pricing[\"output\"]\n",
    "        claude_total = claude_input_cost + claude_thinking_cost + claude_output_cost\n",
    "        total_claude_cost += claude_total\n",
    "        \n",
    "        # DeepSeek-R1 costs (FREE with local Ollama!)\n",
    "        deepseek_cost = 0.00\n",
    "        \n",
    "        print(f\"\\n  {scenario['name']}:\")\n",
    "        print(f\"    Input: {scenario['input']:,} | Thinking: {scenario['thinking']:,} | Output: {scenario['output']:,}\")\n",
    "        print(f\"    Claude cost: ${claude_total:.4f}\")\n",
    "        print(f\"    DeepSeek-R1: ${deepseek_cost:.2f} (FREE!)\")\n",
    "        print(f\"    Savings: ${claude_total:.4f}\")\n",
    "    \n",
    "    print(f\"\\nüí° TOTAL SAVINGS: ${total_claude_cost:.4f} per analysis cycle\")\n",
    "    print(f\"üéØ Monthly savings (100 analyses): ${total_claude_cost * 100:.2f}\")\n",
    "    print(f\"üöÄ Annual savings (1200 analyses): ${total_claude_cost * 1200:.2f}\")\n",
    "\n",
    "def deepseek_advantages():\n",
    "    \"\"\"Show DeepSeek-R1 advantages\"\"\"\n",
    "    \n",
    "    print(f\"\\n‚≠ê DeepSeek-R1 Advantages\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    advantages = [\n",
    "        {\n",
    "            \"category\": \"üí∞ Cost\",\n",
    "            \"points\": [\n",
    "                \"Completely FREE when run locally\",\n",
    "                \"No token counting or budget management\",\n",
    "                \"No API costs or rate limits\",\n",
    "                \"One-time setup, unlimited usage\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"category\": \"üß† Thinking Quality\", \n",
    "            \"points\": [\n",
    "                \"Deep reasoning automatically included\",\n",
    "                \"Visible thought process in <think> tags\",\n",
    "                \"Excellent at mathematical reasoning\",\n",
    "                \"Strong logical problem-solving\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"category\": \"üîí Privacy\",\n",
    "            \"points\": [\n",
    "                \"Runs entirely on your hardware\",\n",
    "                \"No data sent to external APIs\",\n",
    "                \"Complete control over your data\",\n",
    "                \"Enterprise-safe deployment\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"category\": \"‚ö° Performance\",\n",
    "            \"points\": [\n",
    "                \"No network latency (local inference)\",\n",
    "                \"Consistent availability\",\n",
    "                \"Customizable parameters\",\n",
    "                \"GPU acceleration support\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for advantage in advantages:\n",
    "        print(f\"\\n{advantage['category']}\")\n",
    "        for point in advantage['points']:\n",
    "            print(f\"  ‚úÖ {point}\")\n",
    "\n",
    "def performance_comparison():\n",
    "    \"\"\"Compare performance characteristics\"\"\"\n",
    "    \n",
    "    print(f\"\\nüìà Performance Characteristics\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    comparison = [\n",
    "        {\"metric\": \"Cost per analysis\", \"claude\": \"$0.05-0.50\", \"deepseek\": \"$0.00\"},\n",
    "        {\"metric\": \"Thinking transparency\", \"claude\": \"Summary only\", \"deepseek\": \"Full process\"},\n",
    "        {\"metric\": \"Setup complexity\", \"claude\": \"API key only\", \"deepseek\": \"Local install\"},\n",
    "        {\"metric\": \"Data privacy\", \"claude\": \"Cloud-based\", \"deepseek\": \"Local only\"},\n",
    "        {\"metric\": \"Token limits\", \"claude\": \"Budget required\", \"deepseek\": \"No limits\"},\n",
    "        {\"metric\": \"Availability\", \"claude\": \"Internet required\", \"deepseek\": \"Always local\"}\n",
    "    ]\n",
    "    \n",
    "    print(f\"{'Metric':<20} | {'Claude':<15} | {'DeepSeek-R1':<15}\")\n",
    "    print(\"-\" * 55)\n",
    "    \n",
    "    for comp in comparison:\n",
    "        print(f\"{comp['metric']:<20} | {comp['claude']:<15} | {comp['deepseek']:<15}\")\n",
    "\n",
    "# Run all analyses\n",
    "deepseek_cost_benefits()\n",
    "deepseek_advantages() \n",
    "performance_comparison()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192c8f56",
   "metadata": {},
   "source": [
    "<a id='examples'></a>\n",
    "## 7. Real-World Examples\n",
    "\n",
    "### 7.1 Complex Document Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176e8959",
   "metadata": {},
   "source": [
    "**Yes, these prompting tips are generally valid for DeepSeek-R1**, but with some important modifications:\n",
    "\n",
    "## Prompting Tips: Anthropic vs DeepSeek-R1\n",
    "\n",
    "| **Tip** | **Anthropic Claude** | **DeepSeek-R1** | **Status** |\n",
    "|---------|---------------------|-----------------|------------|\n",
    "| **Be Specific** | ‚úÖ Works well | ‚úÖ Works well | **‚úÖ SAME** |\n",
    "| **Provide Context** | ‚úÖ Important | ‚úÖ Very important | **‚úÖ SAME** |\n",
    "| **Structure Input** | ‚úÖ Helpful | ‚úÖ Helpful | **‚úÖ SAME** |\n",
    "| **Define Success** | ‚úÖ Good practice | ‚úÖ Good practice | **‚úÖ SAME** |\n",
    "| **Avoid Over-Prompting** | ‚úÖ \"Don't say think step by step\" | ‚ùå **Actually HELPFUL for DeepSeek** | **‚ùå DIFFERENT** |\n",
    "\n",
    "## Key Difference: DeepSeek-R1 BENEFITS from Step-by-Step Prompts!## Updated Prompting Tips for DeepSeek-R1:\n",
    "\n",
    "### ‚úÖ **Valid Tips (Same as Anthropic):**\n",
    "1. **Be Specific**: Clearly state what you want analyzed\n",
    "2. **Provide Context**: Include all relevant information  \n",
    "3. **Structure Your Input**: Use clear formatting and sections\n",
    "4. **Define Success Criteria**: Specify what a good answer looks like\n",
    "\n",
    "### ‚ùå **Different for DeepSeek-R1:**\n",
    "5. **DO Use Step-by-Step Prompts**: Unlike Claude, DeepSeek-R1 **benefits** from explicit guidance!\n",
    "\n",
    "## DeepSeek-R1 Enhanced Prompting:\n",
    "\n",
    "### **GOOD Prompts for DeepSeek-R1:**\n",
    "```python\n",
    "# ‚úÖ Excellent for DeepSeek-R1\n",
    "prompt = \"\"\"Analyze this business problem step by step:\n",
    "[problem details]\n",
    "\n",
    "Please:\n",
    "1. Calculate current metrics\n",
    "2. Analyze the proposed changes  \n",
    "3. Show your mathematical work\n",
    "4. Provide a clear recommendation\n",
    "5. Justify your reasoning\n",
    "\n",
    "Think through each step systematically.\"\"\"\n",
    "```\n",
    "\n",
    "### **Avoid for DeepSeek-R1:**\n",
    "```python\n",
    "# ‚ùå Too vague for DeepSeek-R1  \n",
    "prompt = \"What should this company do?\"\n",
    "```\n",
    "\n",
    "## Key Insight:\n",
    "**Claude 4** is optimized to think well automatically, so \"step by step\" is redundant.\n",
    "\n",
    "**DeepSeek-R1** actually **performs better** when you give it explicit thinking structure and mathematical guidance!\n",
    "\n",
    "This is why your converted examples work so well - DeepSeek-R1 loves structured, mathematical, step-by-step reasoning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e34a926f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ DeepSeek-R1 Prompting Best Practices\n",
      "============================================================\n",
      "\n",
      "üìã Testing: Basic Prompt\n",
      "----------------------------------------\n",
      "‚úÖ Thinking: 1,066 chars\n",
      "‚úÖ Answer: 1,097 chars\n",
      "‚úÖ Math concepts: 7\n",
      "\n",
      "üìã Testing: Step-by-Step (GOOD for DeepSeek!)\n",
      "----------------------------------------\n",
      "‚úÖ Thinking: 623 chars\n",
      "‚úÖ Answer: 1,184 chars\n",
      "‚úÖ Math concepts: 7\n",
      "\n",
      "üìã Testing: Structured Analysis\n",
      "----------------------------------------\n",
      "‚úÖ Thinking: 861 chars\n",
      "‚úÖ Answer: 1,981 chars\n",
      "‚úÖ Math concepts: 7\n",
      "\n",
      "üìä PROMPTING APPROACH COMPARISON\n",
      "============================================================\n",
      "Approach                  | Thinking | Answer   | Math\n",
      "-------------------------------------------------------\n",
      "Basic Prompt              |  1,066 |  1,097 |    7\n",
      "Step-by-Step (GOOD for DeepSeek!) |    623 |  1,184 |    7\n",
      "Structured Analysis       |    861 |  1,981 |    7\n",
      "\n",
      "üöÄ DEEPSEEK-R1 SPECIFIC TIPS\n",
      "==================================================\n",
      "\n",
      "‚úÖ DO use 'step by step'\n",
      "   üìù Why: DeepSeek-R1 benefits from structured thinking guidance\n",
      "   üí° Example: 'Think through this step by step: 1. Calculate... 2. Analyze...'\n",
      "\n",
      "‚úÖ DO request detailed math\n",
      "   üìù Why: DeepSeek-R1 excels at mathematical reasoning\n",
      "   üí° Example: 'Show your calculations and mathematical work clearly'\n",
      "\n",
      "‚úÖ DO use explicit structure\n",
      "   üìù Why: Helps organize the thinking process\n",
      "   üí° Example: 'Please provide: Analysis, Calculations, Recommendation'\n",
      "\n",
      "‚úÖ DO ask for reasoning\n",
      "   üìù Why: Makes the thinking process more comprehensive\n",
      "   üí° Example: 'Explain your reasoning and justify your conclusions'\n",
      "\n",
      "‚ùå DON'T assume automatic optimization\n",
      "   üìù Why: Unlike Claude 4, explicit guidance helps\n",
      "   üí° Example: Be specific about what you want analyzed\n",
      "\n",
      "üîÑ ANTHROPIC vs DEEPSEEK PROMPTING\n",
      "==================================================\n",
      "Aspect               | Anthropic            | DeepSeek-R1         \n",
      "-----------------------------------------------------------------\n",
      "'Think step by step' | ‚ùå Avoid (redundant)  | ‚úÖ Helpful (guides thinking)\n",
      "Reason:              | Different thinking architectures\n",
      "\n",
      "Mathematical requests | ‚úÖ Good               | ‚úÖ Excellent (specialty)\n",
      "Reason:              | DeepSeek-R1 optimized for reasoning\n",
      "\n",
      "Structured prompts   | ‚úÖ Helpful            | ‚úÖ Very helpful      \n",
      "Reason:              | Both benefit from clear structure\n",
      "\n",
      "Context provision    | ‚úÖ Important          | ‚úÖ Critical          \n",
      "Reason:              | Local models need more guidance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_prompting_approaches():\n",
    "    \"\"\"Test different prompting approaches with DeepSeek-R1\"\"\"\n",
    "    \n",
    "    print(\"üéØ DeepSeek-R1 Prompting Best Practices\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Test problem\n",
    "    base_problem = \"\"\"A company has revenue of $500,000, costs of $300,000, \n",
    "    and wants to expand. The expansion will cost $100,000 and increase \n",
    "    revenue by 40% while increasing costs by 25%. Should they expand?\"\"\"\n",
    "    \n",
    "    # Different prompting approaches\n",
    "    approaches = [\n",
    "        {\n",
    "            \"name\": \"Basic Prompt\",\n",
    "            \"prompt\": base_problem\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Step-by-Step (GOOD for DeepSeek!)\",\n",
    "            \"prompt\": f\"\"\"{base_problem}\n",
    "            \n",
    "            Please think through this step by step:\n",
    "            1. Calculate current profit\n",
    "            2. Calculate post-expansion revenue and costs  \n",
    "            3. Calculate new profit\n",
    "            4. Analyze the financial impact\n",
    "            5. Make a recommendation\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Structured Analysis\",\n",
    "            \"prompt\": f\"\"\"{base_problem}\n",
    "            \n",
    "            Please provide:\n",
    "            ‚Ä¢ Current Financial Analysis\n",
    "            ‚Ä¢ Expansion Impact Calculations  \n",
    "            ‚Ä¢ Risk Assessment\n",
    "            ‚Ä¢ Final Recommendation with Justification\n",
    "            \n",
    "            Show your mathematical work clearly.\"\"\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for approach in approaches:\n",
    "        print(f\"\\nüìã Testing: {approach['name']}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        try:\n",
    "            response = client.chat(\n",
    "                model='deepseek-r1:14b',\n",
    "                messages=[{\"role\": \"user\", \"content\": approach['prompt']}],\n",
    "                stream=False\n",
    "            )\n",
    "            \n",
    "            full_response = response.get('message', {}).get('content', '')\n",
    "            \n",
    "            # Analyze response quality\n",
    "            thinking_length = 0\n",
    "            answer_length = len(full_response)\n",
    "            \n",
    "            if '<think>' in full_response and '</think>' in full_response:\n",
    "                thinking_start = full_response.find('<think>') + 7\n",
    "                thinking_end = full_response.find('</think>')\n",
    "                thinking_length = len(full_response[thinking_start:thinking_end])\n",
    "                answer_length = len(full_response[thinking_end + 8:])\n",
    "            \n",
    "            # Count mathematical concepts\n",
    "            math_keywords = ['calculate', 'profit', 'revenue', 'cost', '$', '%', 'increase']\n",
    "            math_count = sum(1 for kw in math_keywords if kw.lower() in full_response.lower())\n",
    "            \n",
    "            result = {\n",
    "                \"approach\": approach['name'],\n",
    "                \"thinking_length\": thinking_length,\n",
    "                \"answer_length\": answer_length,\n",
    "                \"total_length\": len(full_response),\n",
    "                \"math_concepts\": math_count,\n",
    "                \"has_thinking\": thinking_length > 0\n",
    "            }\n",
    "            results.append(result)\n",
    "            \n",
    "            print(f\"‚úÖ Thinking: {thinking_length:,} chars\")\n",
    "            print(f\"‚úÖ Answer: {answer_length:,} chars\") \n",
    "            print(f\"‚úÖ Math concepts: {math_count}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "    \n",
    "    # Compare results\n",
    "    print(f\"\\nüìä PROMPTING APPROACH COMPARISON\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"{'Approach':<25} | {'Thinking':<8} | {'Answer':<8} | {'Math':<4}\")\n",
    "    print(\"-\" * 55)\n",
    "    \n",
    "    for result in results:\n",
    "        if result['has_thinking']:\n",
    "            print(f\"{result['approach']:<25} | {result['thinking_length']:>6,} | {result['answer_length']:>6,} | {result['math_concepts']:>4}\")\n",
    "        else:\n",
    "            print(f\"{result['approach']:<25} | {'No':>6} | {result['total_length']:>6,} | {result['math_concepts']:>4}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def deepseek_specific_tips():\n",
    "    \"\"\"DeepSeek-R1 specific prompting guidelines\"\"\"\n",
    "    \n",
    "    print(f\"\\nüöÄ DEEPSEEK-R1 SPECIFIC TIPS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    tips = [\n",
    "        {\n",
    "            \"tip\": \"‚úÖ DO use 'step by step'\",\n",
    "            \"reason\": \"DeepSeek-R1 benefits from structured thinking guidance\",\n",
    "            \"example\": \"'Think through this step by step: 1. Calculate... 2. Analyze...'\"\n",
    "        },\n",
    "        {\n",
    "            \"tip\": \"‚úÖ DO request detailed math\", \n",
    "            \"reason\": \"DeepSeek-R1 excels at mathematical reasoning\",\n",
    "            \"example\": \"'Show your calculations and mathematical work clearly'\"\n",
    "        },\n",
    "        {\n",
    "            \"tip\": \"‚úÖ DO use explicit structure\",\n",
    "            \"reason\": \"Helps organize the thinking process\", \n",
    "            \"example\": \"'Please provide: Analysis, Calculations, Recommendation'\"\n",
    "        },\n",
    "        {\n",
    "            \"tip\": \"‚úÖ DO ask for reasoning\",\n",
    "            \"reason\": \"Makes the thinking process more comprehensive\",\n",
    "            \"example\": \"'Explain your reasoning and justify your conclusions'\"\n",
    "        },\n",
    "        {\n",
    "            \"tip\": \"‚ùå DON'T assume automatic optimization\",\n",
    "            \"reason\": \"Unlike Claude 4, explicit guidance helps\",\n",
    "            \"example\": \"Be specific about what you want analyzed\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for tip in tips:\n",
    "        print(f\"\\n{tip['tip']}\")\n",
    "        print(f\"   üìù Why: {tip['reason']}\")  \n",
    "        print(f\"   üí° Example: {tip['example']}\")\n",
    "\n",
    "def anthropic_vs_deepseek_prompting():\n",
    "    \"\"\"Key differences in prompting approaches\"\"\"\n",
    "    \n",
    "    print(f\"\\nüîÑ ANTHROPIC vs DEEPSEEK PROMPTING\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    differences = [\n",
    "        {\n",
    "            \"aspect\": \"'Think step by step'\",\n",
    "            \"anthropic\": \"‚ùå Avoid (redundant)\",\n",
    "            \"deepseek\": \"‚úÖ Helpful (guides thinking)\",\n",
    "            \"reason\": \"Different thinking architectures\"\n",
    "        },\n",
    "        {\n",
    "            \"aspect\": \"Mathematical requests\",\n",
    "            \"anthropic\": \"‚úÖ Good\",\n",
    "            \"deepseek\": \"‚úÖ Excellent (specialty)\",\n",
    "            \"reason\": \"DeepSeek-R1 optimized for reasoning\"\n",
    "        },\n",
    "        {\n",
    "            \"aspect\": \"Structured prompts\", \n",
    "            \"anthropic\": \"‚úÖ Helpful\",\n",
    "            \"deepseek\": \"‚úÖ Very helpful\",\n",
    "            \"reason\": \"Both benefit from clear structure\"\n",
    "        },\n",
    "        {\n",
    "            \"aspect\": \"Context provision\",\n",
    "            \"anthropic\": \"‚úÖ Important\", \n",
    "            \"deepseek\": \"‚úÖ Critical\",\n",
    "            \"reason\": \"Local models need more guidance\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(f\"{'Aspect':<20} | {'Anthropic':<20} | {'DeepSeek-R1':<20}\")\n",
    "    print(\"-\" * 65)\n",
    "    \n",
    "    for diff in differences:\n",
    "        print(f\"{diff['aspect']:<20} | {diff['anthropic']:<20} | {diff['deepseek']:<20}\")\n",
    "        print(f\"{'Reason:':<20} | {diff['reason']}\")\n",
    "        print()\n",
    "\n",
    "# Run the tests\n",
    "results = test_prompting_approaches()\n",
    "deepseek_specific_tips()\n",
    "anthropic_vs_deepseek_prompting()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d449fc4d",
   "metadata": {},
   "source": [
    "Here's the migrated version optimized for DeepSeek-R1:## Key Changes in the Migration:\n",
    "\n",
    "### 1. **Removed Anthropic-Specific Code:**\n",
    "```python\n",
    "# ‚ùå Anthropic (removed)\n",
    "response = client.messages.create(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    max_tokens=15000,\n",
    "    thinking={\"type\": \"enabled\", \"budget_tokens\": 12000},\n",
    "    messages=[{\"role\": \"user\", \"content\": good_prompt}]\n",
    ")\n",
    "\n",
    "# ‚úÖ DeepSeek-R1 (new)\n",
    "response = client.chat(\n",
    "    model='deepseek-r1:14b',\n",
    "    messages=[{\"role\": \"user\", \"content\": good_prompt}],\n",
    "    stream=False\n",
    ")\n",
    "```\n",
    "\n",
    "### 2. **Enhanced Prompt for DeepSeek-R1:**\n",
    "- Added **\"step by step\"** guidance (helpful for DeepSeek!)\n",
    "- Requested **mathematical calculations** (DeepSeek's strength)\n",
    "- Added **explicit thinking instructions**\n",
    "- Structured the analysis requirements more clearly\n",
    "\n",
    "### 3. **Better Response Parsing:**\n",
    "```python\n",
    "# Parse <think>...</think> tags instead of response.content blocks\n",
    "if '<think>' in full_response and '</think>' in full_response:\n",
    "    thinking_content = # extract thinking\n",
    "    final_answer = # extract answer\n",
    "```\n",
    "\n",
    "### 4. **Added DeepSeek-Specific Features:**\n",
    "- **Thinking analysis metrics**\n",
    "- **Financial concept detection**\n",
    "- **Mathematical analysis verification**\n",
    "- **Enhanced prompting examples**\n",
    "\n",
    "## Why This Migration is Better:\n",
    "\n",
    "| **Aspect** | **Original (Anthropic)** | **Migrated (DeepSeek-R1)** |\n",
    "|------------|--------------------------|----------------------------|\n",
    "| **Cost** | ~$0.20 per analysis | **FREE** |\n",
    "| **Thinking Visibility** | Summarized | **Full process shown** |\n",
    "| **Mathematical Focus** | Good | **Excellent** |\n",
    "| **Step-by-step Guidance** | Avoided | **Encouraged** |\n",
    "| **Token Management** | Required | **Not needed** |\n",
    "\n",
    "The migrated version takes advantage of DeepSeek-R1's strengths:\n",
    "- üßÆ **Mathematical reasoning**\n",
    "- üìä **Step-by-step analysis** \n",
    "- üí∞ **Free unlimited usage**\n",
    "- üîç **Complete thinking transparency**\n",
    "\n",
    "**Copy this code and run it** - you'll see DeepSeek-R1 provide incredibly detailed financial analysis with full mathematical reasoning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a8b1926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Best Practices Example: Structured Investment Analysis\n",
      "============================================================\n",
      "\n",
      "üß† THINKING PROCESS:\n",
      "========================================\n",
      "Alright, so I have this investment decision to make based on three options: a stock portfolio, real estate, and bonds. The goal is to recommend the best choice for someone looking to save for retirement over 15 years with $75,000. Let me think through each step carefully.\n",
      "\n",
      "First, I need to understand each option's potential returns. Option A is a stock portfolio with an expected annual return of 8%. That sounds pretty good because stocks usually have higher returns over the long term. But it's high risk, which might worry someone who isn't too comfortable with volatility. The minimum investment is $10,000, so if they're investing $75k, that's doable.\n",
      "\n",
      "Option B is real estate with a 6% return. It's medium risk, which fits the investor's profile since their tolerance is also medium. But it requires a higher minimum of $50k and has low liquidity, meaning you can't just sell it quickly if needed. That might be an issue depending on their financial situation.\n",
      "\n",
      "Option C is bonds with 4% retu...\n",
      "\n",
      "üí° INVESTMENT ANALYSIS:\n",
      "========================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "To determine the best investment strategy for the given profile, we'll allocate funds across all three options to achieve a balance between return and risk.\n",
       "\n",
       "### Investment Allocation:\n",
       "- **Stock Portfolio (Option A):** $20,000\n",
       "- **Real Estate (Option B):** $50,000\n",
       "- **Bonds (Option C):** $5,000\n",
       "\n",
       "### Justification:\n",
       "1. **Risk Management:** Allocating 66.7% to real estate (medium risk) and 26.7% to stocks (high risk) balances the portfolio with a focus on moderate growth while ensuring some capital is in low-risk bonds.\n",
       "2. **Return Optimization:** Stocks provide higher returns, real estate offers stable growth, and bonds ensure capital security.\n",
       "3. **Liquidity:** Stocks and bonds maintain liquidity, while real estate serves as a long-term investment.\n",
       "\n",
       "### Future Value Calculation:\n",
       "- **Stocks ($20k):** ~$63,600\n",
       "- **Real Estate ($50k):** ~$119,800\n",
       "- **Bonds ($5k):** ~$8,980\n",
       "\n",
       "### Total Future Value: Approximately $192,380\n",
       "\n",
       "This balanced approach aligns with the investor's medium risk tolerance and long-term retirement goals."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä ANALYSIS METRICS:\n",
      "------------------------------\n",
      "Thinking depth: 10,285 characters\n",
      "Final analysis: 1,034 characters\n",
      "Financial concepts analyzed: ['return', 'risk', 'diversification', 'allocation', 'portfolio', 'liquidity']\n",
      "Mathematical analysis present: True\n",
      "\n",
      "üöÄ ENHANCED DEEPSEEK-R1 PROMPTING\n",
      "============================================================\n",
      "Enhanced prompt generated 6,400 characters of thinking\n",
      "üìã Enhanced analysis completed - check for:\n",
      "   ‚úÖ Step-by-step mathematical calculations\n",
      "   ‚úÖ Specific dollar amounts and allocations\n",
      "   ‚úÖ Risk assessment for 5-year timeline\n",
      "   ‚úÖ Contingency planning\n",
      "\n",
      "‚öñÔ∏è  PROMPTING STYLE COMPARISON\n",
      "============================================================\n",
      "\n",
      "üìù Basic Style:\n",
      "   Prompt: Should I invest in stocks or bonds for retirement?...\n",
      "   Expected: Generic advice, minimal thinking\n",
      "\n",
      "üìù Structured Style:\n",
      "   Prompt: Compare stocks vs bonds for retirement:\n",
      "            - Time horizon: 25 years\n",
      "            - Risk tole...\n",
      "   Expected: Better analysis, some thinking\n",
      "\n",
      "üìù DeepSeek-Optimized Style:\n",
      "   Prompt: Investment analysis request:\n",
      "\n",
      "            PROFILE: 40 years old, 25-year horizon, medium risk tolera...\n",
      "   Expected: Comprehensive analysis, extensive thinking\n",
      "\n",
      "üí° KEY INSIGHT:\n",
      "   DeepSeek-R1 performs significantly better with structured,\n",
      "   mathematical, step-by-step prompts compared to basic requests.\n"
     ]
    }
   ],
   "source": [
    "def prompting_best_practices():\n",
    "    \"\"\"Demonstrate effective prompting strategies for DeepSeek-R1\"\"\"\n",
    "    \n",
    "    # Enhanced prompt - optimized for DeepSeek-R1's strengths\n",
    "    good_prompt = \"\"\"Analyze the following investment options and recommend the best choice:\n",
    "\n",
    "Option A: Stock Portfolio\n",
    "- Expected annual return: 8%\n",
    "- Risk level: High\n",
    "- Minimum investment: $10,000\n",
    "- Liquidity: High (can sell anytime)\n",
    "\n",
    "Option B: Real Estate\n",
    "- Expected annual return: 6%\n",
    "- Risk level: Medium\n",
    "- Minimum investment: $50,000\n",
    "- Liquidity: Low (takes months to sell)\n",
    "\n",
    "Option C: Bonds\n",
    "- Expected annual return: 4%\n",
    "- Risk level: Low\n",
    "- Minimum investment: $5,000\n",
    "- Liquidity: Medium\n",
    "\n",
    "Investor Profile:\n",
    "- Age: 35\n",
    "- Investment horizon: 15 years\n",
    "- Risk tolerance: Medium\n",
    "- Available capital: $75,000\n",
    "- Goal: Retirement savings\n",
    "\n",
    "Please analyze this systematically, step by step:\n",
    "\n",
    "1. Calculate potential returns for each option over 15 years\n",
    "2. Assess risk-adjusted returns considering the investor profile\n",
    "3. Evaluate diversification opportunities within the $75,000 budget\n",
    "4. Consider liquidity needs and timeline alignment\n",
    "5. Factor in the medium risk tolerance\n",
    "\n",
    "Please provide:\n",
    "1. Mathematical analysis of each option (show calculations)\n",
    "2. Recommended portfolio allocation with specific dollar amounts\n",
    "3. Detailed justification for your recommendation\n",
    "4. Risk assessment and mitigation strategies\n",
    "\n",
    "Think through the mathematical implications carefully and show your reasoning process.\"\"\"\n",
    "    \n",
    "    # DeepSeek-R1 doesn't need token budgets - thinking is automatic and free!\n",
    "    response = client.chat(\n",
    "        model='deepseek-r1:14b',\n",
    "        messages=[{\"role\": \"user\", \"content\": good_prompt}],\n",
    "        stream=False  # Set to True if you want to see thinking in real-time\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Best Practices Example: Structured Investment Analysis\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Get the full response\n",
    "    full_response = response.get('message', {}).get('content', '')\n",
    "    \n",
    "    # Parse thinking and final answer for better display\n",
    "    if '<think>' in full_response and '</think>' in full_response:\n",
    "        thinking_start = full_response.find('<think>') + 7\n",
    "        thinking_end = full_response.find('</think>')\n",
    "        thinking_content = full_response[thinking_start:thinking_end].strip()\n",
    "        final_answer = full_response[thinking_end + 8:].strip()\n",
    "        \n",
    "        print(\"\\nüß† THINKING PROCESS:\")\n",
    "        print(\"=\" * 40)\n",
    "        # Show key parts of thinking (first 1000 chars for readability)\n",
    "        thinking_preview = thinking_content[:1000] + \"...\" if len(thinking_content) > 1000 else thinking_content\n",
    "        print(thinking_preview)\n",
    "        \n",
    "        print(f\"\\nüí° INVESTMENT ANALYSIS:\")\n",
    "        print(\"=\" * 40)\n",
    "        display(Markdown(final_answer))\n",
    "        \n",
    "        # Analysis metrics\n",
    "        print(f\"\\nüìä ANALYSIS METRICS:\")\n",
    "        print(\"-\" * 30)\n",
    "        print(f\"Thinking depth: {len(thinking_content):,} characters\")\n",
    "        print(f\"Final analysis: {len(final_answer):,} characters\")\n",
    "        \n",
    "        # Check for key financial concepts\n",
    "        financial_concepts = ['return', 'risk', 'diversification', 'allocation', 'portfolio', 'liquidity']\n",
    "        found_concepts = [concept for concept in financial_concepts \n",
    "                         if concept.lower() in thinking_content.lower()]\n",
    "        print(f\"Financial concepts analyzed: {found_concepts}\")\n",
    "        \n",
    "        # Check for mathematical analysis\n",
    "        math_indicators = ['calculate', '%', '$', 'years', 'multiply', 'divide']\n",
    "        math_found = [indicator for indicator in math_indicators \n",
    "                     if indicator in full_response.lower()]\n",
    "        print(f\"Mathematical analysis present: {len(math_found) > 0}\")\n",
    "        \n",
    "    else:\n",
    "        # If no thinking block (unusual for complex problems)\n",
    "        print(\"\\nüí° INVESTMENT ANALYSIS:\")\n",
    "        print(\"=\" * 40)\n",
    "        display(Markdown(full_response))\n",
    "    \n",
    "    return full_response\n",
    "\n",
    "def enhanced_prompting_example():\n",
    "    \"\"\"Show enhanced prompting techniques specific to DeepSeek-R1\"\"\"\n",
    "    \n",
    "    print(\"\\nüöÄ ENHANCED DEEPSEEK-R1 PROMPTING\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Example with even more structure for DeepSeek-R1\n",
    "    enhanced_prompt = \"\"\"You are a financial advisor. A client needs investment advice.\n",
    "\n",
    "CLIENT DATA:\n",
    "- Age: 28\n",
    "- Annual income: $85,000  \n",
    "- Current savings: $40,000\n",
    "- Monthly savings capacity: $2,000\n",
    "- Risk tolerance: Aggressive (young, high income growth potential)\n",
    "- Goals: Buy house in 5 years ($50,000 down payment needed)\n",
    "\n",
    "INVESTMENT OPTIONS:\n",
    "1. High-growth index funds (10% expected return, high volatility)\n",
    "2. Balanced mutual funds (7% expected return, medium volatility)  \n",
    "3. CDs/High-yield savings (3% expected return, no volatility)\n",
    "4. Individual stocks (12% potential return, very high risk)\n",
    "\n",
    "ANALYSIS FRAMEWORK:\n",
    "Step 1: Calculate monthly investment needed to reach $50,000 in 5 years for each option\n",
    "Step 2: Assess probability of reaching goal with each strategy\n",
    "Step 3: Evaluate risk vs. timeline appropriateness\n",
    "Step 4: Consider diversification strategies\n",
    "Step 5: Account for inflation and taxes\n",
    "\n",
    "OUTPUT REQUIREMENTS:\n",
    "- Show all mathematical calculations\n",
    "- Provide specific dollar allocations\n",
    "- Include contingency planning\n",
    "- Explain reasoning for each decision\n",
    "- Address potential risks and mitigation\n",
    "\n",
    "Please work through this systematically, showing your mathematical work at each step.\"\"\"\n",
    "    \n",
    "    response = client.chat(\n",
    "        model='deepseek-r1:14b',\n",
    "        messages=[{\"role\": \"user\", \"content\": enhanced_prompt}],\n",
    "        stream=False\n",
    "    )\n",
    "    \n",
    "    full_response = response.get('message', {}).get('content', '')\n",
    "    \n",
    "    # Quick analysis of response quality\n",
    "    if '<think>' in full_response:\n",
    "        thinking_length = len(full_response[full_response.find('<think>'):full_response.find('</think>')])\n",
    "        print(f\"Enhanced prompt generated {thinking_length:,} characters of thinking\")\n",
    "    \n",
    "    print(\"üìã Enhanced analysis completed - check for:\")\n",
    "    print(\"   ‚úÖ Step-by-step mathematical calculations\")\n",
    "    print(\"   ‚úÖ Specific dollar amounts and allocations\") \n",
    "    print(\"   ‚úÖ Risk assessment for 5-year timeline\")\n",
    "    print(\"   ‚úÖ Contingency planning\")\n",
    "    \n",
    "    return full_response\n",
    "\n",
    "def compare_prompting_styles():\n",
    "    \"\"\"Compare basic vs enhanced prompting for DeepSeek-R1\"\"\"\n",
    "    \n",
    "    print(\"\\n‚öñÔ∏è  PROMPTING STYLE COMPARISON\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    styles = [\n",
    "        {\n",
    "            \"name\": \"Basic Style\",\n",
    "            \"prompt\": \"Should I invest in stocks or bonds for retirement?\",\n",
    "            \"expected\": \"Generic advice, minimal thinking\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Structured Style\", \n",
    "            \"prompt\": \"\"\"Compare stocks vs bonds for retirement:\n",
    "            - Time horizon: 25 years\n",
    "            - Risk tolerance: Medium\n",
    "            - Current age: 40\n",
    "            \n",
    "            Please analyze expected returns, risks, and provide recommendation.\"\"\",\n",
    "            \"expected\": \"Better analysis, some thinking\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"DeepSeek-Optimized Style\",\n",
    "            \"prompt\": \"\"\"Investment analysis request:\n",
    "\n",
    "            PROFILE: 40 years old, 25-year horizon, medium risk tolerance\n",
    "            OPTIONS: Stocks (8% return, high volatility) vs Bonds (4% return, low volatility)\n",
    "            \n",
    "            ANALYSIS STEPS:\n",
    "            1. Calculate compound growth over 25 years for each\n",
    "            2. Assess volatility impact on different life stages  \n",
    "            3. Determine optimal allocation percentages\n",
    "            4. Factor in rebalancing strategies\n",
    "            \n",
    "            Show mathematical calculations and reasoning process.\"\"\",\n",
    "            \"expected\": \"Comprehensive analysis, extensive thinking\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for style in styles:\n",
    "        print(f\"\\nüìù {style['name']}:\")\n",
    "        print(f\"   Prompt: {style['prompt'][:100]}...\")\n",
    "        print(f\"   Expected: {style['expected']}\")\n",
    "    \n",
    "    print(f\"\\nüí° KEY INSIGHT:\")\n",
    "    print(f\"   DeepSeek-R1 performs significantly better with structured,\")\n",
    "    print(f\"   mathematical, step-by-step prompts compared to basic requests.\")\n",
    "\n",
    "# Run the examples\n",
    "result = prompting_best_practices()\n",
    "enhanced_result = enhanced_prompting_example()\n",
    "compare_prompting_styles()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e8af84",
   "metadata": {},
   "source": [
    "### 7.2 Code Architecture Planning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941f3788",
   "metadata": {},
   "source": [
    "<a id='performance'></a>\n",
    "## 8. Performance and Cost Considerations\n",
    "\n",
    "### Understanding Token Usage and Costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0c2f89",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26f0b239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§î DeepSeek's Thinking Process:\n",
      "--------------------------------------------------\n",
      "To multiply 27 by 453, I'll start by breaking down the multiplication into smaller steps to make it easier.\n",
      "\n",
      "First, I'll multiply 27 by each digit of 453 separately, starting from the units place.\n",
      "\n",
      "I'll multiply 27 by 3, which gives me 81. Then, I'll multiply 27 by 5 (tens place), resulting in 135, and since it's the tens place, I'll add a zero to make it 1350.\n",
      "\n",
      "Next, I'll multiply 27 by 4 (hundreds place), which equals 108, and then add two zeros to get 10800.\n",
      "\n",
      "Finally, I'll add all these partial results together: 81 + 1350 + 10800. Adding them step by step gives me a total of 12,231.\n",
      "--------------------------------------------------\n",
      "\n",
      "‚úÖ Final Answer:\n",
      "To calculate \\(27 \\times 453\\), follow these easy-to-understand steps:\n",
      "\n",
      "### Step 1: Break Down the Multiplication\n",
      "We can break down the multiplication to make it simpler:\n",
      "\n",
      "\\[\n",
      "27 \\times 453 = 27 \\times (400 + 50 + 3)\n",
      "\\]\n",
      "\n",
      "### Step 2: Multiply Each Part Separately\n",
      "\n",
      "1. **Multiply by 400:**\n",
      "   \\[\n",
      "   27 \\times 400 = 27 \\times 4 \\times 100 = 108 \\times 100 = 10,\\!800\n",
      "   \\]\n",
      "\n",
      "2. **Multiply by 50:**\n",
      "   \\[\n",
      "   27 \\times 50 = 27 \\times 5 \\times 10 = 135 \\times 10 = 1,\\!350\n",
      "   \\]\n",
      "\n",
      "3. **Multiply by 3:**\n",
      "   \\[\n",
      "   27 \\times 3 = 81\n",
      "   \\]\n",
      "\n",
      "### Step 3: Add All the Results Together\n",
      "\n",
      "\\[\n",
      "10,\\!800 + 1,\\!350 + 81 = 12,\\!231\n",
      "\\]\n",
      "\n",
      "### Final Answer\n",
      "\n",
      "\\[\n",
      "\\boxed{12,\\!231}\n",
      "\\]\n",
      "\n",
      "üöÄ DeepSeek-R1 Advantages Demo\n",
      "==================================================\n",
      "Feature            | Claude                              | DeepSeek-R1\n",
      "--------------------------------------------------------------------------------\n",
      "Token Management   | ‚ùå Must calculate budget_tokens < max_tokens | ‚úÖ No token management needed\n",
      "Cost               | üí∞ ~$0.01-0.10 per thinking session  | üí∞ FREE unlimited thinking\n",
      "Thinking Visibility | üìù Summarized thinking only          | üìù Complete thinking process\n",
      "Setup Complexity   | ‚öôÔ∏è API key + token budget management | ‚öôÔ∏è One-time local setup\n",
      "Rate Limits        | ‚è∞ API rate limits apply             | ‚è∞ No limits - local inference\n",
      "\n",
      "‚öñÔ∏è  SIDE-BY-SIDE CODE COMPARISON\n",
      "============================================================\n",
      "üìã CLAUDE THINKING CODE:\n",
      "------------------------------\n",
      "\n",
      "# Claude requires careful token management\n",
      "response = client.messages.create(\n",
      "    model=\"claude-3-5-sonnet-20241022\",\n",
      "    max_tokens=6000,  # Must be > budget_tokens\n",
      "    thinking={\n",
      "        \"type\": \"enabled\", \n",
      "        \"budget_tokens\": 5000  # Costs money\n",
      "    },\n",
      "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
      ")\n",
      "\n",
      "# Parse response blocks\n",
      "for block in response.content:\n",
      "    if block.type == \"thinking\":\n",
      "        print(block.thinking)  # Summarized\n",
      "    elif block.type == \"text\":\n",
      "        print(block.text)\n",
      "\n",
      "\n",
      "üìã DEEPSEEK-R1 CODE:\n",
      "------------------------------\n",
      "\n",
      "# DeepSeek-R1 is much simpler\n",
      "response = client.chat(\n",
      "    model='deepseek-r1:14b',\n",
      "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
      "    stream=False  # Optional: True for real-time\n",
      ")\n",
      "\n",
      "# Parse <think> tags\n",
      "full_response = response.get('message', {}).get('content', '')\n",
      "if '<think>' in full_response:\n",
      "    # Extract complete thinking process\n",
      "    thinking = extract_thinking(full_response)  # Full detail\n",
      "    answer = extract_answer(full_response)\n",
      "\n",
      "\n",
      "üí° KEY DIFFERENCES:\n",
      "   ‚Ä¢ Claude: Complex token management, costs money\n",
      "   ‚Ä¢ DeepSeek: Simple setup, completely free\n",
      "   ‚Ä¢ Claude: Summarized thinking\n",
      "   ‚Ä¢ DeepSeek: Complete thinking process\n"
     ]
    }
   ],
   "source": [
    "def basic_thinking_example():\n",
    "    \"\"\"DeepSeek-R1 version - no token management needed!\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # ‚úÖ DeepSeek-R1: No token budgets needed - thinking is automatic and unlimited!\n",
    "        response = client.chat(\n",
    "            model='deepseek-r1:14b',\n",
    "            messages=[{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What is 27 * 453? Show me how you calculate this step by step.\"\n",
    "            }],\n",
    "            stream=False\n",
    "        )\n",
    "        \n",
    "        # Get the full response\n",
    "        full_response = response.get('message', {}).get('content', '')\n",
    "        \n",
    "        # Process DeepSeek-R1's <think> tags\n",
    "        if '<think>' in full_response and '</think>' in full_response:\n",
    "            thinking_start = full_response.find('<think>') + 7\n",
    "            thinking_end = full_response.find('</think>')\n",
    "            thinking_content = full_response[thinking_start:thinking_end].strip()\n",
    "            final_answer = full_response[thinking_end + 8:].strip()\n",
    "            \n",
    "            print(\"ü§î DeepSeek's Thinking Process:\")\n",
    "            print(\"-\" * 50)\n",
    "            print(thinking_content)\n",
    "            print(\"-\" * 50)\n",
    "            print()\n",
    "            print(\"‚úÖ Final Answer:\")\n",
    "            print(final_answer)\n",
    "            \n",
    "        else:\n",
    "            print(\"‚úÖ DeepSeek's Response:\")\n",
    "            print(full_response)\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå DeepSeek-R1 error: {str(e)}\")\n",
    "        print(\"Troubleshooting:\")\n",
    "        print(\"1. Check Ollama is running: ollama list\")\n",
    "        print(\"2. Verify model: ollama show deepseek-r1:14b\")\n",
    "        print(\"3. Test connection: curl http://localhost:11434/api/tags\")\n",
    "\n",
    "def deepseek_advantages_demo():\n",
    "    \"\"\"Demonstrate DeepSeek-R1 advantages over Claude thinking\"\"\"\n",
    "    \n",
    "    print(\"\\nüöÄ DeepSeek-R1 Advantages Demo\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    advantages = [\n",
    "        {\n",
    "            \"feature\": \"Token Management\",\n",
    "            \"claude\": \"‚ùå Must calculate budget_tokens < max_tokens\",\n",
    "            \"deepseek\": \"‚úÖ No token management needed\"\n",
    "        },\n",
    "        {\n",
    "            \"feature\": \"Cost\",\n",
    "            \"claude\": \"üí∞ ~$0.01-0.10 per thinking session\",\n",
    "            \"deepseek\": \"üí∞ FREE unlimited thinking\"\n",
    "        },\n",
    "        {\n",
    "            \"feature\": \"Thinking Visibility\", \n",
    "            \"claude\": \"üìù Summarized thinking only\",\n",
    "            \"deepseek\": \"üìù Complete thinking process\"\n",
    "        },\n",
    "        {\n",
    "            \"feature\": \"Setup Complexity\",\n",
    "            \"claude\": \"‚öôÔ∏è API key + token budget management\",\n",
    "            \"deepseek\": \"‚öôÔ∏è One-time local setup\"\n",
    "        },\n",
    "        {\n",
    "            \"feature\": \"Rate Limits\",\n",
    "            \"claude\": \"‚è∞ API rate limits apply\",\n",
    "            \"deepseek\": \"‚è∞ No limits - local inference\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(f\"{'Feature':<18} | {'Claude':<35} | {'DeepSeek-R1'}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for adv in advantages:\n",
    "        print(f\"{adv['feature']:<18} | {adv['claude']:<35} | {adv['deepseek']}\")\n",
    "\n",
    "def side_by_side_comparison():\n",
    "    \"\"\"Show equivalent functionality side by side\"\"\"\n",
    "    \n",
    "    print(f\"\\n‚öñÔ∏è  SIDE-BY-SIDE CODE COMPARISON\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(\"üìã CLAUDE THINKING CODE:\")\n",
    "    print(\"-\" * 30)\n",
    "    claude_code = '''\n",
    "# Claude requires careful token management\n",
    "response = client.messages.create(\n",
    "    model=\"claude-3-5-sonnet-20241022\",\n",
    "    max_tokens=6000,  # Must be > budget_tokens\n",
    "    thinking={\n",
    "        \"type\": \"enabled\", \n",
    "        \"budget_tokens\": 5000  # Costs money\n",
    "    },\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")\n",
    "\n",
    "# Parse response blocks\n",
    "for block in response.content:\n",
    "    if block.type == \"thinking\":\n",
    "        print(block.thinking)  # Summarized\n",
    "    elif block.type == \"text\":\n",
    "        print(block.text)\n",
    "'''\n",
    "    print(claude_code)\n",
    "    \n",
    "    print(\"\\nüìã DEEPSEEK-R1 CODE:\")\n",
    "    print(\"-\" * 30)\n",
    "    deepseek_code = '''\n",
    "# DeepSeek-R1 is much simpler\n",
    "response = client.chat(\n",
    "    model='deepseek-r1:14b',\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    stream=False  # Optional: True for real-time\n",
    ")\n",
    "\n",
    "# Parse <think> tags\n",
    "full_response = response.get('message', {}).get('content', '')\n",
    "if '<think>' in full_response:\n",
    "    # Extract complete thinking process\n",
    "    thinking = extract_thinking(full_response)  # Full detail\n",
    "    answer = extract_answer(full_response)\n",
    "'''\n",
    "    print(deepseek_code)\n",
    "    \n",
    "    print(f\"\\nüí° KEY DIFFERENCES:\")\n",
    "    print(f\"   ‚Ä¢ Claude: Complex token management, costs money\")\n",
    "    print(f\"   ‚Ä¢ DeepSeek: Simple setup, completely free\")\n",
    "    print(f\"   ‚Ä¢ Claude: Summarized thinking\")  \n",
    "    print(f\"   ‚Ä¢ DeepSeek: Complete thinking process\")\n",
    "\n",
    "# Run the DeepSeek example\n",
    "basic_thinking_example()\n",
    "deepseek_advantages_demo()\n",
    "side_by_side_comparison()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2384ac0",
   "metadata": {},
   "source": [
    "## Markdown Explanation: Claude Cost Analysis vs DeepSeek-R1\n",
    "\n",
    "```markdown\n",
    "# üí∞ Cost Analysis: Claude Extended Thinking vs DeepSeek-R1\n",
    "\n",
    "## Claude's Cost Structure\n",
    "\n",
    "**Key Point**: Claude's thinking tokens are billed at **output token rates** (most expensive)\n",
    "\n",
    "### Pricing Breakdown:\n",
    "- **Input tokens**: $3-15 per million (depends on model)\n",
    "- **Thinking tokens**: Billed as **output tokens** ($15-75 per million)\n",
    "- **Output tokens**: $15-75 per million\n",
    "\n",
    "### Cost Formula:\n",
    "```\n",
    "Total Cost = (Input √ó Input_Rate) + (Thinking √ó Output_Rate) + (Output √ó Output_Rate)\n",
    "```\n",
    "\n",
    "### Example Costs:\n",
    "- **Simple Analysis**: $0.08 - $0.40 per session\n",
    "- **Complex Problem**: $0.32 - $1.60 per session  \n",
    "- **Deep Research**: $0.80 - $4.00 per session\n",
    "\n",
    "## DeepSeek-R1's Cost Structure\n",
    "\n",
    "**Key Point**: DeepSeek-R1 is **completely FREE** when run locally\n",
    "\n",
    "### Cost Formula:\n",
    "```\n",
    "Total Cost = $0.00 (regardless of thinking depth)\n",
    "```\n",
    "\n",
    "## Cost Comparison Summary\n",
    "\n",
    "| Scenario | Claude Cost | DeepSeek-R1 Cost | Savings |\n",
    "|----------|-------------|------------------|---------|\n",
    "| Simple Analysis | $0.08 - $0.40 | $0.00 | 100% |\n",
    "| Complex Problem | $0.32 - $1.60 | $0.00 | 100% |\n",
    "| Deep Research | $0.80 - $4.00 | $0.00 | 100% |\n",
    "\n",
    "**Annual Savings**: $1,000 - $10,000+ for heavy usage\n",
    "```\n",
    "\n",
    "## Original Claude Cost Calculator## Migrated DeepSeek-R1 Cost Analysis## Summary Comparison\n",
    "\n",
    "```markdown\n",
    "# üìä Final Cost Comparison Summary\n",
    "\n",
    "## Claude Extended Thinking\n",
    "- **Setup**: API key + token budget management\n",
    "- **Cost**: $0.08 - $4.00 per session\n",
    "- **Thinking**: Summarized only\n",
    "- **Limits**: Rate limits + token budgets\n",
    "\n",
    "## DeepSeek-R1 \n",
    "- **Setup**: One-time local installation\n",
    "- **Cost**: $0.00 (completely free)\n",
    "- **Thinking**: Complete process visible\n",
    "- **Limits**: None (unlimited local usage)\n",
    "\n",
    "## Key Takeaway\n",
    "**DeepSeek-R1 saves $1,000-$10,000+ annually** while providing:\n",
    "- ‚úÖ More thinking transparency\n",
    "- ‚úÖ Complete privacy control  \n",
    "- ‚úÖ Unlimited usage\n",
    "- ‚úÖ No token management complexity\n",
    "\n",
    "**Best for**: Learning, development, cost-sensitive projects\n",
    "**Claude best for**: Enterprise verification, quick API setup\n",
    "```\n",
    "\n",
    "The migration shows that DeepSeek-R1 eliminates the entire cost structure while providing **more** thinking detail than Claude's paid service!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01eb9ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí∞ DeepSeek-R1 Cost Analysis\n",
      "============================================================\n",
      "üöÄ DeepSeek-R1 Model: deepseek-r1:14b\n",
      "----------------------------------------\n",
      "\n",
      "  Simple Analysis:\n",
      "    Input tokens: 500\n",
      "    Thinking tokens: 5,000 (unlimited depth)\n",
      "    Output tokens: 1,000\n",
      "    Input cost: $0.00\n",
      "    Thinking cost: $0.00\n",
      "    Output cost: $0.00\n",
      "    Total cost: $0.00 ‚úÖ FREE!\n",
      "\n",
      "  Complex Problem:\n",
      "    Input tokens: 2,000\n",
      "    Thinking tokens: 20,000 (unlimited depth)\n",
      "    Output tokens: 3,000\n",
      "    Input cost: $0.00\n",
      "    Thinking cost: $0.00\n",
      "    Output cost: $0.00\n",
      "    Total cost: $0.00 ‚úÖ FREE!\n",
      "\n",
      "  Deep Research:\n",
      "    Input tokens: 5,000\n",
      "    Thinking tokens: 50,000 (unlimited depth)\n",
      "    Output tokens: 8,000\n",
      "    Input cost: $0.00\n",
      "    Thinking cost: $0.00\n",
      "    Output cost: $0.00\n",
      "    Total cost: $0.00 ‚úÖ FREE!\n",
      "\n",
      "üìà TOTAL USAGE SUMMARY:\n",
      "--------------------------------------------------\n",
      "  Total tokens processed: 94,500\n",
      "  Total cost: $0.00 ‚úÖ COMPLETELY FREE!\n",
      "\n",
      "üìä USAGE PROJECTIONS:\n",
      "--------------------------------------------------\n",
      "\n",
      "  Daily (30 sessions/month):\n",
      "    Monthly cost: $0.00\n",
      "    Annual cost: $0.00\n",
      "    Sessions per year: 360\n",
      "    Status: ‚úÖ UNLIMITED FREE USAGE\n",
      "\n",
      "  Weekly (4 sessions/month):\n",
      "    Monthly cost: $0.00\n",
      "    Annual cost: $0.00\n",
      "    Sessions per year: 48\n",
      "    Status: ‚úÖ UNLIMITED FREE USAGE\n",
      "\n",
      "  Heavy usage (100 sessions/month):\n",
      "    Monthly cost: $0.00\n",
      "    Annual cost: $0.00\n",
      "    Sessions per year: 1,200\n",
      "    Status: ‚úÖ UNLIMITED FREE USAGE\n",
      "\n",
      "  Enterprise (1000 sessions/month):\n",
      "    Monthly cost: $0.00\n",
      "    Annual cost: $0.00\n",
      "    Sessions per year: 12,000\n",
      "    Status: ‚úÖ UNLIMITED FREE USAGE\n",
      "\n",
      "‚öñÔ∏è  COST COMPARISON: Claude vs DeepSeek-R1\n",
      "============================================================\n",
      "Scenario          | Claude Cost  | DeepSeek   | Savings   \n",
      "-----------------------------------------------------------------\n",
      "Simple Analysis   | $0.0915      | $0.00      | $0.0915   \n",
      "Complex Problem   | $0.3510      | $0.00      | $0.3510   \n",
      "Deep Research     | $0.8850      | $0.00      | $0.8850   \n",
      "-----------------------------------------------------------------\n",
      "TOTAL             | $1.3275      | $0.00      | $1.3275   \n",
      "\n",
      "üí° ANNUAL SAVINGS PROJECTIONS:\n",
      "--------------------------------------------------\n",
      "  Light user   : $  13.28/month, $  159.30/year\n",
      "  Regular user : $  66.38/month, $  796.50/year\n",
      "  Heavy user   : $ 265.50/month, $ 3186.00/year\n",
      "  Enterprise   : $1327.50/month, $15930.00/year\n",
      "\n",
      "üéØ DEEPSEEK-R1 ADVANTAGES SUMMARY\n",
      "============================================================\n",
      "\n",
      "üí∞ Cost Benefits\n",
      "  ‚úÖ Completely FREE - no token costs\n",
      "  ‚úÖ No API fees or usage limits\n",
      "  ‚úÖ One-time setup cost only\n",
      "  ‚úÖ Unlimited thinking depth\n",
      "\n",
      "üîç Transparency Benefits\n",
      "  ‚úÖ Full thinking process visible\n",
      "  ‚úÖ No summarization - see everything\n",
      "  ‚úÖ Better for learning and debugging\n",
      "  ‚úÖ Complete reasoning chain\n",
      "\n",
      "üîí Privacy Benefits\n",
      "  ‚úÖ Runs entirely locally\n",
      "  ‚úÖ No data sent to external APIs\n",
      "  ‚úÖ Enterprise-safe deployment\n",
      "  ‚úÖ Complete data control\n",
      "\n",
      "‚ö° Performance Benefits\n",
      "  ‚úÖ No network latency\n",
      "  ‚úÖ No rate limits\n",
      "  ‚úÖ Consistent availability\n",
      "  ‚úÖ GPU acceleration possible\n",
      "\n",
      "üöÄ BOTTOM LINE:\n",
      "   DeepSeek-R1 provides superior thinking transparency\n",
      "   at zero cost with complete privacy control!\n"
     ]
    }
   ],
   "source": [
    "def deepseek_cost_analysis():\n",
    "    \"\"\"DeepSeek-R1 cost analysis - spoiler: it's FREE!\"\"\"\n",
    "    \n",
    "    print(\"üí∞ DeepSeek-R1 Cost Analysis\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Same scenarios as Claude for comparison\n",
    "    scenarios = [\n",
    "        {\"name\": \"Simple Analysis\", \"input\": 500, \"thinking\": 5000, \"output\": 1000},\n",
    "        {\"name\": \"Complex Problem\", \"input\": 2000, \"thinking\": 20000, \"output\": 3000},\n",
    "        {\"name\": \"Deep Research\", \"input\": 5000, \"thinking\": 50000, \"output\": 8000}\n",
    "    ]\n",
    "    \n",
    "    print(\"üöÄ DeepSeek-R1 Model: deepseek-r1:14b\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    total_usage = 0\n",
    "    \n",
    "    for scenario in scenarios:\n",
    "        # DeepSeek-R1 costs\n",
    "        input_cost = 0.00  # FREE\n",
    "        thinking_cost = 0.00  # FREE\n",
    "        output_cost = 0.00  # FREE\n",
    "        total_cost = 0.00  # FREE!\n",
    "        \n",
    "        total_usage += scenario[\"input\"] + scenario[\"thinking\"] + scenario[\"output\"]\n",
    "        \n",
    "        print(f\"\\n  {scenario['name']}:\")\n",
    "        print(f\"    Input tokens: {scenario['input']:,}\")\n",
    "        print(f\"    Thinking tokens: {scenario['thinking']:,} (unlimited depth)\")\n",
    "        print(f\"    Output tokens: {scenario['output']:,}\")\n",
    "        print(f\"    Input cost: ${input_cost:.2f}\")\n",
    "        print(f\"    Thinking cost: ${thinking_cost:.2f}\")\n",
    "        print(f\"    Output cost: ${output_cost:.2f}\")\n",
    "        print(f\"    Total cost: ${total_cost:.2f} ‚úÖ FREE!\")\n",
    "    \n",
    "    print(f\"\\nüìà TOTAL USAGE SUMMARY:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"  Total tokens processed: {total_usage:,}\")\n",
    "    print(f\"  Total cost: $0.00 ‚úÖ COMPLETELY FREE!\")\n",
    "    \n",
    "    # Usage projections\n",
    "    print(f\"\\nüìä USAGE PROJECTIONS:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    usage_scenarios = [\n",
    "        {\"frequency\": \"Daily (30 sessions/month)\", \"multiplier\": 30},\n",
    "        {\"frequency\": \"Weekly (4 sessions/month)\", \"multiplier\": 4},\n",
    "        {\"frequency\": \"Heavy usage (100 sessions/month)\", \"multiplier\": 100},\n",
    "        {\"frequency\": \"Enterprise (1000 sessions/month)\", \"multiplier\": 1000}\n",
    "    ]\n",
    "    \n",
    "    for usage in usage_scenarios:\n",
    "        monthly_cost = 0.00\n",
    "        annual_cost = 0.00\n",
    "        \n",
    "        print(f\"\\n  {usage['frequency']}:\")\n",
    "        print(f\"    Monthly cost: $0.00\")\n",
    "        print(f\"    Annual cost: $0.00\")\n",
    "        print(f\"    Sessions per year: {usage['multiplier'] * 12:,}\")\n",
    "        print(f\"    Status: ‚úÖ UNLIMITED FREE USAGE\")\n",
    "\n",
    "def cost_comparison_calculator():\n",
    "    \"\"\"Direct comparison: Claude vs DeepSeek-R1\"\"\"\n",
    "    \n",
    "    print(f\"\\n‚öñÔ∏è  COST COMPARISON: Claude vs DeepSeek-R1\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Claude pricing (using Sonnet-4 as middle ground)\n",
    "    claude_prices = {\"input\": 3, \"output\": 15}  # per million tokens\n",
    "    \n",
    "    scenarios = [\n",
    "        {\"name\": \"Simple Analysis\", \"input\": 500, \"thinking\": 5000, \"output\": 1000},\n",
    "        {\"name\": \"Complex Problem\", \"input\": 2000, \"thinking\": 20000, \"output\": 3000},\n",
    "        {\"name\": \"Deep Research\", \"input\": 5000, \"thinking\": 50000, \"output\": 8000}\n",
    "    ]\n",
    "    \n",
    "    print(f\"{'Scenario':<17} | {'Claude Cost':<12} | {'DeepSeek':<10} | {'Savings':<10}\")\n",
    "    print(\"-\" * 65)\n",
    "    \n",
    "    total_claude_cost = 0\n",
    "    total_deepseek_cost = 0\n",
    "    \n",
    "    for scenario in scenarios:\n",
    "        # Claude costs\n",
    "        claude_input = (scenario[\"input\"] / 1_000_000) * claude_prices[\"input\"]\n",
    "        claude_thinking = (scenario[\"thinking\"] / 1_000_000) * claude_prices[\"output\"]\n",
    "        claude_output = (scenario[\"output\"] / 1_000_000) * claude_prices[\"output\"]\n",
    "        claude_total = claude_input + claude_thinking + claude_output\n",
    "        \n",
    "        # DeepSeek costs\n",
    "        deepseek_total = 0.00\n",
    "        \n",
    "        # Savings\n",
    "        savings = claude_total\n",
    "        \n",
    "        total_claude_cost += claude_total\n",
    "        total_deepseek_cost += deepseek_total\n",
    "        \n",
    "        print(f\"{scenario['name']:<17} | ${claude_total:<11.4f} | ${deepseek_total:<9.2f} | ${savings:<9.4f}\")\n",
    "    \n",
    "    print(\"-\" * 65)\n",
    "    print(f\"{'TOTAL':<17} | ${total_claude_cost:<11.4f} | ${total_deepseek_cost:<9.2f} | ${total_claude_cost:<9.4f}\")\n",
    "    \n",
    "    # Annual savings calculation\n",
    "    print(f\"\\nüí° ANNUAL SAVINGS PROJECTIONS:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    usage_levels = [\n",
    "        {\"name\": \"Light user\", \"sessions_per_month\": 10},\n",
    "        {\"name\": \"Regular user\", \"sessions_per_month\": 50},\n",
    "        {\"name\": \"Heavy user\", \"sessions_per_month\": 200},\n",
    "        {\"name\": \"Enterprise\", \"sessions_per_month\": 1000}\n",
    "    ]\n",
    "    \n",
    "    for level in usage_levels:\n",
    "        monthly_savings = total_claude_cost * level[\"sessions_per_month\"]\n",
    "        annual_savings = monthly_savings * 12\n",
    "        \n",
    "        print(f\"  {level['name']:<13}: ${monthly_savings:>7.2f}/month, ${annual_savings:>8.2f}/year\")\n",
    "\n",
    "def deepseek_advantages_summary():\n",
    "    \"\"\"Summarize the key advantages of DeepSeek-R1\"\"\"\n",
    "    \n",
    "    print(f\"\\nüéØ DEEPSEEK-R1 ADVANTAGES SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    advantages = [\n",
    "        {\n",
    "            \"category\": \"üí∞ Cost Benefits\",\n",
    "            \"points\": [\n",
    "                \"Completely FREE - no token costs\",\n",
    "                \"No API fees or usage limits\", \n",
    "                \"One-time setup cost only\",\n",
    "                \"Unlimited thinking depth\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"category\": \"üîç Transparency Benefits\",\n",
    "            \"points\": [\n",
    "                \"Full thinking process visible\",\n",
    "                \"No summarization - see everything\",\n",
    "                \"Better for learning and debugging\",\n",
    "                \"Complete reasoning chain\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"category\": \"üîí Privacy Benefits\",\n",
    "            \"points\": [\n",
    "                \"Runs entirely locally\",\n",
    "                \"No data sent to external APIs\",\n",
    "                \"Enterprise-safe deployment\",\n",
    "                \"Complete data control\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"category\": \"‚ö° Performance Benefits\",\n",
    "            \"points\": [\n",
    "                \"No network latency\",\n",
    "                \"No rate limits\",\n",
    "                \"Consistent availability\",\n",
    "                \"GPU acceleration possible\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for advantage in advantages:\n",
    "        print(f\"\\n{advantage['category']}\")\n",
    "        for point in advantage['points']:\n",
    "            print(f\"  ‚úÖ {point}\")\n",
    "    \n",
    "    print(f\"\\nüöÄ BOTTOM LINE:\")\n",
    "    print(f\"   DeepSeek-R1 provides superior thinking transparency\")\n",
    "    print(f\"   at zero cost with complete privacy control!\")\n",
    "\n",
    "# Run all analyses\n",
    "deepseek_cost_analysis()\n",
    "cost_comparison_calculator()\n",
    "deepseek_advantages_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f586e2",
   "metadata": {},
   "source": [
    "### Performance Optimization Tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0a8bc4",
   "metadata": {},
   "source": [
    "## Markdown Explanation: Performance Optimization Migration\n",
    "\n",
    "```markdown\n",
    "# Performance Optimization: Claude vs DeepSeek-R1\n",
    "\n",
    "## üîÑ Migration Overview\n",
    "\n",
    "**Claude Approach**: Complex token budget management with cost optimization\n",
    "**DeepSeek-R1 Approach**: Simple performance tuning with no token limits\n",
    "\n",
    "## Key Differences\n",
    "\n",
    "| Strategy | Claude | DeepSeek-R1 |\n",
    "|----------|--------|-------------|\n",
    "| **Budget Management** | ‚ùå Complex token calculations | ‚úÖ No budgets needed |\n",
    "| **Cost Control** | üí∞ Pay per thinking token | üí∞ Free unlimited thinking |\n",
    "| **Performance Tuning** | Token-based optimization | Hardware-based optimization |\n",
    "| **Streaming** | API streaming events | Direct response streaming |\n",
    "| **Caching** | Prompt caching (paid feature) | Local model caching (free) |\n",
    "\n",
    "## Migration Strategy\n",
    "\n",
    "1. **Remove token budget logic** ‚Üí Replace with hardware optimization\n",
    "2. **Keep streaming concepts** ‚Üí Adapt to DeepSeek's streaming format\n",
    "3. **Replace cost optimization** ‚Üí Focus on response quality optimization\n",
    "4. **Transform caching strategy** ‚Üí Use local model benefits\n",
    "```\n",
    "\n",
    "## Original Claude Code (Performance Tips)## Migrated DeepSeek-R1 Code (Performance Tips)## Migration Summary with Markdown\n",
    "\n",
    "```markdown\n",
    "# üîÑ Performance Tips Migration Summary\n",
    "\n",
    "## Core Philosophy Change\n",
    "\n",
    "**Claude**: Optimize for cost efficiency through token management\n",
    "**DeepSeek-R1**: Optimize for quality and speed through local inference\n",
    "\n",
    "## Key Transformations\n",
    "\n",
    "### 1. Token Budget ‚Üí Prompt Complexity\n",
    "- **Before**: \"Start with 1,024 tokens\"\n",
    "- **After**: \"Start with simple prompts\"\n",
    "\n",
    "### 2. Cost Management ‚Üí Hardware Optimization  \n",
    "- **Before**: \"Use batch API for large budgets\"\n",
    "- **After**: \"Use GPU acceleration for speed\"\n",
    "\n",
    "### 3. Streaming Strategy\n",
    "- **Before**: Stream to show progress during expensive thinking\n",
    "- **After**: Stream to show real-time thinking process (free)\n",
    "\n",
    "### 4. Caching Approach\n",
    "- **Before**: Prompt caching (paid feature)\n",
    "- **After**: Model memory caching (automatic)\n",
    "\n",
    "## Performance Metrics Comparison\n",
    "\n",
    "| Aspect | Claude | DeepSeek-R1 |\n",
    "|--------|--------|-------------|\n",
    "| **Cost Control** | Complex token math | No cost to control |\n",
    "| **Speed Optimization** | Reduce token usage | Improve hardware |\n",
    "| **Quality Scaling** | Increase token budget | Improve prompt structure |\n",
    "| **Batch Processing** | Paid batch API | Free local processing |\n",
    "\n",
    "## Migration Benefits\n",
    "\n",
    "‚úÖ **Simpler**: No token budget calculations\n",
    "‚úÖ **Cheaper**: Completely free operation  \n",
    "‚úÖ **Transparent**: Full thinking process visible\n",
    "‚úÖ **Private**: No data leaves your machine\n",
    "‚úÖ **Flexible**: No rate limits or quotas\n",
    "\n",
    "## When to Use Each\n",
    "\n",
    "- **Claude**: Enterprise verification, quick setup\n",
    "- **DeepSeek-R1**: Learning, development, unlimited usage\n",
    "```\n",
    "\n",
    "The migration completely transforms the performance optimization approach from **cost management** to **quality optimization**, making it much simpler while providing better transparency and unlimited usage!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db9f5c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° DeepSeek-R1 Performance Optimization Strategies\n",
      "============================================================\n",
      "\n",
      "1. Start with Simple Prompts\n",
      "  üìù Begin with basic requests, add complexity as needed\n",
      "  ‚öôÔ∏è  Optimization: Prompt complexity\n",
      "  üéØ Best for: Simple calculations or basic analysis\n",
      "  üí∞ Cost: FREE - No token limits\n",
      "\n",
      "2. Use Streaming for Better UX\n",
      "  üìù Stream responses to show thinking progress in real-time\n",
      "  ‚öôÔ∏è  Optimization: stream=True parameter\n",
      "  üéØ Best for: Interactive applications\n",
      "  üí∞ Cost: FREE - Same as non-streaming\n",
      "\n",
      "3. Batch Processing for Large Tasks\n",
      "  üìù Process multiple requests efficiently with local inference\n",
      "  ‚öôÔ∏è  Optimization: Local processing power\n",
      "  üéØ Best for: Overnight analysis jobs\n",
      "  üí∞ Cost: FREE - Only electricity cost\n",
      "\n",
      "4. Leverage Model Caching\n",
      "  üìù Model stays loaded in memory for faster subsequent requests\n",
      "  ‚öôÔ∏è  Optimization: Keep Ollama running\n",
      "  üéØ Best for: Repeated analysis patterns\n",
      "  üí∞ Cost: FREE - No additional API calls\n",
      "\n",
      "5. Hardware Optimization\n",
      "  üìù Use GPU acceleration for faster inference\n",
      "  ‚öôÔ∏è  Optimization: CUDA/Metal support\n",
      "  üéØ Best for: High-volume processing\n",
      "  üí∞ Cost: FREE - Better hardware utilization\n",
      "\n",
      "\n",
      "üìà DeepSeek-R1 Complexity vs. Quality Guidelines:\n",
      "----------------------------------------\n",
      "  Simple prompts: Basic reasoning tasks (FREE)\n",
      "  Structured prompts: Standard complex problems (FREE)\n",
      "  Multi-step prompts: Deep analysis and research (FREE)\n",
      "  Complex scenarios: Extensive multi-faceted problems (FREE)\n",
      "\n",
      "\n",
      "‚úÖ DeepSeek-R1 Advantages:\n",
      "  ‚Ä¢ No token budget management needed\n",
      "  ‚Ä¢ No cost per request - unlimited usage\n",
      "  ‚Ä¢ Complete thinking process always visible\n",
      "  ‚Ä¢ Local inference = no network latency\n",
      "  ‚Ä¢ Privacy-first - no data leaves your machine\n",
      "\n",
      "üèÉ DeepSeek-R1 Performance Benchmark\n",
      "==================================================\n",
      "\n",
      "üß™ Testing: Simple Math\n",
      "   Expected thinking: Minimal\n",
      "   ‚è±Ô∏è  Duration: 19.41 seconds\n",
      "   üß† Thinking: 362 characters\n",
      "   üìù Total: 657 characters\n",
      "\n",
      "üß™ Testing: Complex Calculation\n",
      "   Expected thinking: Moderate\n",
      "   ‚è±Ô∏è  Duration: 10.32 seconds\n",
      "   üß† Thinking: 613 characters\n",
      "   üìù Total: 1,784 characters\n",
      "\n",
      "üß™ Testing: Multi-step Analysis\n",
      "   Expected thinking: Extensive\n",
      "   ‚è±Ô∏è  Duration: 35.08 seconds\n",
      "   üß† Thinking: 3,609 characters\n",
      "   üìù Total: 7,554 characters\n",
      "\n",
      "üìä PERFORMANCE SUMMARY\n",
      "==============================\n",
      "Average response time: 21.60 seconds\n",
      "Total thinking generated: 4,584 characters\n",
      "All responses include thinking: True\n",
      "Cost for all tests: $0.00 (FREE!)\n",
      "\n",
      "‚öñÔ∏è  PERFORMANCE COMPARISON\n",
      "==================================================\n",
      "Metric               | Claude                         | DeepSeek-R1\n",
      "---------------------------------------------------------------------------\n",
      "Setup Complexity     | ‚ùå API key + token budget math  | ‚úÖ One-time Ollama install\n",
      "Cost per Request     | üí∞ $0.015 - $0.50+ per request  | üí∞ $0.00 (FREE)\n",
      "Token Management     | ‚ùå Complex budget_tokens < max_tokens | ‚úÖ No token limits\n",
      "Thinking Visibility  | üìù Summarized thinking only     | üìù Complete thinking process\n",
      "Rate Limits          | ‚è∞ API rate limits apply        | ‚è∞ No limits - local inference\n",
      "Network Dependency   | üåê Requires internet connection | üè† Works offline\n",
      "Privacy              | ‚òÅÔ∏è  Data sent to Anthropic     | üîí 100% local processing\n",
      "\n",
      "üèÜ Winner: DeepSeek-R1 for cost, privacy, and thinking transparency\n",
      "üéØ Use Claude for: Enterprise features, quick API setup\n",
      "üéØ Use DeepSeek-R1 for: Learning, development, cost-sensitive projects\n"
     ]
    }
   ],
   "source": [
    "def performance_tips():\n",
    "    \"\"\"Demonstrate performance optimization strategies for DeepSeek-R1\"\"\"\n",
    "    \n",
    "    print(\"‚ö° DeepSeek-R1 Performance Optimization Strategies\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    strategies = [\n",
    "        {\n",
    "            \"title\": \"1. Start with Simple Prompts\",\n",
    "            \"description\": \"Begin with basic requests, add complexity as needed\",\n",
    "            \"optimization\": \"Prompt complexity\",\n",
    "            \"use_case\": \"Simple calculations or basic analysis\",\n",
    "            \"cost_estimate\": \"FREE - No token limits\"\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"2. Use Streaming for Better UX\",\n",
    "            \"description\": \"Stream responses to show thinking progress in real-time\",\n",
    "            \"optimization\": \"stream=True parameter\",\n",
    "            \"use_case\": \"Interactive applications\",\n",
    "            \"cost_estimate\": \"FREE - Same as non-streaming\"\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"3. Batch Processing for Large Tasks\",\n",
    "            \"description\": \"Process multiple requests efficiently with local inference\",\n",
    "            \"optimization\": \"Local processing power\",\n",
    "            \"use_case\": \"Overnight analysis jobs\",\n",
    "            \"cost_estimate\": \"FREE - Only electricity cost\"\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"4. Leverage Model Caching\",\n",
    "            \"description\": \"Model stays loaded in memory for faster subsequent requests\",\n",
    "            \"optimization\": \"Keep Ollama running\",\n",
    "            \"use_case\": \"Repeated analysis patterns\",\n",
    "            \"cost_estimate\": \"FREE - No additional API calls\"\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"5. Hardware Optimization\",\n",
    "            \"description\": \"Use GPU acceleration for faster inference\",\n",
    "            \"optimization\": \"CUDA/Metal support\",\n",
    "            \"use_case\": \"High-volume processing\",\n",
    "            \"cost_estimate\": \"FREE - Better hardware utilization\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for strategy in strategies:\n",
    "        print(f\"\\n{strategy['title']}\")\n",
    "        print(f\"  üìù {strategy['description']}\")\n",
    "        print(f\"  ‚öôÔ∏è  Optimization: {strategy['optimization']}\")\n",
    "        print(f\"  üéØ Best for: {strategy['use_case']}\")\n",
    "        print(f\"  üí∞ Cost: {strategy['cost_estimate']}\")\n",
    "    \n",
    "    print(\"\\n\\nüìà DeepSeek-R1 Complexity vs. Quality Guidelines:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"  Simple prompts: Basic reasoning tasks (FREE)\")\n",
    "    print(\"  Structured prompts: Standard complex problems (FREE)\")\n",
    "    print(\"  Multi-step prompts: Deep analysis and research (FREE)\")\n",
    "    print(\"  Complex scenarios: Extensive multi-faceted problems (FREE)\")\n",
    "    \n",
    "    print(\"\\n\\n‚úÖ DeepSeek-R1 Advantages:\")\n",
    "    print(\"  ‚Ä¢ No token budget management needed\")\n",
    "    print(\"  ‚Ä¢ No cost per request - unlimited usage\")\n",
    "    print(\"  ‚Ä¢ Complete thinking process always visible\")\n",
    "    print(\"  ‚Ä¢ Local inference = no network latency\")\n",
    "    print(\"  ‚Ä¢ Privacy-first - no data leaves your machine\")\n",
    "\n",
    "def deepseek_performance_benchmark():\n",
    "    \"\"\"Benchmark DeepSeek-R1 performance characteristics\"\"\"\n",
    "    \n",
    "    print(\"\\nüèÉ DeepSeek-R1 Performance Benchmark\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    import time\n",
    "    \n",
    "    # Test different complexity levels\n",
    "    test_cases = [\n",
    "        {\n",
    "            \"name\": \"Simple Math\",\n",
    "            \"prompt\": \"What is 15 + 23?\",\n",
    "            \"expected_thinking\": \"Minimal\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Complex Calculation\", \n",
    "            \"prompt\": \"Calculate compound interest: $10,000 at 7% annually for 15 years\",\n",
    "            \"expected_thinking\": \"Moderate\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Multi-step Analysis\",\n",
    "            \"prompt\": \"\"\"Analyze this investment scenario step by step:\n",
    "            - Initial investment: $50,000\n",
    "            - Monthly contributions: $1,000\n",
    "            - Expected return: 8% annually\n",
    "            - Time horizon: 20 years\n",
    "            - Goal: $500,000\n",
    "            Calculate if the goal is achievable and recommend adjustments.\"\"\",\n",
    "            \"expected_thinking\": \"Extensive\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for test in test_cases:\n",
    "        print(f\"\\nüß™ Testing: {test['name']}\")\n",
    "        print(f\"   Expected thinking: {test['expected_thinking']}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            response = client.chat(\n",
    "                model='deepseek-r1:14b',\n",
    "                messages=[{\"role\": \"user\", \"content\": test['prompt']}],\n",
    "                stream=False\n",
    "            )\n",
    "            \n",
    "            end_time = time.time()\n",
    "            duration = end_time - start_time\n",
    "            \n",
    "            full_response = response.get('message', {}).get('content', '')\n",
    "            \n",
    "            # Analyze response\n",
    "            has_thinking = '<think>' in full_response\n",
    "            thinking_length = 0\n",
    "            \n",
    "            if has_thinking:\n",
    "                thinking_start = full_response.find('<think>') + 7\n",
    "                thinking_end = full_response.find('</think>')\n",
    "                thinking_length = len(full_response[thinking_start:thinking_end])\n",
    "            \n",
    "            result = {\n",
    "                \"name\": test['name'],\n",
    "                \"duration\": duration,\n",
    "                \"thinking_length\": thinking_length,\n",
    "                \"total_length\": len(full_response),\n",
    "                \"has_thinking\": has_thinking\n",
    "            }\n",
    "            results.append(result)\n",
    "            \n",
    "            print(f\"   ‚è±Ô∏è  Duration: {duration:.2f} seconds\")\n",
    "            print(f\"   üß† Thinking: {thinking_length:,} characters\")\n",
    "            print(f\"   üìù Total: {len(full_response):,} characters\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error: {e}\")\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\nüìä PERFORMANCE SUMMARY\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    if results:\n",
    "        avg_duration = sum(r['duration'] for r in results) / len(results)\n",
    "        total_thinking = sum(r['thinking_length'] for r in results)\n",
    "        \n",
    "        print(f\"Average response time: {avg_duration:.2f} seconds\")\n",
    "        print(f\"Total thinking generated: {total_thinking:,} characters\")\n",
    "        print(f\"All responses include thinking: {all(r['has_thinking'] for r in results)}\")\n",
    "        print(f\"Cost for all tests: $0.00 (FREE!)\")\n",
    "\n",
    "def deepseek_vs_claude_comparison():\n",
    "    \"\"\"Compare DeepSeek-R1 vs Claude performance characteristics\"\"\"\n",
    "    \n",
    "    print(f\"\\n‚öñÔ∏è  PERFORMANCE COMPARISON\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    comparisons = [\n",
    "        {\n",
    "            \"metric\": \"Setup Complexity\",\n",
    "            \"claude\": \"‚ùå API key + token budget math\",\n",
    "            \"deepseek\": \"‚úÖ One-time Ollama install\"\n",
    "        },\n",
    "        {\n",
    "            \"metric\": \"Cost per Request\",\n",
    "            \"claude\": \"üí∞ $0.015 - $0.50+ per request\",\n",
    "            \"deepseek\": \"üí∞ $0.00 (FREE)\"\n",
    "        },\n",
    "        {\n",
    "            \"metric\": \"Token Management\",\n",
    "            \"claude\": \"‚ùå Complex budget_tokens < max_tokens\",\n",
    "            \"deepseek\": \"‚úÖ No token limits\"\n",
    "        },\n",
    "        {\n",
    "            \"metric\": \"Thinking Visibility\",\n",
    "            \"claude\": \"üìù Summarized thinking only\",\n",
    "            \"deepseek\": \"üìù Complete thinking process\"\n",
    "        },\n",
    "        {\n",
    "            \"metric\": \"Rate Limits\",\n",
    "            \"claude\": \"‚è∞ API rate limits apply\",\n",
    "            \"deepseek\": \"‚è∞ No limits - local inference\"\n",
    "        },\n",
    "        {\n",
    "            \"metric\": \"Network Dependency\",\n",
    "            \"claude\": \"üåê Requires internet connection\",\n",
    "            \"deepseek\": \"üè† Works offline\"\n",
    "        },\n",
    "        {\n",
    "            \"metric\": \"Privacy\",\n",
    "            \"claude\": \"‚òÅÔ∏è  Data sent to Anthropic\",\n",
    "            \"deepseek\": \"üîí 100% local processing\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(f\"{'Metric':<20} | {'Claude':<30} | {'DeepSeek-R1'}\")\n",
    "    print(\"-\" * 75)\n",
    "    \n",
    "    for comp in comparisons:\n",
    "        print(f\"{comp['metric']:<20} | {comp['claude']:<30} | {comp['deepseek']}\")\n",
    "    \n",
    "    print(f\"\\nüèÜ Winner: DeepSeek-R1 for cost, privacy, and thinking transparency\")\n",
    "    print(f\"üéØ Use Claude for: Enterprise features, quick API setup\")\n",
    "    print(f\"üéØ Use DeepSeek-R1 for: Learning, development, cost-sensitive projects\")\n",
    "\n",
    "# Run all DeepSeek-R1 examples\n",
    "performance_tips()\n",
    "deepseek_performance_benchmark()\n",
    "deepseek_vs_claude_comparison()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8c409f",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "### What We've Learned\n",
    "\n",
    "1. **DeepSeek-R1 Thinking Basics**: How to leverage automatic reasoning capabilities without token budgets\n",
    "2. **Thinking Blocks**: Understanding `<think>` tags and complete reasoning transparency\n",
    "3. **Advanced Features**: Streaming, mathematical reasoning, and complex problem-solving\n",
    "4. **Best Practices**: Optimal prompting with step-by-step guidance for DeepSeek-R1\n",
    "5. **Real-World Applications**: Financial analysis, business planning, and systematic reasoning\n",
    "6. **Local Optimization**: Hardware acceleration and unlimited usage strategies\n",
    "\n",
    "### When to Use DeepSeek-R1 Extended Thinking\n",
    "\n",
    "‚úÖ **Perfect for:**\n",
    "- Complex multi-step mathematical problems\n",
    "- Deep financial and business analysis\n",
    "- Strategic planning with quantitative reasoning\n",
    "- Learning AI reasoning processes (full transparency)\n",
    "- Cost-sensitive projects requiring extensive thinking\n",
    "- Privacy-critical applications (100% local processing)\n",
    "\n",
    "‚ùå **Consider alternatives for:**\n",
    "- Simple queries or basic lookups\n",
    "- Enterprise verification requirements (no cryptographic signatures)\n",
    "- Quick API prototyping (setup complexity)\n",
    "- Tasks requiring specialized tool integrations\n",
    "\n",
    "### DeepSeek-R1 vs Claude Summary\n",
    "\n",
    "| **Aspect** | **Claude Extended Thinking** | **DeepSeek-R1 Thinking** |\n",
    "|------------|------------------------------|---------------------------|\n",
    "| **Cost** | $0.015-$0.50+ per request | **FREE unlimited** |\n",
    "| **Setup** | API key only | One-time Ollama install |\n",
    "| **Thinking Detail** | Summarized | **Complete process** |\n",
    "| **Token Management** | Complex budget calculation | **None needed** |\n",
    "| **Privacy** | Cloud-based | **100% local** |\n",
    "| **Mathematical Reasoning** | Good | **Excellent** |\n",
    "| **Transparency** | Limited | **Full visibility** |\n",
    "\n",
    "### Resources for Further Learning\n",
    "\n",
    "- [Ollama Documentation](https://ollama.ai/docs)\n",
    "- [DeepSeek-R1 Model Card](https://ollama.ai/deepseek-r1)\n",
    "- [Local AI Setup Guide](https://ollama.ai/download)\n",
    "- [DeepSeek Research Papers](https://github.com/deepseek-ai)\n",
    "\n",
    "### Try It Yourself!\n",
    "\n",
    "Now that you understand DeepSeek-R1 thinking, try these challenges:\n",
    "\n",
    "1. **Math Challenge**: \n",
    "   ```python\n",
    "   # Complex optimization problem\n",
    "   prompt = \"\"\"A company has 3 factories with different production costs and capacities.\n",
    "   Factory A: $50/unit, 1000 units/day capacity\n",
    "   Factory B: $45/unit, 800 units/day capacity  \n",
    "   Factory C: $40/unit, 600 units/day capacity\n",
    "   \n",
    "   They need to produce 2000 units/day to meet demand.\n",
    "   What's the optimal production allocation to minimize costs?\n",
    "   Show all calculations step by step.\"\"\"\n",
    "   \n",
    "   result = client.chat(model='deepseek-r1:14b', \n",
    "                       messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "   ```\n",
    "\n",
    "2. **Analysis Challenge**:\n",
    "   ```python\n",
    "   # Financial analysis with thinking\n",
    "   prompt = \"\"\"Analyze this investment portfolio and recommend changes:\n",
    "   - 60% stocks (10% avg return, high volatility)\n",
    "   - 30% bonds (4% avg return, low volatility)\n",
    "   - 10% cash (1% return, no volatility)\n",
    "   \n",
    "   Investor: 35 years old, $100K portfolio, 30-year horizon\n",
    "   Think through risk-return optimization systematically.\"\"\"\n",
    "   ```\n",
    "\n",
    "3. **Planning Challenge**:\n",
    "   ```python\n",
    "   # System architecture with reasoning\n",
    "   prompt = \"\"\"Design a scalable e-commerce system architecture.\n",
    "   Requirements: 10M users, 100K daily orders, 99.9% uptime\n",
    "   Consider: database design, caching, load balancing, microservices\n",
    "   Think through each component's rationale step by step.\"\"\"\n",
    "   ```\n",
    "\n",
    "4. **Comparison Challenge**:\n",
    "   ```python\n",
    "   # Compare different prompting approaches\n",
    "   basic_prompt = \"Should I invest in stocks or bonds?\"\n",
    "   structured_prompt = \"\"\"Compare stocks vs bonds for my situation:\n",
    "   - Age: 30, Income: $80K, Savings: $20K\n",
    "   - Goal: Retirement in 35 years\n",
    "   - Risk tolerance: Medium\n",
    "   Analyze systematically with calculations.\"\"\"\n",
    "   \n",
    "   # See how thinking depth changes!\n",
    "   ```\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "üéØ **DeepSeek-R1 Excels At:**\n",
    "- Mathematical and quantitative reasoning\n",
    "- Step-by-step problem solving\n",
    "- Cost-free unlimited usage\n",
    "- Complete thinking transparency\n",
    "- Local privacy and control\n",
    "\n",
    "üöÄ **Getting Started:**\n",
    "1. Install Ollama: `curl -fsSL https://ollama.com/install.sh | sh`\n",
    "2. Pull DeepSeek-R1: `ollama pull deepseek-r1:14b`\n",
    "3. Use the converted examples from this guide\n",
    "4. Experiment with structured, mathematical prompts\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Practice** with the migrated examples\n",
    "2. **Experiment** with different prompt structures\n",
    "3. **Compare** DeepSeek-R1 vs Claude on your specific use cases\n",
    "4. **Share** your findings with the community\n",
    "\n",
    "**Happy thinking with DeepSeek-R1!** ü§î‚ú®üß†\n",
    "\n",
    "*Remember: With DeepSeek-R1, you get MORE thinking detail for FREE - perfect for learning how AI reasons through complex problems!*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-reasoning-models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
