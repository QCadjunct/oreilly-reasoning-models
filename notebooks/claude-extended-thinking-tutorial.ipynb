{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claude with Extended Thinking: A Comprehensive Tutorial\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "In this notebook, we'll explore Claude's extended thinking capabilities - a powerful feature that gives Claude enhanced reasoning for complex tasks. We'll start with the basics and gradually build up to advanced use cases.\n",
    "\n",
    "### Table of Contents\n",
    "1. [Introduction to Extended Thinking](#introduction)\n",
    "2. [Setting Up Your Environment](#setup)\n",
    "3. [Basic Usage](#basic-usage)\n",
    "4. [Understanding Thinking Blocks](#thinking-blocks)\n",
    "5. [Advanced Features](#advanced-features)\n",
    "6. [Best Practices](#best-practices)\n",
    "7. [Real-World Examples](#examples)\n",
    "8. [Performance and Cost Considerations](#performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='introduction'></a>\n",
    "## 1. Introduction to Extended Thinking\n",
    "\n",
    "Extended thinking is a feature that allows Claude to \"think\" through complex problems step-by-step before providing a final answer. This is particularly useful for:\n",
    "\n",
    "- üßÆ **Mathematical problems** requiring multi-step calculations\n",
    "- üîç **Complex analysis** of documents or data\n",
    "- üèóÔ∏è **Architecture decisions** in software development\n",
    "- üéØ **Strategic planning** and decision-making\n",
    "\n",
    "### How It Works\n",
    "\n",
    "When extended thinking is enabled, Claude:\n",
    "1. Creates internal \"thinking\" content blocks\n",
    "2. Works through the problem systematically\n",
    "3. Incorporates insights from this reasoning\n",
    "4. Delivers a more thoughtful final response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "## 2. Setting Up Your Environment\n",
    "\n",
    "Let's start by installing the necessary packages and setting up our API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the Anthropic Python SDK\n",
    "# !pip install anthropic>=0.34.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import anthropic\n",
    "from IPython.display import Markdown, display\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Set up your API key\n",
    "# You can either set it as an environment variable or directly here\n",
    "# For security, we recommend using environment variables\n",
    "api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "if not api_key:\n",
    "    api_key = input(\"Please enter your Anthropic API key: \")\n",
    "\n",
    "client = anthropic.Anthropic(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supported Models\n",
    "\n",
    "Extended thinking is planned for:\n",
    "- **Claude Opus 4** (`claude-opus-4-20250514`) - *Coming Soon*\n",
    "- **Claude Sonnet 4** (`claude-sonnet-4-20250514`) - *Coming Soon*\n",
    "- **Claude Sonnet 3.7** (`claude-3-7-sonnet-20250219`) - *Preview*\n",
    "\n",
    "**Currently Available Models:**\n",
    "- **Claude 3.5 Sonnet** (`claude-3-5-sonnet-20241022`) - *Standard model used in examples*\n",
    "\n",
    "Note: This notebook uses fallback code to demonstrate concepts with currently available models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ö†Ô∏è Important Note\n",
    "\n",
    "**Extended thinking is currently in preview and may not be available to all users.** The examples in this notebook include fallback code that will work with regular Claude models if extended thinking is not available. The tutorial demonstrates the concepts and API structure even if the actual thinking feature isn't accessible yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='basic-usage'></a>\n",
    "## 3. Basic Usage\n",
    "\n",
    "Let's start with a simple example to see extended thinking in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§î Claude's Thinking Process:\n",
      "--------------------------------------------------\n",
      "I need to calculate 27 * 453. I'll do this step by step using the standard multiplication algorithm.\n",
      "\n",
      "27 * 453\n",
      "\n",
      "I can break this down as:\n",
      "27 * 453 = 27 * (400 + 50 + 3)\n",
      "= 27 * 400 + 27 * 50 + 27 * 3\n",
      "\n",
      "Let me calculate each part:\n",
      "\n",
      "27 * 3 = 81\n",
      "27 * 50 = 27 * 5 * 10 = 135 * 10 = 1,350\n",
      "27 * 400 = 27 * 4 * 100 = 108 * 100 = 10,800\n",
      "\n",
      "So: 81 + 1,350 + 10,800 = 12,231\n",
      "\n",
      "Let me double-check this using the standard multiplication method:\n",
      "\n",
      "    453\n",
      "  √ó  27\n",
      "  -----\n",
      "   3171  (453 √ó 7)\n",
      "  9060   (453 √ó 20)\n",
      "  -----\n",
      "  12231\n",
      "\n",
      "Let me verify the partial products:\n",
      "453 √ó 7:\n",
      "3 √ó 7 = 21, write 1 carry 2\n",
      "5 √ó 7 = 35, plus 2 = 37, write 7 carry 3\n",
      "4 √ó 7 = 28, plus 3 = 31, write 31\n",
      "So 453 √ó 7 = 3171 ‚úì\n",
      "\n",
      "453 √ó 20:\n",
      "453 √ó 2 = 906, then multiply by 10 = 9060 ‚úì\n",
      "\n",
      "3171 + 9060 = 12231 ‚úì\n",
      "--------------------------------------------------\n",
      "\n",
      "‚úÖ Final Answer:\n",
      "I'll calculate 27 √ó 453 using the standard multiplication method:\n",
      "\n",
      "```\n",
      "    453\n",
      "  √ó  27\n",
      "  -----\n",
      "   3171  (453 √ó 7)\n",
      "  9060   (453 √ó 20)\n",
      "  -----\n",
      "  12231\n",
      "```\n",
      "\n",
      "Let me break down each step:\n",
      "\n",
      "**Step 1: Calculate 453 √ó 7**\n",
      "- 3 √ó 7 = 21 (write 1, carry 2)\n",
      "- 5 √ó 7 = 35, plus carried 2 = 37 (write 7, carry 3)\n",
      "- 4 √ó 7 = 28, plus carried 3 = 31 (write 31)\n",
      "- Result: 3,171\n",
      "\n",
      "**Step 2: Calculate 453 √ó 20**\n",
      "- First calculate 453 √ó 2 = 906\n",
      "- Then multiply by 10 (add a zero): 9,060\n",
      "\n",
      "**Step 3: Add the partial products**\n",
      "- 3,171 + 9,060 = 12,231\n",
      "\n",
      "Therefore, **27 √ó 453 = 12,231**\n"
     ]
    }
   ],
   "source": [
    "def basic_thinking_example():\n",
    "    \"\"\"A simple example demonstrating extended thinking\"\"\"\n",
    "    \n",
    "    response = client.messages.create(\n",
    "        model=\"claude-sonnet-4-20250514\",\n",
    "        max_tokens=6000,  # Must be greater than budget_tokens\n",
    "        thinking={\n",
    "            \"type\": \"enabled\",\n",
    "            \"budget_tokens\": 5000  # How many tokens Claude can use for thinking\n",
    "        },\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is 27 * 453? Show me how you calculate this step by step.\"\n",
    "        }]\n",
    "    )\n",
    "    \n",
    "    # Process the response\n",
    "    for block in response.content:\n",
    "        if block.type == \"thinking\":\n",
    "            print(\"ü§î Claude's Thinking Process:\")\n",
    "            print(\"-\" * 50)\n",
    "            print(block.thinking)\n",
    "            print(\"-\" * 50)\n",
    "            print()\n",
    "        elif block.type == \"text\":\n",
    "            print(\"‚úÖ Final Answer:\")\n",
    "            print(block.text)\n",
    "\n",
    "# Run the example\n",
    "basic_thinking_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Parameters\n",
    "\n",
    "- **`type: \"enabled\"`**: Turns on extended thinking\n",
    "- **`budget_tokens`**: Maximum tokens Claude can use for reasoning\n",
    "  - Minimum: 1,024 tokens\n",
    "  - For complex tasks: 16,000+ tokens\n",
    "  - For very complex tasks: 32,000+ tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='thinking-blocks'></a>\n",
    "## 4. Understanding Thinking Blocks\n",
    "\n",
    "Let's explore how thinking blocks work and what information they contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Response Structure Analysis\n",
      "============================================================\n",
      "\n",
      "Block 1:\n",
      "  Type: thinking\n",
      "  Thinking Summary Length: 1798 characters\n",
      "  Has Signature: Yes\n",
      "\n",
      "  Thinking Content (first 500 chars):\n",
      "  Let me work through this step by step.\n",
      "\n",
      "Given list: [15, 23, 8, 42, 16, 4, 30, 12]\n",
      "\n",
      "1. Find the median:\n",
      "First, I need to sort the list in ascending order:\n",
      "[4, 8, 12, 15, 16, 23, 30, 42]\n",
      "\n",
      "There are 8 numbers (even count), so the median is the average of the 4th and 5th values.\n",
      "4th value: 15\n",
      "5th value: 16\n",
      "Median = (15 + 16) / 2 = 31 / 2 = 15.5\n",
      "\n",
      "2. Calculate the mean:\n",
      "Sum = 15 + 23 + 8 + 42 + 16 + 4 + 30 + 12 = 150\n",
      "Count = 8\n",
      "Mean = 150 / 8 = 18.75\n",
      "\n",
      "3. Identify outliers using IQR method:\n",
      "First, I ne...\n",
      "\n",
      "Block 2:\n",
      "  Type: text\n",
      "  Text Length: 1331 characters\n",
      "\n",
      "  Final Response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "I'll analyze your data step by step: [15, 23, 8, 42, 16, 4, 30, 12]\n",
       "\n",
       "## 1. Median\n",
       "First, I'll sort the data: [4, 8, 12, 15, 16, 23, 30, 42]\n",
       "\n",
       "With 8 values (even number), the median is the average of the 4th and 5th values:\n",
       "**Median = (15 + 16) √∑ 2 = 15.5**\n",
       "\n",
       "## 2. Mean\n",
       "Sum: 15 + 23 + 8 + 42 + 16 + 4 + 30 + 12 = 150\n",
       "**Mean = 150 √∑ 8 = 18.75**\n",
       "\n",
       "## 3. Outliers using IQR Method\n",
       "From the sorted data [4, 8, 12, 15, 16, 23, 30, 42]:\n",
       "\n",
       "- **Q1** (1st quartile): Average of 2nd and 3rd values = (8 + 12) √∑ 2 = 10\n",
       "- **Q3** (3rd quartile): Average of 6th and 7th values = (23 + 30) √∑ 2 = 26.5\n",
       "- **IQR** = Q3 - Q1 = 26.5 - 10 = 16.5\n",
       "\n",
       "Outlier boundaries:\n",
       "- Lower fence: Q1 - 1.5(IQR) = 10 - 24.75 = -14.75\n",
       "- Upper fence: Q3 + 1.5(IQR) = 26.5 + 24.75 = 51.25\n",
       "\n",
       "**No outliers detected** - all values fall within the range [-14.75, 51.25]\n",
       "\n",
       "## 4. What this data might represent\n",
       "Given the range (4-42) and distribution, this could represent:\n",
       "- **Ages** of people in a group (perhaps a mixed-age class or team)\n",
       "- **Test scores** (out of 50 points)\n",
       "- **Daily sales quantities** of a product\n",
       "- **Response times** in seconds for a task\n",
       "- **Temperature readings** in Celsius\n",
       "- **Number of items** per category in an inventory\n",
       "\n",
       "The relatively small range and whole numbers suggest it's likely a count or measurement that doesn't require decimal precision."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def analyze_thinking_blocks():\n",
    "    \"\"\"Demonstrate the structure of thinking blocks\"\"\"\n",
    "    \n",
    "    response = client.messages.create(\n",
    "        model=\"claude-sonnet-4-20250514\",\n",
    "        max_tokens=10000,\n",
    "        thinking={\n",
    "            \"type\": \"enabled\",\n",
    "            \"budget_tokens\": 8000\n",
    "        },\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"I have a list of numbers: [15, 23, 8, 42, 16, 4, 30, 12].\n",
    "            \n",
    "            Please:\n",
    "            1. Find the median\n",
    "            2. Calculate the mean\n",
    "            3. Identify any outliers using the IQR method\n",
    "            4. Suggest what this data might represent\"\"\"\n",
    "        }]\n",
    "    )\n",
    "    \n",
    "    # Analyze the response structure\n",
    "    print(\"üìä Response Structure Analysis\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i, block in enumerate(response.content):\n",
    "        print(f\"\\nBlock {i + 1}:\")\n",
    "        print(f\"  Type: {block.type}\")\n",
    "        \n",
    "        if block.type == \"thinking\":\n",
    "            # In Claude 4, thinking is summarized\n",
    "            print(f\"  Thinking Summary Length: {len(block.thinking)} characters\")\n",
    "            print(f\"  Has Signature: {'Yes' if hasattr(block, 'signature') else 'No'}\")\n",
    "            print(\"\\n  Thinking Content (first 500 chars):\")\n",
    "            print(f\"  {block.thinking[:500]}...\")\n",
    "        elif block.type == \"text\":\n",
    "            print(f\"  Text Length: {len(block.text)} characters\")\n",
    "            print(\"\\n  Final Response:\")\n",
    "            display(Markdown(block.text))\n",
    "\n",
    "analyze_thinking_blocks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Points About Thinking Blocks\n",
    "\n",
    "1. **Summarization**: Claude 4 models provide summarized thinking, not full reasoning\n",
    "2. **Billing**: You're charged for full thinking tokens, not the summary\n",
    "3. **Signature**: Each thinking block includes a cryptographic signature for verification\n",
    "4. **Privacy**: Thinking blocks help prevent misuse while maintaining intelligence benefits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='advanced-features'></a>\n",
    "## 5. Advanced Features\n",
    "\n",
    "### 5.1 Streaming Responses\n",
    "\n",
    "For better user experience, especially with longer thinking times, you can stream responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåä Streaming Extended Thinking Example\n",
      "============================================================\n",
      "\n",
      "ü§î Claude is thinking........... Done thinking!\n",
      "\n",
      "\n",
      "‚úÖ Final Response:\n",
      "I'll design a comprehensive REST API for a todo list application with all the considerations you mentioned.\n",
      "\n",
      "## Todo List REST API Design\n",
      "\n",
      "### Base URL\n",
      "```\n",
      "https://api.todoapp.com/v1\n",
      "```\n",
      "\n",
      "### Authentication\n",
      "Using JWT (JSON Web Tokens) with Bearer authentication:\n",
      "```\n",
      "Authorization: Bearer <token>\n",
      "```\n",
      "\n",
      "### Response Format\n",
      "All responses follow this structure:\n",
      "```json\n",
      "{\n",
      "  \"success\": true|false,\n",
      "  \"data\": {...} | [...],\n",
      "  \"message\": \"string\",\n",
      "  \"errors\": [...],\n",
      "  \"metadata\": {\n",
      "    \"timestamp\": \"2024-01-15T10:30:00Z\",\n",
      "    \"version\": \"1.0\"\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "### API Endpoints\n",
      "\n",
      "#### 1. Authentication Endpoints\n",
      "\n",
      "**Register User**\n",
      "```http\n",
      "POST /auth/register\n",
      "Content-Type: application/json\n",
      "\n",
      "{\n",
      "  \"email\": \"user@example.com\",\n",
      "  \"password\": \"securePassword123\",\n",
      "  \"name\": \"John Doe\"\n",
      "}\n",
      "\n",
      "Response (201 Created):\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"data\": {\n",
      "    \"user\": {\n",
      "      \"id\": \"usr_123456\",\n",
      "      \"email\": \"user@example.com\",\n",
      "      \"name\": \"John Doe\",\n",
      "      \"created_at\": \"2024-01-15T10:30:00Z\"\n",
      "    },\n",
      "    \"token\": \"eyJhbGciOiJIUzI1NiIs...\"\n",
      "  },\n",
      "  \"message\": \"User registered successfully\"\n",
      "}\n",
      "```\n",
      "\n",
      "**Login**\n",
      "```http\n",
      "POST /auth/login\n",
      "Content-Type: application/json\n",
      "\n",
      "{\n",
      "  \"email\": \"user@example.com\",\n",
      "  \"password\": \"securePassword123\"\n",
      "}\n",
      "\n",
      "Response (200 OK):\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"data\": {\n",
      "    \"user\": {\n",
      "      \"id\": \"usr_123456\",\n",
      "      \"email\": \"user@example.com\",\n",
      "      \"name\": \"John Doe\"\n",
      "    },\n",
      "    \"token\": \"eyJhbGciOiJIUzI1NiIs...\",\n",
      "    \"refresh_token\": \"rt_abcdef123456\"\n",
      "  },\n",
      "  \"message\": \"Login successful\"\n",
      "}\n",
      "```\n",
      "\n",
      "#### 2. Todo CRUD Operations\n",
      "\n",
      "**Create Todo**\n",
      "```http\n",
      "POST /todos\n",
      "Authorization: Bearer <token>\n",
      "Content-Type: application/json\n",
      "\n",
      "{\n",
      "  \"title\": \"Complete API documentation\",\n",
      "  \"description\": \"Write comprehensive API docs\",\n",
      "  \"due_date\": \"2024-01-20T17:00:00Z\",\n",
      "  \"priority\": \"high\",\n",
      "  \"tags\": [\"work\", \"urgent\"]\n",
      "}\n",
      "\n",
      "Response (201 Created):\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"data\": {\n",
      "    \"id\": \"todo_789012\",\n",
      "    \"title\": \"Complete API documentation\",\n",
      "    \"description\": \"Write comprehensive API docs\",\n",
      "    \"status\": \"pending\",\n",
      "    \"priority\": \"high\",\n",
      "    \"due_date\": \"2024-01-20T17:00:00Z\",\n",
      "    \"tags\": [\"work\", \"urgent\"],\n",
      "    \"created_at\": \"2024-01-15T10:30:00Z\",\n",
      "    \"updated_at\": \"2024-01-15T10:30:00Z\",\n",
      "    \"user_id\": \"usr_123456\"\n",
      "  },\n",
      "  \"message\": \"Todo created successfully\"\n",
      "}\n",
      "```\n",
      "\n",
      "**Get All Todos**\n",
      "```http\n",
      "GET /todos?page=1&limit=10&status=pending&sort=due_date&order=asc\n",
      "Authorization: Bearer <token>\n",
      "\n",
      "Response (200 OK):\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"id\": \"todo_789012\",\n",
      "      \"title\": \"Complete API documentation\",\n",
      "      \"description\": \"Write comprehensive API docs\",\n",
      "      \"status\": \"pending\",\n",
      "      \"priority\": \"high\",\n",
      "      \"due_date\": \"2024-01-20T17:00:00Z\",\n",
      "      \"tags\": [\"work\", \"urgent\"],\n",
      "      \"created_at\": \"2024-01-15T10:30:00Z\",\n",
      "      \"updated_at\": \"2024-01-15T10:30:00Z\"\n",
      "    }\n",
      "  ],\n",
      "  \"message\": \"Todos retrieved successfully\",\n",
      "  \"metadata\": {\n",
      "    \"timestamp\": \"2024-01-15T10:30:00Z\",\n",
      "    \"version\": \"1.0\",\n",
      "    \"pagination\": {\n",
      "      \"page\": 1,\n",
      "      \"limit\": 10,\n",
      "      \"total\": 25,\n",
      "      \"total_pages\": 3\n",
      "    }\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "**Get Single Todo**\n",
      "```http\n",
      "GET /todos/{id}\n",
      "Authorization: Bearer <token>\n",
      "\n",
      "Response (200 OK):\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"data\": {\n",
      "    \"id\": \"todo_789012\",\n",
      "    \"title\": \"Complete API documentation\",\n",
      "    \"description\": \"Write comprehensive API docs\",\n",
      "    \"status\": \"pending\",\n",
      "    \"priority\": \"high\",\n",
      "    \"due_date\": \"2024-01-20T17:00:00Z\",\n",
      "    \"tags\": [\"work\", \"urgent\"],\n",
      "    \"created_at\": \"2024-01-15T10:30:00Z\",\n",
      "    \"updated_at\": \"2024-01-15T10:30:00Z\",\n",
      "    \"user_id\": \"usr_123456\"\n",
      "  },\n",
      "  \"message\": \"Todo retrieved successfully\"\n",
      "}\n",
      "```\n",
      "\n",
      "**Update Todo**\n",
      "```http\n",
      "PUT /todos/{id}\n",
      "Authorization: Bearer <token>\n",
      "Content-Type: application/json\n",
      "\n",
      "{\n",
      "  \"title\": \"Complete API documentation v2\",\n",
      "  \"status\": \"in_progress\",\n",
      "  \"priority\": \"medium\"\n",
      "}\n",
      "\n",
      "Response (200 OK):\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"data\": {\n",
      "    \"id\": \"todo_789012\",\n",
      "    \"title\": \"Complete API documentation v2\",\n",
      "    \"description\": \"Write comprehensive API docs\",\n",
      "    \"status\": \"in_progress\",\n",
      "    \"priority\": \"medium\",\n",
      "    \"due_date\": \"2024-01-20T17:00:00Z\",\n",
      "    \"tags\": [\"work\", \"urgent\"],\n",
      "    \"created_at\": \"2024-01-15T10:30:00Z\",\n",
      "    \"updated_at\": \"2024-01-15T11:45:00Z\",\n",
      "    \"user_id\": \"usr_123456\"\n",
      "  },\n",
      "  \"message\": \"Todo updated successfully\"\n",
      "}\n",
      "```\n",
      "\n",
      "**Delete Todo**\n",
      "```http\n",
      "DELETE /todos/{id}\n",
      "Authorization: Bearer <token>\n",
      "\n",
      "Response (200 OK):\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"data\": null,\n",
      "  \"message\": \"Todo deleted successfully\"\n",
      "}\n",
      "```\n",
      "\n",
      "### Error Handling\n",
      "\n",
      "**Validation Error (400)**\n",
      "```json\n",
      "{\n",
      "  \"success\": false,\n",
      "  \"data\": null,\n",
      "  \"message\": \"Validation failed\",\n",
      "  \"errors\": [\n",
      "    {\n",
      "      \"field\": \"title\",\n",
      "      \"message\": \"Title is required and must be between 3-100 characters\"\n",
      "    },\n",
      "    {\n",
      "      \"field\": \"due_date\",\n",
      "      \"message\": \"Due date must be in the future\"\n",
      "    }\n",
      "  ],\n",
      "  \"metadata\": {\n",
      "    \"timestamp\": \"2024-01-15T10:30:00Z\",\n",
      "    \"version\": \"1.0\"\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "**Authentication Error (401)**\n",
      "```json\n",
      "{\n",
      "  \"success\": false,\n",
      "  \"data\": null,\n",
      "  \"message\": \"Authentication failed\",\n",
      "  \"errors\": [\n",
      "    {\n",
      "      \"code\": \"INVALID_TOKEN\",\n",
      "      \"message\": \"The provided token is invalid or expired\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "**Not Found Error (404)**\n",
      "```json\n",
      "{\n",
      "  \"success\": false,\n",
      "  \"data\": null,\n",
      "  \"message\": \"Resource not found\",\n",
      "  \"errors\": [\n",
      "    {\n",
      "      \"code\": \"TODO_NOT_FOUND\",\n",
      "      \"message\": \"Todo with id 'todo_789012' not found\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "**Server Error (500)**\n",
      "```json\n",
      "{\n",
      "  \"success\": false,\n",
      "  \"data\": null,\n",
      "  \"message\": \"Internal server error\",\n",
      "  \"errors\": [\n",
      "    {\n",
      "      \"code\": \"INTERNAL_ERROR\",\n",
      "      \"message\": \"An unexpected error occurred. Please try again later.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "### Data Validation Rules\n",
      "\n",
      "```javascript\n",
      "// Todo Schema Validation\n",
      "{\n",
      "  title: {\n",
      "    type: \"string\",\n",
      "    required: true,\n",
      "    minLength: 3,\n",
      "    maxLength: 100\n",
      "  },\n",
      "  description: {\n",
      "    type: \"string\",\n",
      "    maxLength: 500\n",
      "  },\n",
      "  status: {\n",
      "    type: \"string\",\n",
      "    enum: [\"pending\", \"in_progress\", \"completed\", \"cancelled\"],\n",
      "    default: \"pending\"\n",
      "  },\n",
      "  priority: {\n",
      "    type: \"string\",\n",
      "    enum: [\"low\", \"medium\", \"high\"],\n",
      "    default: \"medium\"\n",
      "  },\n",
      "  due_date: {\n",
      "    type: \"datetime\",\n",
      "    format: \"ISO8601\",\n",
      "    futureOnly: true\n",
      "  },\n",
      "  tags: {\n",
      "    type: \"array\",\n",
      "    items: \"string\",\n",
      "    maxItems: 5,\n",
      "    uniqueItems: true\n",
      "  }\n",
      "}\n",
      "\n",
      "// User Registration Validation\n",
      "{\n",
      "  email: {\n",
      "    type: \"string\",\n",
      "    required: true,\n",
      "    format: \"email\",\n",
      "    unique: true\n",
      "  },\n",
      "  password: {\n",
      "    type: \"string\",\n",
      "    required: true,\n",
      "    minLength: 8,\n",
      "    pattern: \"^(?=.*[a-z])(?=.*[A-Z])(?=.*\\\\d).+$\"\n",
      "  },\n",
      "  name: {\n",
      "    type: \"string\",\n",
      "    required: true,\n",
      "    minLength: 2,\n",
      "    maxLength: 50\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "### Additional Features\n",
      "\n",
      "**Batch Operations**\n",
      "```http\n",
      "POST /todos/batch\n",
      "Authorization: Bearer <token>\n",
      "Content-Type: application/json\n",
      "\n",
      "{\n",
      "  \"operation\": \"update\",\n",
      "  \"ids\": [\"todo_123\", \"todo_456\", \"todo_789\"],\n",
      "  \"data\": {\n",
      "    \"status\": \"completed\"\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "**Search Todos**\n",
      "```http\n",
      "GET /todos/search?q=documentation&tags=work,urgent\n",
      "Authorization: Bearer <token>\n",
      "```\n",
      "\n",
      "**Export Todos**\n",
      "```http\n",
      "GET /todos/export?format=csv\n",
      "Authorization: Bearer <token>\n",
      "```\n",
      "\n",
      "### Rate Limiting Headers\n",
      "```http\n",
      "X-RateLimit-Limit: 100\n",
      "X-RateLimit-Remaining: 95\n",
      "X-RateLimit-Reset: 1642248000\n",
      "```\n",
      "\n",
      "### Security Considerations\n",
      "1. **HTTPS only** - All endpoints require HTTPS\n",
      "2. **JWT expiration** - Tokens expire after 24 hours\n",
      "3. **Rate limiting** - 100 requests per hour per user\n",
      "4. **Input sanitization** - All inputs are sanitized to prevent XSS\n",
      "5. **SQL injection prevention** - Using parameterized queries\n",
      "6. **CORS configuration** - Properly configured for allowed origins\n",
      "\n",
      "This API design provides a robust, secure, and scalable foundation for a todo list application with proper authentication, validation, and error handling."
     ]
    }
   ],
   "source": [
    "def stream_thinking_example():\n",
    "    \"\"\"Demonstrate streaming with extended thinking\"\"\"\n",
    "    \n",
    "    print(\"üåä Streaming Extended Thinking Example\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    with client.messages.stream(\n",
    "        model=\"claude-opus-4-20250514\",\n",
    "        max_tokens=15000,  # Must be greater than budget_tokens\n",
    "        thinking={\"type\": \"enabled\", \"budget_tokens\": 10000},\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"Design a simple REST API for a todo list application. \n",
    "            Include endpoints for CRUD operations and consider:\n",
    "            - Authentication\n",
    "            - Error handling\n",
    "            - Data validation\n",
    "            - Response formats\"\"\"\n",
    "        }],\n",
    "    ) as stream:\n",
    "        current_block_type = None\n",
    "        \n",
    "        for event in stream:\n",
    "            if event.type == \"content_block_start\":\n",
    "                current_block_type = event.content_block.type\n",
    "                if current_block_type == \"thinking\":\n",
    "                    print(\"\\nü§î Claude is thinking...\", end=\"\", flush=True)\n",
    "                elif current_block_type == \"text\":\n",
    "                    print(\"\\n\\n‚úÖ Final Response:\\n\", end=\"\", flush=True)\n",
    "            \n",
    "            elif event.type == \"content_block_delta\":\n",
    "                if event.delta.type == \"thinking_delta\":\n",
    "                    # Show progress dots for thinking\n",
    "                    print(\".\", end=\"\", flush=True)\n",
    "                elif event.delta.type == \"text_delta\":\n",
    "                    print(event.delta.text, end=\"\", flush=True)\n",
    "            \n",
    "            elif event.type == \"content_block_stop\":\n",
    "                if current_block_type == \"thinking\":\n",
    "                    print(\" Done thinking!\")\n",
    "\n",
    "stream_thinking_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Extended Thinking with Tool Use\n",
    "\n",
    "Extended thinking can be combined with tool use for even more powerful applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ Party Planning with Extended Thinking\n",
      "============================================================\n",
      "\n",
      "ü§î Planning Process:\n",
      "Let me break down this party planning calculation:\n",
      "\n",
      "1. Pizza calculation:\n",
      "   - 25 people √ó 3 slices each = 75 slices total\n",
      "   - 8 slices per pizza\n",
      "   - Number of pizzas needed = 75 √∑ 8 = 9.375, so I need to round up to 10 pizzas\n",
      "   - Cost of pizzas = 10 √ó $12 = $120\n",
      "\n",
      "2. Soda calculation:\n",
      "   - 25 people √ó 2 sodas each = 50 sodas\n",
      "   - Cost per soda = $1.50\n",
      "   - Total soda cost = 50 √ó $1.50 = $75\n",
      "\n",
      "3. Dessert calculation:\n",
      "   - 25 people √ó 1 dessert each = 25 desserts\n",
      "   - Cost per dessert = $3.00\n",
      "   - Total dessert cost = 25 √ó $3.00 = $75\n",
      "\n",
      "4. Total cost = Pizza cost + Soda cost + Dessert cost = $120 + $75 + $75 = $270\n",
      "\n",
      "Let me use the calculator to verify these calculations....\n",
      "\n",
      "\n",
      "üìã Final Plan:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "I'll help you calculate the quantities needed and total cost for your party. Let me break this down step by step."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Using tool: calculator\n",
      "   Input: {'expression': '25 * 3'}\n"
     ]
    }
   ],
   "source": [
    "def thinking_with_tools_example():\n",
    "    \"\"\"Demonstrate extended thinking with tool use\"\"\"\n",
    "    \n",
    "    # Define a simple calculator tool\n",
    "    tools = [{\n",
    "        \"name\": \"calculator\",\n",
    "        \"description\": \"Perform mathematical calculations\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"expression\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Mathematical expression to evaluate\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"expression\"]\n",
    "        }\n",
    "    }]\n",
    "    \n",
    "    response = client.messages.create(\n",
    "        model=\"claude-sonnet-4-20250514\",\n",
    "        max_tokens=10000,        # Total tokens available\n",
    "        thinking={\n",
    "            \"type\": \"enabled\",\n",
    "            \"budget_tokens\": 8000   # 80% for thinking, 20% for response\n",
    "        },\n",
    "        tools=tools,\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"I'm planning a party for 25 people. Each person will eat:\n",
    "            - 3 slices of pizza (8 slices per pizza)\n",
    "            - 2 sodas ($1.50 each)\n",
    "            - 1 dessert ($3.00 each)\n",
    "            \n",
    "            Pizzas cost $12 each. Calculate the total cost and quantities needed.\"\"\"\n",
    "        }]\n",
    "    )\n",
    "    \n",
    "    print(\"üéâ Party Planning with Extended Thinking\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for block in response.content:\n",
    "        if block.type == \"thinking\":\n",
    "            print(\"\\nü§î Planning Process:\")\n",
    "            print(block.thinking[:1000] + \"...\\n\")\n",
    "        elif block.type == \"tool_use\":\n",
    "            print(f\"\\nüîß Using tool: {block.name}\")\n",
    "            print(f\"   Input: {block.input}\")\n",
    "        elif block.type == \"text\":\n",
    "            print(\"\\nüìã Final Plan:\")\n",
    "            display(Markdown(block.text))\n",
    "\n",
    "# RULE OF THUMB FOR TOKEN ALLOCATION:\n",
    "# Simple tasks:  max_tokens=3000, budget_tokens=2000  (67% thinking)\n",
    "# Medium tasks:  max_tokens=8000, budget_tokens=6000  (75% thinking)  \n",
    "# Complex tasks: max_tokens=12000, budget_tokens=10000 (83% thinking)\n",
    "# Always ensure: max_tokens > budget_tokens + 500 (minimum response buffer)\n",
    "\n",
    "thinking_with_tools_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='best-practices'></a>\n",
    "## 6. Best Practices\n",
    "\n",
    "### 6.1 Choosing the Right Budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí∞ Thinking Budget Comparison\n",
      "============================================================\n",
      "\n",
      "üìä Budget: 1,024 tokens | Max: 2,000 tokens\n",
      "--------------------------------------------------\n",
      "‚è±Ô∏è  Time: 19.40 seconds\n",
      "üß† Thinking length: 1,618 characters\n",
      "üìù Response length: 1,676 characters\n",
      "üí° Response preview: ## Current Business Analysis\n",
      "\n",
      "**Existing Performance:**\n",
      "- Location A: $2,500/day ‚Üí $875/day profit (35% margin)\n",
      "- Location B: $1,800/day ‚Üí $630/day profit (35% margin)  \n",
      "- Location C: $3,200/day ‚Üí $1,...\n",
      "\n",
      "üìä Budget: 5,000 tokens | Max: 7,000 tokens\n",
      "--------------------------------------------------\n",
      "‚è±Ô∏è  Time: 22.31 seconds\n",
      "üß† Thinking length: 2,072 characters\n",
      "üìù Response length: 1,708 characters\n",
      "üí° Response preview: ## Current Financial Analysis\n",
      "\n",
      "**Existing Performance:**\n",
      "- Location A: $2,500/day ‚Üí $875/day profit (35% margin)\n",
      "- Location B: $1,800/day ‚Üí $630/day profit  \n",
      "- Location C: $3,200/day ‚Üí $1,120/day prof...\n",
      "\n",
      "üìä Budget: 15,000 tokens | Max: 17,000 tokens\n",
      "--------------------------------------------------\n",
      "‚è±Ô∏è  Time: 27.27 seconds\n",
      "üß† Thinking length: 2,335 characters\n",
      "üìù Response length: 1,852 characters\n",
      "üí° Response preview: ## Current Performance Analysis\n",
      "\n",
      "Let me first analyze the existing locations:\n",
      "\n",
      "**Location A:** $2,500/day revenue ‚Üí $875/day profit (35% margin)\n",
      "**Location B:** $1,800/day revenue ‚Üí $630/day profit (3...\n",
      "\n",
      "üéØ Token Allocation Guidelines\n",
      "==================================================\n",
      "Rule of thumb: max_tokens = budget_tokens + response_buffer\n",
      "\n",
      "üìã Simple questions     | Budget: 1K-2K    | Max: 3K-4K\n",
      "üìã Complex analysis     | Budget: 5K-10K   | Max: 7K-12K\n",
      "üìã Deep reasoning       | Budget: 15K-20K  | Max: 17K-22K\n",
      "üìã Maximum thinking     | Budget: 25K-30K  | Max: 27K-32K\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def budget_comparison():\n",
    "    \"\"\"Compare different thinking budgets\"\"\"\n",
    "    \n",
    "    problem = \"\"\"Analyze this business scenario:\n",
    "    A coffee shop has 3 locations. Location A makes $2,500/day, \n",
    "    Location B makes $1,800/day, and Location C makes $3,200/day.\n",
    "    Operating costs are 65% of revenue. They want to open a 4th location.\n",
    "    What factors should they consider and what's the minimum daily revenue \n",
    "    the new location needs to be profitable?\"\"\"\n",
    "    \n",
    "    # Budget configurations with appropriate max_tokens\n",
    "    configs = [\n",
    "        {\"budget\": 1024, \"max_tokens\": 2000},    # Small thinking budget\n",
    "        {\"budget\": 5000, \"max_tokens\": 7000},    # Medium thinking budget  \n",
    "        {\"budget\": 15000, \"max_tokens\": 17000}   # Large thinking budget\n",
    "    ]\n",
    "    \n",
    "    print(\"üí∞ Thinking Budget Comparison\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for config in configs:\n",
    "        budget = config[\"budget\"]\n",
    "        max_tokens = config[\"max_tokens\"]\n",
    "        \n",
    "        print(f\"\\nüìä Budget: {budget:,} tokens | Max: {max_tokens:,} tokens\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            response = client.messages.create(\n",
    "                model=\"claude-sonnet-4-20250514\",\n",
    "                max_tokens=max_tokens,\n",
    "                thinking={\"type\": \"enabled\", \"budget_tokens\": budget},\n",
    "                messages=[{\"role\": \"user\", \"content\": problem}]\n",
    "            )\n",
    "            \n",
    "            elapsed_time = time.time() - start_time\n",
    "            \n",
    "            # Get response and thinking content\n",
    "            response_text = \"\"\n",
    "            thinking_text = \"\"\n",
    "            \n",
    "            for block in response.content:\n",
    "                if block.type == \"text\":\n",
    "                    response_text = block.text\n",
    "                elif block.type == \"thinking\":\n",
    "                    thinking_text = block.thinking\n",
    "            \n",
    "            print(f\"‚è±Ô∏è  Time: {elapsed_time:.2f} seconds\")\n",
    "            print(f\"üß† Thinking length: {len(thinking_text):,} characters\")\n",
    "            print(f\"üìù Response length: {len(response_text):,} characters\")\n",
    "            print(f\"üí° Response preview: {response_text[:200]}...\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {str(e)}\")\n",
    "\n",
    "# Rule of thumb for token allocation\n",
    "def show_token_guidelines():\n",
    "    \"\"\"Show recommended token allocation guidelines\"\"\"\n",
    "    \n",
    "    print(\"\\nüéØ Token Allocation Guidelines\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Rule of thumb: max_tokens = budget_tokens + response_buffer\")\n",
    "    print()\n",
    "    \n",
    "    guidelines = [\n",
    "        {\"use_case\": \"Simple questions\", \"budget\": \"1K-2K\", \"max_tokens\": \"3K-4K\"},\n",
    "        {\"use_case\": \"Complex analysis\", \"budget\": \"5K-10K\", \"max_tokens\": \"7K-12K\"},\n",
    "        {\"use_case\": \"Deep reasoning\", \"budget\": \"15K-20K\", \"max_tokens\": \"17K-22K\"},\n",
    "        {\"use_case\": \"Maximum thinking\", \"budget\": \"25K-30K\", \"max_tokens\": \"27K-32K\"}\n",
    "    ]\n",
    "    \n",
    "    for guide in guidelines:\n",
    "        print(f\"üìã {guide['use_case']:<20} | Budget: {guide['budget']:<8} | Max: {guide['max_tokens']}\")\n",
    "\n",
    "# Run both examples\n",
    "budget_comparison()\n",
    "show_token_guidelines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Effective Prompting for Extended Thinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Best Practices Example: Structured Investment Analysis\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Investment Analysis\n",
       "\n",
       "### 1. Analysis of Each Option\n",
       "\n",
       "**Option A: Stock Portfolio**\n",
       "- **Strengths**: Highest expected return (8%), excellent liquidity, reasonable minimum investment\n",
       "- **Weaknesses**: High risk level exceeds investor's medium risk tolerance\n",
       "- **Suitability**: Good for long-term growth component, but shouldn't be the sole investment\n",
       "\n",
       "**Option B: Real Estate**\n",
       "- **Strengths**: Matches medium risk tolerance, provides diversification, solid returns (6%)\n",
       "- **Weaknesses**: Low liquidity problematic for flexibility, high minimum investment consumes 67% of available capital\n",
       "- **Suitability**: Could work as part of diversified portfolio, but concentration risk is concerning\n",
       "\n",
       "**Option C: Bonds**\n",
       "- **Strengths**: Low risk, good liquidity, low minimum investment\n",
       "- **Weaknesses**: 4% return may not meet long-term retirement goals, too conservative for 15-year horizon\n",
       "- **Suitability**: Important for portfolio stability but insufficient as primary investment\n",
       "\n",
       "### 2. Recommended Allocation\n",
       "\n",
       "**Diversified Portfolio Approach: $75,000 total**\n",
       "\n",
       "- **Stocks**: $35,000 (47%)\n",
       "- **Bonds**: $25,000 (33%)\n",
       "- **Cash Reserve**: $15,000 (20%)\n",
       "\n",
       "**Skip real estate** for this investor due to liquidity constraints and over-concentration risk.\n",
       "\n",
       "### 3. Justification\n",
       "\n",
       "**Why this allocation works best:**\n",
       "\n",
       "1. **Risk-Return Balance**: The 47% stock allocation provides growth potential while the 33% bond allocation offers stability, creating a balanced medium-risk profile.\n",
       "\n",
       "2. **Flexibility**: Avoiding the $50,000 real estate minimum prevents over-concentration and maintains liquidity for opportunities or emergencies.\n",
       "\n",
       "3. **Time Horizon Optimization**: With 15 years until the goal, this allocation can weather market volatility while positioning for long-term growth.\n",
       "\n",
       "4. **Expected Portfolio Return**: Approximately 6.4% annually [(0.47 √ó 8%) + (0.33 √ó 4%) + (0.20 √ó 2%)]\n",
       "\n",
       "5. **Liquidity**: High stock liquidity and medium bond liquidity provide flexibility for rebalancing or emergency access.\n",
       "\n",
       "**Alternative Consideration**: If the investor strongly desires real estate exposure, they could allocate $50,000 to real estate and $25,000 to stocks, but this creates concentration risk and reduces flexibility.\n",
       "\n",
       "This recommended allocation balances growth potential with the investor's medium risk tolerance while maintaining the flexibility crucial for long-term retirement planning."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def prompting_best_practices():\n",
    "    \"\"\"Demonstrate effective prompting strategies\"\"\"\n",
    "    \n",
    "    # Good prompt - clear, specific, structured\n",
    "    good_prompt = \"\"\"Analyze the following investment options and recommend the best choice:\n",
    "\n",
    "Option A: Stock Portfolio\n",
    "- Expected annual return: 8%\n",
    "- Risk level: High\n",
    "- Minimum investment: $10,000\n",
    "- Liquidity: High (can sell anytime)\n",
    "\n",
    "Option B: Real Estate\n",
    "- Expected annual return: 6%\n",
    "- Risk level: Medium\n",
    "- Minimum investment: $50,000\n",
    "- Liquidity: Low (takes months to sell)\n",
    "\n",
    "Option C: Bonds\n",
    "- Expected annual return: 4%\n",
    "- Risk level: Low\n",
    "- Minimum investment: $5,000\n",
    "- Liquidity: Medium\n",
    "\n",
    "Investor Profile:\n",
    "- Age: 35\n",
    "- Investment horizon: 15 years\n",
    "- Risk tolerance: Medium\n",
    "- Available capital: $75,000\n",
    "- Goal: Retirement savings\n",
    "\n",
    "Please provide:\n",
    "1. Analysis of each option\n",
    "2. Recommended allocation\n",
    "3. Justification for your recommendation\"\"\"\n",
    "    \n",
    "    response = client.messages.create(\n",
    "        model=\"claude-sonnet-4-20250514\",\n",
    "        max_tokens=15000,  # Total tokens (thinking + response)\n",
    "        thinking={\"type\": \"enabled\", \"budget_tokens\": 12000},  # Just thinking tokens\n",
    "        messages=[{\"role\": \"user\", \"content\": good_prompt}]\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Best Practices Example: Structured Investment Analysis\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for block in response.content:\n",
    "        if block.type == \"text\":\n",
    "            display(Markdown(block.text))\n",
    "\n",
    "prompting_best_practices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Prompting Tips:\n",
    "\n",
    "1. **Be Specific**: Clearly state what you want analyzed\n",
    "2. **Provide Context**: Include all relevant information\n",
    "3. **Structure Your Input**: Use clear formatting and sections\n",
    "4. **Define Success Criteria**: Specify what a good answer looks like\n",
    "5. **Avoid Over-Prompting**: Don't tell Claude to \"think step by step\" - it already does!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='examples'></a>\n",
    "## 7. Real-World Examples\n",
    "\n",
    "### 7.1 Complex Document Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Best Practices Example: Structured Investment Analysis\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Investment Analysis and Recommendation\n",
       "\n",
       "## 1. Analysis of Each Option\n",
       "\n",
       "### Option A: Stock Portfolio\n",
       "**Strengths:**\n",
       "- Highest expected return (8%) - excellent for long-term growth\n",
       "- High liquidity provides flexibility\n",
       "- Accessible minimum investment ($10,000)\n",
       "\n",
       "**Weaknesses:**\n",
       "- High risk level exceeds your medium risk tolerance\n",
       "- Subject to market volatility\n",
       "- May cause emotional stress during market downturns\n",
       "\n",
       "### Option B: Real Estate\n",
       "**Strengths:**\n",
       "- Solid returns (6%) with medium risk - aligns with your risk tolerance\n",
       "- Inflation hedge and potential tax benefits\n",
       "- Diversification from traditional securities\n",
       "\n",
       "**Weaknesses:**\n",
       "- High minimum investment ($50,000) limits diversification\n",
       "- Low liquidity could be problematic for emergencies\n",
       "- Requires more active management\n",
       "\n",
       "### Option C: Bonds\n",
       "**Strengths:**\n",
       "- Low risk provides stability and capital preservation\n",
       "- Predictable income stream\n",
       "- Moderate liquidity for rebalancing\n",
       "\n",
       "**Weaknesses:**\n",
       "- Lowest returns (4%) may not keep pace with inflation\n",
       "- Limited growth potential over 15-year horizon\n",
       "- Interest rate risk\n",
       "\n",
       "## 2. Recommended Allocation\n",
       "\n",
       "Given your profile, I recommend a **balanced three-asset approach**:\n",
       "\n",
       "- **Stock Portfolio: $25,000 (33%)**\n",
       "- **Real Estate: $50,000 (67%)**\n",
       "- **Bonds: $0 initially**\n",
       "\n",
       "**Alternative if you prefer more conservative approach:**\n",
       "- **Stock Portfolio: $20,000 (27%)**\n",
       "- **Real Estate: $30,000 (40%)**\n",
       "- **Bonds: $25,000 (33%)**\n",
       "\n",
       "## 3. Justification\n",
       "\n",
       "### Primary Recommendation Rationale:\n",
       "\n",
       "1. **Risk Alignment:** The 67% real estate allocation matches your medium risk tolerance while the 33% stock allocation provides growth potential appropriate for your 15-year horizon.\n",
       "\n",
       "2. **Growth Potential:** At age 35, you can afford some equity exposure for inflation protection and wealth building, despite the higher risk.\n",
       "\n",
       "3. **Diversification:** Combining real estate and stocks provides diversification across asset classes and sectors.\n",
       "\n",
       "4. **Time Horizon Advantage:** 15 years allows you to ride out market volatility in the stock portion while benefiting from real estate's steady appreciation.\n",
       "\n",
       "5. **Capital Efficiency:** Uses your full $75,000 effectively while meeting minimum investment requirements.\n",
       "\n",
       "### Expected Portfolio Performance:\n",
       "- **Blended Return:** ~6.7% annually\n",
       "- **Risk Level:** Medium (balanced)\n",
       "- **Projected Value in 15 years:** ~$195,000\n",
       "\n",
       "### Key Considerations:\n",
       "- Maintain emergency fund separately\n",
       "- Review and rebalance annually\n",
       "- Consider gradually shifting toward bonds as you approach retirement\n",
       "- Monitor liquidity needs given real estate's low liquidity\n",
       "\n",
       "This allocation balances growth potential with risk management, making it suitable for your medium risk tolerance and long-term retirement goals."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def prompting_best_practices():\n",
    "    \"\"\"Demonstrate effective prompting strategies\"\"\"\n",
    "    \n",
    "    # Good prompt - clear, specific, structured\n",
    "    good_prompt = \"\"\"Analyze the following investment options and recommend the best choice:\n",
    "\n",
    "Option A: Stock Portfolio\n",
    "- Expected annual return: 8%\n",
    "- Risk level: High\n",
    "- Minimum investment: $10,000\n",
    "- Liquidity: High (can sell anytime)\n",
    "\n",
    "Option B: Real Estate\n",
    "- Expected annual return: 6%\n",
    "- Risk level: Medium\n",
    "- Minimum investment: $50,000\n",
    "- Liquidity: Low (takes months to sell)\n",
    "\n",
    "Option C: Bonds\n",
    "- Expected annual return: 4%\n",
    "- Risk level: Low\n",
    "- Minimum investment: $5,000\n",
    "- Liquidity: Medium\n",
    "\n",
    "Investor Profile:\n",
    "- Age: 35\n",
    "- Investment horizon: 15 years\n",
    "- Risk tolerance: Medium\n",
    "- Available capital: $75,000\n",
    "- Goal: Retirement savings\n",
    "\n",
    "Please provide:\n",
    "1. Analysis of each option\n",
    "2. Recommended allocation\n",
    "3. Justification for your recommendation\"\"\"\n",
    "    \n",
    "    response = client.messages.create(\n",
    "        model=\"claude-sonnet-4-20250514\",\n",
    "        max_tokens=15000,  # Total tokens (thinking + response)\n",
    "        thinking={\"type\": \"enabled\", \"budget_tokens\": 12000},  # Just thinking tokens\n",
    "        messages=[{\"role\": \"user\", \"content\": good_prompt}]\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Best Practices Example: Structured Investment Analysis\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for block in response.content:\n",
    "        if block.type == \"text\":\n",
    "            display(Markdown(block.text))\n",
    "\n",
    "prompting_best_practices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Code Architecture Planning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='performance'></a>\n",
    "## 8. Performance and Cost Considerations\n",
    "\n",
    "### Understanding Token Usage and Costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Extended thinking not available: \"Could not resolve authentication method. Expected either api_key or auth_token to be set. Or for one of the `X-Api-Key` or `Authorization` headers to be explicitly omitted\"\n",
      "Falling back to regular Claude response...\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "\"Could not resolve authentication method. Expected either api_key or auth_token to be set. Or for one of the `X-Api-Key` or `Authorization` headers to be explicitly omitted\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mbasic_thinking_example\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[32m      4\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m# Try with extended thinking first\u001b[39;00m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclaude-3-5-sonnet-20241022\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use a known available model\u001b[39;49;00m\n",
      "\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mthinking\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n",
      "\u001b[32m     10\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43menabled\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m     11\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbudget_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5000\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# How many tokens Claude can use for thinking\u001b[39;49;00m\n",
      "\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\n",
      "\u001b[32m     14\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m     15\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat is 27 * 453? Show me how you calculate this step by step.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n",
      "\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m     19\u001b[39m     \u001b[38;5;66;03m# Process the response\u001b[39;00m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mz:\\VSCODE Projects\\PythonProjects\\oreilly-reasoning-models\\oreilly-reasoning-models\\.venv\\Lib\\site-packages\\anthropic\\_utils\\_utils.py:283\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n",
      "\u001b[32m    282\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n",
      "\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mz:\\VSCODE Projects\\PythonProjects\\oreilly-reasoning-models\\oreilly-reasoning-models\\.venv\\Lib\\site-packages\\anthropic\\resources\\messages\\messages.py:997\u001b[39m, in \u001b[36mMessages.create\u001b[39m\u001b[34m(self, max_tokens, messages, model, metadata, service_tier, stop_sequences, stream, system, temperature, thinking, tool_choice, tools, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n",
      "\u001b[32m    991\u001b[39m     warnings.warn(\n",
      "\u001b[32m    992\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe model \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is deprecated and will reach end-of-life on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDEPRECATED_MODELS[model]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPlease migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\u001b[39m\u001b[33m\"\u001b[39m,\n",
      "\u001b[32m    993\u001b[39m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n",
      "\u001b[32m    994\u001b[39m         stacklevel=\u001b[32m3\u001b[39m,\n",
      "\u001b[32m    995\u001b[39m     )\n",
      "\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/v1/messages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    999\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n",
      "\u001b[32m   1001\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1002\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1003\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1004\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1005\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1006\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop_sequences\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_sequences\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1007\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1008\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1009\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1010\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthinking\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mthinking\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1011\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1012\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1013\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_k\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1014\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMessageCreateParamsStreaming\u001b[49m\n",
      "\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n",
      "\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMessageCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1019\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1020\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m   1021\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n",
      "\u001b[32m   1022\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1023\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMessage\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1024\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1025\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mRawMessageStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1026\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mz:\\VSCODE Projects\\PythonProjects\\oreilly-reasoning-models\\oreilly-reasoning-models\\.venv\\Lib\\site-packages\\anthropic\\_base_client.py:1314\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n",
      "\u001b[32m   1311\u001b[39m opts = FinalRequestOptions.construct(\n",
      "\u001b[32m   1312\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n",
      "\u001b[32m   1313\u001b[39m )\n",
      "\u001b[32m-> \u001b[39m\u001b[32m1314\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mz:\\VSCODE Projects\\PythonProjects\\oreilly-reasoning-models\\oreilly-reasoning-models\\.venv\\Lib\\site-packages\\anthropic\\_base_client.py:1023\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n",
      "\u001b[32m   1022\u001b[39m remaining_retries = max_retries - retries_taken\n",
      "\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m request = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   1024\u001b[39m \u001b[38;5;28mself\u001b[39m._prepare_request(request)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mz:\\VSCODE Projects\\PythonProjects\\oreilly-reasoning-models\\oreilly-reasoning-models\\.venv\\Lib\\site-packages\\anthropic\\_base_client.py:506\u001b[39m, in \u001b[36mBaseClient._build_request\u001b[39m\u001b[34m(self, options, retries_taken)\u001b[39m\n",
      "\u001b[32m    504\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected JSON data type, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(json_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, cannot merge with `extra_body`\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[32m--> \u001b[39m\u001b[32m506\u001b[39m headers = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    507\u001b[39m params = _merge_mappings(\u001b[38;5;28mself\u001b[39m.default_query, options.params)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mz:\\VSCODE Projects\\PythonProjects\\oreilly-reasoning-models\\oreilly-reasoning-models\\.venv\\Lib\\site-packages\\anthropic\\_base_client.py:447\u001b[39m, in \u001b[36mBaseClient._build_headers\u001b[39m\u001b[34m(self, options, retries_taken)\u001b[39m\n",
      "\u001b[32m    438\u001b[39m headers_dict = _merge_mappings(\n",
      "\u001b[32m    439\u001b[39m     {\n",
      "\u001b[32m    440\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mx-stainless-timeout\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(options.timeout.read)\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m    445\u001b[39m     custom_headers,\n",
      "\u001b[32m    446\u001b[39m )\n",
      "\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheaders_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_headers\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    449\u001b[39m \u001b[38;5;66;03m# headers are case-insensitive while dictionaries are not.\u001b[39;00m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mz:\\VSCODE Projects\\PythonProjects\\oreilly-reasoning-models\\oreilly-reasoning-models\\.venv\\Lib\\site-packages\\anthropic\\_client.py:196\u001b[39m, in \u001b[36mAnthropic._validate_headers\u001b[39m\u001b[34m(self, headers, custom_headers)\u001b[39m\n",
      "\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n",
      "\u001b[32m    197\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not resolve authentication method. Expected either api_key or auth_token to be set. Or for one of the `X-Api-Key` or `Authorization` headers to be explicitly omitted\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[32m    198\u001b[39m )\n",
      "\n",
      "\u001b[31mTypeError\u001b[39m: \"Could not resolve authentication method. Expected either api_key or auth_token to be set. Or for one of the `X-Api-Key` or `Authorization` headers to be explicitly omitted\"\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 49\u001b[39m\n",
      "\u001b[32m     46\u001b[39m         \u001b[38;5;28mprint\u001b[39m(response.content[\u001b[32m0\u001b[39m].text)\n",
      "\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# Run the example\u001b[39;00m\n",
      "\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[43mbasic_thinking_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mbasic_thinking_example\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFalling back to regular Claude response...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Fallback to regular response without thinking\u001b[39;00m\n",
      "\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclaude-3-5-sonnet-20241022\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\n",
      "\u001b[32m     40\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m     41\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat is 27 * 453? Show me how you calculate this step by step.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n",
      "\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[32m     43\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m     45\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Claude\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms Response:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[32m     46\u001b[39m \u001b[38;5;28mprint\u001b[39m(response.content[\u001b[32m0\u001b[39m].text)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mz:\\VSCODE Projects\\PythonProjects\\oreilly-reasoning-models\\oreilly-reasoning-models\\.venv\\Lib\\site-packages\\anthropic\\_utils\\_utils.py:283\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n",
      "\u001b[32m    281\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m    282\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n",
      "\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mz:\\VSCODE Projects\\PythonProjects\\oreilly-reasoning-models\\oreilly-reasoning-models\\.venv\\Lib\\site-packages\\anthropic\\resources\\messages\\messages.py:997\u001b[39m, in \u001b[36mMessages.create\u001b[39m\u001b[34m(self, max_tokens, messages, model, metadata, service_tier, stop_sequences, stream, system, temperature, thinking, tool_choice, tools, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n",
      "\u001b[32m    990\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m DEPRECATED_MODELS:\n",
      "\u001b[32m    991\u001b[39m     warnings.warn(\n",
      "\u001b[32m    992\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe model \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is deprecated and will reach end-of-life on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDEPRECATED_MODELS[model]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPlease migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\u001b[39m\u001b[33m\"\u001b[39m,\n",
      "\u001b[32m    993\u001b[39m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n",
      "\u001b[32m    994\u001b[39m         stacklevel=\u001b[32m3\u001b[39m,\n",
      "\u001b[32m    995\u001b[39m     )\n",
      "\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/v1/messages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    999\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n",
      "\u001b[32m   1001\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1002\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1003\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1004\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1005\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1006\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop_sequences\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_sequences\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1007\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1008\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1009\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1010\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthinking\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mthinking\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1011\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1012\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1013\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_k\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1014\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMessageCreateParamsStreaming\u001b[49m\n",
      "\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n",
      "\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMessageCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1019\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1020\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m   1021\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n",
      "\u001b[32m   1022\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1023\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMessage\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1024\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1025\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mRawMessageStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1026\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mz:\\VSCODE Projects\\PythonProjects\\oreilly-reasoning-models\\oreilly-reasoning-models\\.venv\\Lib\\site-packages\\anthropic\\_base_client.py:1314\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n",
      "\u001b[32m   1300\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n",
      "\u001b[32m   1301\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n",
      "\u001b[32m   1302\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m   1309\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "\u001b[32m   1310\u001b[39m ) -> ResponseT | _StreamT:\n",
      "\u001b[32m   1311\u001b[39m     opts = FinalRequestOptions.construct(\n",
      "\u001b[32m   1312\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n",
      "\u001b[32m   1313\u001b[39m     )\n",
      "\u001b[32m-> \u001b[39m\u001b[32m1314\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mz:\\VSCODE Projects\\PythonProjects\\oreilly-reasoning-models\\oreilly-reasoning-models\\.venv\\Lib\\site-packages\\anthropic\\_base_client.py:1023\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n",
      "\u001b[32m   1020\u001b[39m options = \u001b[38;5;28mself\u001b[39m._prepare_options(options)\n",
      "\u001b[32m   1022\u001b[39m remaining_retries = max_retries - retries_taken\n",
      "\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m request = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   1024\u001b[39m \u001b[38;5;28mself\u001b[39m._prepare_request(request)\n",
      "\u001b[32m   1026\u001b[39m kwargs: HttpxSendArgs = {}\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mz:\\VSCODE Projects\\PythonProjects\\oreilly-reasoning-models\\oreilly-reasoning-models\\.venv\\Lib\\site-packages\\anthropic\\_base_client.py:506\u001b[39m, in \u001b[36mBaseClient._build_request\u001b[39m\u001b[34m(self, options, retries_taken)\u001b[39m\n",
      "\u001b[32m    503\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m    504\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected JSON data type, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(json_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, cannot merge with `extra_body`\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[32m--> \u001b[39m\u001b[32m506\u001b[39m headers = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    507\u001b[39m params = _merge_mappings(\u001b[38;5;28mself\u001b[39m.default_query, options.params)\n",
      "\u001b[32m    508\u001b[39m content_type = headers.get(\u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mz:\\VSCODE Projects\\PythonProjects\\oreilly-reasoning-models\\oreilly-reasoning-models\\.venv\\Lib\\site-packages\\anthropic\\_base_client.py:447\u001b[39m, in \u001b[36mBaseClient._build_headers\u001b[39m\u001b[34m(self, options, retries_taken)\u001b[39m\n",
      "\u001b[32m    437\u001b[39m custom_headers = options.headers \u001b[38;5;129;01mor\u001b[39;00m {}\n",
      "\u001b[32m    438\u001b[39m headers_dict = _merge_mappings(\n",
      "\u001b[32m    439\u001b[39m     {\n",
      "\u001b[32m    440\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mx-stainless-timeout\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(options.timeout.read)\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m    445\u001b[39m     custom_headers,\n",
      "\u001b[32m    446\u001b[39m )\n",
      "\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheaders_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_headers\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    449\u001b[39m \u001b[38;5;66;03m# headers are case-insensitive while dictionaries are not.\u001b[39;00m\n",
      "\u001b[32m    450\u001b[39m headers = httpx.Headers(headers_dict)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mz:\\VSCODE Projects\\PythonProjects\\oreilly-reasoning-models\\oreilly-reasoning-models\\.venv\\Lib\\site-packages\\anthropic\\_client.py:196\u001b[39m, in \u001b[36mAnthropic._validate_headers\u001b[39m\u001b[34m(self, headers, custom_headers)\u001b[39m\n",
      "\u001b[32m    193\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(custom_headers.get(\u001b[33m\"\u001b[39m\u001b[33mAuthorization\u001b[39m\u001b[33m\"\u001b[39m), Omit):\n",
      "\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n",
      "\u001b[32m    197\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not resolve authentication method. Expected either api_key or auth_token to be set. Or for one of the `X-Api-Key` or `Authorization` headers to be explicitly omitted\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[32m    198\u001b[39m )\n",
      "\n",
      "\u001b[31mTypeError\u001b[39m: \"Could not resolve authentication method. Expected either api_key or auth_token to be set. Or for one of the `X-Api-Key` or `Authorization` headers to be explicitly omitted\""
     ]
    }
   ],
   "source": [
    "def basic_thinking_example():\n",
    "    \"\"\"A simple example demonstrating extended thinking\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Try with extended thinking first\n",
    "        response = client.messages.create(\n",
    "            model=\"claude-3-5-sonnet-20241022\",  # Use a known available model\n",
    "            max_tokens=2000,\n",
    "            thinking={\n",
    "                \"type\": \"enabled\",\n",
    "                \"budget_tokens\": 5000  # How many tokens Claude can use for thinking\n",
    "            },\n",
    "            messages=[{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What is 27 * 453? Show me how you calculate this step by step.\"\n",
    "            }]\n",
    "        )\n",
    "        \n",
    "        # Process the response\n",
    "        for block in response.content:\n",
    "            if block.type == \"thinking\":\n",
    "                print(\"ü§î Claude's Thinking Process:\")\n",
    "                print(\"-\" * 50)\n",
    "                print(block.thinking)\n",
    "                print(\"-\" * 50)\n",
    "                print()\n",
    "            elif block.type == \"text\":\n",
    "                print(\"‚úÖ Final Answer:\")\n",
    "                print(block.text)\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Extended thinking not available: {str(e)}\")\n",
    "        print(\"Falling back to regular Claude response...\\n\")\n",
    "        \n",
    "        # Fallback to regular response without thinking\n",
    "        response = client.messages.create(\n",
    "            model=\"claude-3-5-sonnet-20241022\",\n",
    "            max_tokens=2000,\n",
    "            messages=[{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What is 27 * 453? Show me how you calculate this step by step.\"\n",
    "            }]\n",
    "        )\n",
    "        \n",
    "        print(\"‚úÖ Claude's Response:\")\n",
    "        print(response.content[0].text)\n",
    "\n",
    "# Run the example\n",
    "basic_thinking_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_calculator():\n",
    "    \"\"\"Calculate costs for extended thinking usage\"\"\"\n",
    "    \n",
    "    # Pricing as of the documentation (prices per million tokens)\n",
    "    pricing = {\n",
    "        \"claude-opus-4\": {\"input\": 15, \"output\": 75},\n",
    "        \"claude-sonnet-4\": {\"input\": 3, \"output\": 15},\n",
    "        \"claude-sonnet-3.7\": {\"input\": 3, \"output\": 15}\n",
    "    }\n",
    "    \n",
    "    print(\"üí∞ Extended Thinking Cost Calculator\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Example scenario\n",
    "    scenarios = [\n",
    "        {\"name\": \"Simple Analysis\", \"input\": 500, \"thinking\": 5000, \"output\": 1000},\n",
    "        {\"name\": \"Complex Problem\", \"input\": 2000, \"thinking\": 20000, \"output\": 3000},\n",
    "        {\"name\": \"Deep Research\", \"input\": 5000, \"thinking\": 50000, \"output\": 8000}\n",
    "    ]\n",
    "    \n",
    "    for model, prices in pricing.items():\n",
    "        print(f\"\\nüìä Model: {model}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        for scenario in scenarios:\n",
    "            # Remember: thinking tokens are billed as output tokens\n",
    "            input_cost = (scenario[\"input\"] / 1_000_000) * prices[\"input\"]\n",
    "            thinking_cost = (scenario[\"thinking\"] / 1_000_000) * prices[\"output\"]\n",
    "            output_cost = (scenario[\"output\"] / 1_000_000) * prices[\"output\"]\n",
    "            total_cost = input_cost + thinking_cost + output_cost\n",
    "            \n",
    "            print(f\"\\n  {scenario['name']}:\")\n",
    "            print(f\"    Input tokens: {scenario['input']:,}\")\n",
    "            print(f\"    Thinking tokens: {scenario['thinking']:,} (billed as output)\")\n",
    "            print(f\"    Output tokens: {scenario['output']:,}\")\n",
    "            print(f\"    Total cost: ${total_cost:.4f}\")\n",
    "\n",
    "cost_calculator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Optimization Tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Performance Optimization Strategies\n",
      "============================================================\n",
      "\n",
      "1. Start with Minimal Budget\n",
      "  üìù Begin with 1,024 tokens and increase only if needed\n",
      "  üí° Budget: 1,024 tokens\n",
      "  üéØ Best for: Simple calculations or basic analysis\n",
      "\n",
      "2. Use Streaming for Better UX\n",
      "  üìù Stream responses to show progress during long thinking\n",
      "  üí° Budget: 10,000 tokens\n",
      "  üéØ Best for: Interactive applications\n",
      "\n",
      "3. Batch Processing for Large Budgets\n",
      "  üìù Use batch API for thinking budgets > 32k tokens\n",
      "  üí° Budget: 50,000 tokens\n",
      "  üéØ Best for: Overnight analysis jobs\n",
      "\n",
      "4. Cache Common Patterns\n",
      "  üìù Use prompt caching for repeated analysis patterns\n",
      "  üí° Budget: 15,000 tokens\n",
      "  üéØ Best for: Standardized document analysis\n",
      "\n",
      "\n",
      "üìà Budget vs. Quality Guidelines:\n",
      "----------------------------------------\n",
      "  1,024 - 5,000 tokens: Basic reasoning tasks\n",
      "  5,000 - 15,000 tokens: Standard complex problems\n",
      "  15,000 - 32,000 tokens: Deep analysis and research\n",
      "  32,000+ tokens: Extensive multi-faceted problems\n"
     ]
    }
   ],
   "source": [
    "def performance_tips():\n",
    "    \"\"\"Demonstrate performance optimization strategies\"\"\"\n",
    "    \n",
    "    print(\"‚ö° Performance Optimization Strategies\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    strategies = [\n",
    "        {\n",
    "            \"title\": \"1. Start with Minimal Budget\",\n",
    "            \"description\": \"Begin with 1,024 tokens and increase only if needed\",\n",
    "            \"example_budget\": 1024,\n",
    "            \"use_case\": \"Simple calculations or basic analysis\"\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"2. Use Streaming for Better UX\",\n",
    "            \"description\": \"Stream responses to show progress during long thinking\",\n",
    "            \"example_budget\": 10000,\n",
    "            \"use_case\": \"Interactive applications\"\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"3. Batch Processing for Large Budgets\",\n",
    "            \"description\": \"Use batch API for thinking budgets > 32k tokens\",\n",
    "            \"example_budget\": 50000,\n",
    "            \"use_case\": \"Overnight analysis jobs\"\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"4. Cache Common Patterns\",\n",
    "            \"description\": \"Use prompt caching for repeated analysis patterns\",\n",
    "            \"example_budget\": 15000,\n",
    "            \"use_case\": \"Standardized document analysis\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for strategy in strategies:\n",
    "        print(f\"\\n{strategy['title']}\")\n",
    "        print(f\"  üìù {strategy['description']}\")\n",
    "        print(f\"  üí° Budget: {strategy['example_budget']:,} tokens\")\n",
    "        print(f\"  üéØ Best for: {strategy['use_case']}\")\n",
    "    \n",
    "    print(\"\\n\\nüìà Budget vs. Quality Guidelines:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"  1,024 - 5,000 tokens: Basic reasoning tasks\")\n",
    "    print(\"  5,000 - 15,000 tokens: Standard complex problems\")\n",
    "    print(\"  15,000 - 32,000 tokens: Deep analysis and research\")\n",
    "    print(\"  32,000+ tokens: Extensive multi-faceted problems\")\n",
    "\n",
    "performance_tips()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "### What We've Learned\n",
    "\n",
    "1. **Extended Thinking Basics**: How to enable and use Claude's reasoning capabilities\n",
    "2. **Thinking Blocks**: Understanding the structure and content of thinking outputs\n",
    "3. **Advanced Features**: Streaming, tool use, and complex scenarios\n",
    "4. **Best Practices**: Optimal prompting and budget selection\n",
    "5. **Real-World Applications**: Document analysis and architecture planning\n",
    "6. **Cost Management**: Understanding pricing and optimization strategies\n",
    "\n",
    "### When to Use Extended Thinking\n",
    "\n",
    "‚úÖ **Use it for:**\n",
    "- Complex multi-step problems\n",
    "- Deep document analysis\n",
    "- Strategic planning and decision-making\n",
    "- Quality-critical tasks where accuracy matters more than speed\n",
    "\n",
    "‚ùå **Avoid it for:**\n",
    "- Simple queries or lookups\n",
    "- Real-time chat applications\n",
    "- Tasks where latency is critical\n",
    "- High-volume, low-complexity requests\n",
    "\n",
    "### Resources for Further Learning\n",
    "\n",
    "- [Anthropic Documentation](https://docs.anthropic.com/)\n",
    "- [Extended Thinking Cookbook](https://docs.anthropic.com/cookbook/extended-thinking)\n",
    "- [API Reference](https://docs.anthropic.com/api/)\n",
    "\n",
    "### Try It Yourself!\n",
    "\n",
    "Now that you understand extended thinking, try these challenges:\n",
    "\n",
    "1. **Math Challenge**: Use extended thinking to solve a complex optimization problem\n",
    "2. **Analysis Challenge**: Analyze a dataset and provide insights with reasoning\n",
    "3. **Planning Challenge**: Design a system architecture for your own project\n",
    "4. **Comparison Challenge**: Compare different thinking budgets on the same problem\n",
    "\n",
    "Happy thinking! ü§î‚ú®"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-reasoning-models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
